{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "from scripts.ollama_handler import OllamaMediaAnalysis\n",
    "from scripts.file_analyzer import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model for ollama\n",
    "# ollama.list() # to get all models\n",
    "MODEL = \"granite3.1-moe:3b-instruct-q8_0\" #\"granite3.1-moe\" #\"granite3.1-dense:8b-instruct-q8_0\" #\"granite3.1-dense:8b\"\n",
    "#SYSTEM_PROMPT = f\"You are a senior researcher, working on a media analysis of articles published in arabic newspapers about ChatGPT and the effect of Artificial Intelligence on society. For your answers only focus on topics that were mentioned in the text without adding any further information. Before answering, thoroughly think about the task, the content provided and build your answer with chain of thought reasoning.\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a senior researcher conducting a media analysis of Arabic newspaper articles \"\n",
    "    \"about ChatGPT and the societal effects of Artificial Intelligence. Your role is to focus \"\n",
    "    \"exclusively on the topics mentioned in the provided text, without introducing external information. \"\n",
    "    \"Before responding, carefully analyze the task, thoroughly evaluate the content of the articles, \"\n",
    "    \"and construct your answer using a clear chain of thought reasoning approach.\"\n",
    ")\n",
    "\n",
    "# MAY TAKE LONG TIME! Whether all files should be processed (indicates Ollama interactions)\n",
    "PROCESS_DOCUMENTS = False\n",
    "\n",
    "# Load spacy model\n",
    "SPACY_MODEL = \"en_core_web_lg\"\n",
    "\n",
    "\n",
    "# Set folder paths\n",
    "DOCUMENTS_FOLDER = \"docs\"\n",
    "FILES_FOLDER = os.path.join(DOCUMENTS_FOLDER, \"DOCX\") # PDFs\n",
    "OUTPUT_FOLDER = os.path.join(DOCUMENTS_FOLDER, \"Processed\", MODEL)\n",
    "EXPORT_FILE_NAME = f\"{datetime.now().strftime(\"%y%m%d\")}-{MODEL}-processed_documents.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d: dict):\n",
    "    \"\"\"Recursively flatten a dictionary with nested lists.\"\"\"\n",
    "    flattened_dict = dict()\n",
    "    for k, v in d.items():\n",
    "        flat_list = []\n",
    "        if isinstance(v, list):\n",
    "            flat_list.extend(flatten_list(v))\n",
    "        elif isinstance(v, dict):\n",
    "            flat_list.extend(flatten_dict(v))\n",
    "        \n",
    "        flattened_dict[k] = flat_list\n",
    "    return flattened_dict\n",
    "\n",
    "def flatten_list(l: list):\n",
    "    \"\"\"Recursively flatten a nested list.\"\"\"\n",
    "    flat_list = []\n",
    "    for item in l:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize File Analyzer\n",
    "Handes all files, folder processing, text extraction, question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define questions for the analyzer\n",
    "questions =  [\n",
    "    \"How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\",\n",
    "    \"Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\",\n",
    "    \"Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\",\n",
    "    \"What is the final message of the article that the author wants to convey? Keep your answer short and precise!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm as instance of OllamaMediaAnalysis\n",
    "llm = OllamaMediaAnalysis(model_name=MODEL, system_prompt=SYSTEM_PROMPT, debug=True)\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = FileAnalyzer(ollama_handler=llm, entity_collection=\"spacy\", spacy_model=SPACY_MODEL, file_name=EXPORT_FILE_NAME, output_folder=OUTPUT_FOLDER, questions=questions, debug=False, speed_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:21:33 Analyzing file from folder: ChatGPT AI grows more powerful as we become more predictable_standardizedlayout.docx\n",
      "23:21:33\t Adding paragraph 1/11 with 32 characters\n",
      "23:21:33\t Adding paragraph 2/11 with 19 characters\n",
      "23:21:33\t Adding paragraph 3/11 with 13 characters\n",
      "23:21:33\t Adding paragraph 4/11 with 19 characters\n",
      "23:21:33\t Adding paragraph 5/11 with 36 characters\n",
      "23:21:33\t Adding paragraph 6/11 with 20 characters\n",
      "23:21:33\t Adding paragraph 7/11 with 11 characters\n",
      "23:21:33\t Adding paragraph 8/11 with 0 characters\n",
      "23:21:33\t Adding paragraph 9/11 with 0 characters\n",
      "23:21:33\t Adding paragraph 10/11 with 0 characters\n",
      "23:21:33\t Adding paragraph 11/11 with 5560 characters\n",
      "23:21:33\t Create Docx document <ChatGPT AI grows mor...> with content of length 5523\n",
      "23:21:33 Initialized Document: <ChatGPT AI grows more powerful as we become more predictable>\n",
      "23:21:33\t Generating tokenized content\n",
      "23:21:33\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...cietal reflection.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:21:43\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...al reinforcement.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:21:44\t Generating summary\n",
      "23:21:59\t Finding answer to 4 questions\n",
      "23:21:59\t Answering question <How do the media in this artic...>\n",
      "23:22:12\t Answering question <Which role does or might the A...>\n",
      "23:22:14\t Answering question <Which use cases of Artificial ...>\n",
      "23:22:18\t Answering question <What is the final message of t...>\n",
      "23:22:21\t Analyzing sentiment\n",
      "23:22:31\t Extracting entities from text\n",
      "23:22:31\t Found 10 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT AI grows more powerful as we become more predictable\n",
      "Temporarily storing documents\n",
      "23:22:42 Analyzing file from folder: ChatGPT is the ‘Netscape moment’ for artificial intelligence’_standardizedlayout.docx\n",
      "23:22:42\t Adding paragraph 1/11 with 32 characters\n",
      "23:22:42\t Adding paragraph 2/11 with 21 characters\n",
      "23:22:42\t Adding paragraph 3/11 with 13 characters\n",
      "23:22:42\t Adding paragraph 4/11 with 19 characters\n",
      "23:22:42\t Adding paragraph 5/11 with 34 characters\n",
      "23:22:42\t Adding paragraph 6/11 with 23 characters\n",
      "23:22:42\t Adding paragraph 7/11 with 11 characters\n",
      "23:22:42\t Adding paragraph 8/11 with 0 characters\n",
      "23:22:42\t Adding paragraph 9/11 with 0 characters\n",
      "23:22:42\t Adding paragraph 10/11 with 0 characters\n",
      "23:22:42\t Adding paragraph 11/11 with 6370 characters\n",
      "23:22:42\t Create Docx document <ChatGPT is the Netsc...> with content of length 6349\n",
      "23:22:42 Initialized Document: <ChatGPT is the Netscape moment' for artificial intelligence'>\n",
      "23:22:42\t Generating tokenized content\n",
      "23:22:43\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T... being developed.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:22:54\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...rmation and harm.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:22:55\t Generating summary\n",
      "23:23:11\t Finding answer to 4 questions\n",
      "23:23:11\t Answering question <How do the media in this artic...>\n",
      "23:23:26\t Answering question <Which role does or might the A...>\n",
      "23:23:27\t Answering question <Which use cases of Artificial ...>\n",
      "23:23:31\t Answering question <What is the final message of t...>\n",
      "23:23:35\t Analyzing sentiment\n",
      "23:23:46\t Extracting entities from text\n",
      "23:23:46\t Found 6 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the Netscape moment' for artificial intelligence'\n",
      "Temporarily storing documents\n",
      "23:23:59 Analyzing file from folder: ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts_standardizedlayout.docx\n",
      "23:23:59\t Adding paragraph 1/16 with 50 characters\n",
      "23:23:59\t Adding paragraph 2/16 with 19 characters\n",
      "23:23:59\t Adding paragraph 3/16 with 13 characters\n",
      "23:23:59\t Adding paragraph 4/16 with 19 characters\n",
      "23:23:59\t Adding paragraph 5/16 with 39 characters\n",
      "23:23:59\t Adding paragraph 6/16 with 26 characters\n",
      "23:23:59\t Adding paragraph 7/16 with 11 characters\n",
      "23:23:59\t Adding paragraph 8/16 with 0 characters\n",
      "23:23:59\t Adding paragraph 9/16 with 0 characters\n",
      "23:23:59\t Adding paragraph 10/16 with 0 characters\n",
      "23:23:59\t Adding paragraph 11/16 with 0 characters\n",
      "23:23:59\t Adding paragraph 12/16 with 68 characters\n",
      "23:23:59\t Adding paragraph 13/16 with 0 characters\n",
      "23:23:59\t Adding paragraph 14/16 with 212 characters\n",
      "23:23:59\t Adding paragraph 15/16 with 0 characters\n",
      "23:23:59\t Adding paragraph 16/16 with 2705 characters\n",
      "23:23:59\t Create Docx document <ChatGPT outperforms ...> with content of length 2944\n",
      "23:23:59 Initialized Document: <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>\n",
      "23:23:59\t Generating tokenized content\n",
      "23:23:59\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"STE...and Google\\'s Bard.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:24:04\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...dvanced AI tools.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:24:05\t Generating summary\n",
      "23:24:12\t Finding answer to 4 questions\n",
      "23:24:12\t Answering question <How do the media in this artic...>\n",
      "23:24:22\t Answering question <Which role does or might the A...>\n",
      "23:24:24\t Answering question <Which use cases of Artificial ...>\n",
      "23:24:28\t Answering question <What is the final message of t...>\n",
      "23:24:30\t Analyzing sentiment\n",
      "23:24:36\t Extracting entities from text\n",
      "23:24:36\t Found 1 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference's outdoor adverts\n",
      "Temporarily storing documents\n",
      "23:24:42 Analyzing file from folder: AI is not smarter than humans_standardizedlayout.docx\n",
      "23:24:42\t Adding paragraph 1/11 with 32 characters\n",
      "23:24:42\t Adding paragraph 2/11 with 19 characters\n",
      "23:24:42\t Adding paragraph 3/11 with 13 characters\n",
      "23:24:42\t Adding paragraph 4/11 with 19 characters\n",
      "23:24:42\t Adding paragraph 5/11 with 36 characters\n",
      "23:24:42\t Adding paragraph 6/11 with 23 characters\n",
      "23:24:42\t Adding paragraph 7/11 with 11 characters\n",
      "23:24:42\t Adding paragraph 8/11 with 0 characters\n",
      "23:24:42\t Adding paragraph 9/11 with 0 characters\n",
      "23:24:42\t Adding paragraph 10/11 with 0 characters\n",
      "23:24:42\t Adding paragraph 11/11 with 4564 characters\n",
      "23:24:43\t Create Docx document <AI is not smarter th...> with content of length 4524\n",
      "23:24:43 Initialized Document: <AI is not smarter than humans>\n",
      "23:24:43\t Generating tokenized content\n",
      "23:24:43\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\"short_summary\": \"The a...ced cultural aspects.\"}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:24:51\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:24:52\t Generating summary\n",
      "23:25:04\t Finding answer to 4 questions\n",
      "23:25:04\t Answering question <How do the media in this artic...>\n",
      "23:25:17\t Answering question <Which role does or might the A...>\n",
      "23:25:18\t Answering question <Which use cases of Artificial ...>\n",
      "23:25:22\t Answering question <What is the final message of t...>\n",
      "23:25:24\t Analyzing sentiment\n",
      "23:25:35\t Extracting entities from text\n",
      "23:25:35\t Found 6 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans\n",
      "Temporarily storing documents\n",
      "23:25:45 Analyzing file from folder: No need to demonize ChatGPT but AI regulation is a must_standardizedlayout.docx\n",
      "23:25:45\t Adding paragraph 1/12 with 32 characters\n",
      "23:25:45\t Adding paragraph 2/12 with 19 characters\n",
      "23:25:45\t Adding paragraph 3/12 with 13 characters\n",
      "23:25:45\t Adding paragraph 4/12 with 19 characters\n",
      "23:25:45\t Adding paragraph 5/12 with 38 characters\n",
      "23:25:45\t Adding paragraph 6/12 with 27 characters\n",
      "23:25:45\t Adding paragraph 7/12 with 11 characters\n",
      "23:25:45\t Adding paragraph 8/12 with 0 characters\n",
      "23:25:45\t Adding paragraph 9/12 with 0 characters\n",
      "23:25:45\t Adding paragraph 10/12 with 0 characters\n",
      "23:25:45\t Adding paragraph 11/12 with 55 characters\n",
      "23:25:45\t Adding paragraph 12/12 with 7475 characters\n",
      "23:25:45\t Create Docx document <No need to demonize ...> with content of length 7471\n",
      "23:25:45 Initialized Document: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "23:25:45\t Generating tokenized content\n",
      "23:25:45\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...obal advancement.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:25:58\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...sible regulation.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:25:59\t Generating summary\n",
      "23:26:19\t Finding answer to 4 questions\n",
      "23:26:19\t Answering question <How do the media in this artic...>\n",
      "23:26:34\t Answering question <Which role does or might the A...>\n",
      "23:26:36\t Answering question <Which use cases of Artificial ...>\n",
      "23:26:40\t Answering question <What is the final message of t...>\n",
      "23:26:54\t Analyzing sentiment\n",
      "23:27:09\t Extracting entities from text\n",
      "23:27:09\t Found 7 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must\n",
      "Temporarily storing documents\n",
      "23:27:25 Analyzing file from folder: Is the Arab world ready for the uncertain age of AI-powered web tools_standardizedlayout.docx\n",
      "23:27:25\t Adding paragraph 1/23 with 32 characters\n",
      "23:27:25\t Adding paragraph 2/23 with 19 characters\n",
      "23:27:25\t Adding paragraph 3/23 with 13 characters\n",
      "23:27:25\t Adding paragraph 4/23 with 19 characters\n",
      "23:27:25\t Adding paragraph 5/23 with 35 characters\n",
      "23:27:25\t Adding paragraph 6/23 with 47 characters\n",
      "23:27:25\t Adding paragraph 7/23 with 11 characters\n",
      "23:27:25\t Adding paragraph 8/23 with 0 characters\n",
      "23:27:25\t Adding paragraph 9/23 with 0 characters\n",
      "23:27:25\t Adding paragraph 10/23 with 0 characters\n",
      "23:27:25\t Adding paragraph 11/23 with 69 characters\n",
      "23:27:25\t Adding paragraph 12/23 with 114 characters\n",
      "23:27:25\t Adding paragraph 13/23 with 104 characters\n",
      "23:27:25\t Adding paragraph 14/23 with 0 characters\n",
      "23:27:25\t Adding paragraph 15/23 with 5372 characters\n",
      "23:27:25\t Adding paragraph 16/23 with 0 characters\n",
      "23:27:25\t Adding paragraph 17/23 with 9 characters\n",
      "23:27:25\t Adding paragraph 18/23 with 55 characters\n",
      "23:27:25\t Adding paragraph 19/23 with 74 characters\n",
      "23:27:25\t Adding paragraph 20/23 with 55 characters\n",
      "23:27:25\t Adding paragraph 21/23 with 55 characters\n",
      "23:27:25\t Adding paragraph 22/23 with 0 characters\n",
      "23:27:25\t Adding paragraph 23/23 with 5093 characters\n",
      "23:27:25\t Create Docx document <Is the Arab world re...> with content of length 10864\n",
      "23:27:25 Initialized Document: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "23:27:25\t Generating tokenized content\n",
      "23:27:25\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"A...cation is fostered.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:27:42\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n    \"short_summary\": ...ible application.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:27:44\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value=\"The rapid advancement of...ision-making processes.\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:28:06\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value=\"The advent of advanced a...industry leaders alike.\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:28:30\t Finding answer to 4 questions\n",
      "23:28:30\t Answering question <How do the media in this artic...>\n",
      "23:28:49\t Answering question <Which role does or might the A...>\n",
      "23:29:07\t Answering question <Which use cases of Artificial ...>\n",
      "23:29:26\t Answering question <What is the final message of t...>\n",
      "23:29:44\t Analyzing sentiment\n",
      "23:30:00\t Extracting entities from text\n",
      "23:30:00\t Found 20 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools\n",
      "Temporarily storing documents\n",
      "23:30:18 Analyzing file from folder: ‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host_standardizedlayout.docx\n",
      "23:30:18\t Adding paragraph 1/230 with 32 characters\n",
      "23:30:18\t Adding paragraph 2/230 with 19 characters\n",
      "23:30:18\t Adding paragraph 3/230 with 13 characters\n",
      "23:30:18\t Adding paragraph 4/230 with 19 characters\n",
      "23:30:18\t Adding paragraph 5/230 with 36 characters\n",
      "23:30:18\t Adding paragraph 6/230 with 22 characters\n",
      "23:30:18\t Adding paragraph 7/230 with 11 characters\n",
      "23:30:18\t Adding paragraph 8/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 9/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 10/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 11/230 with 69 characters\n",
      "23:30:18\t Adding paragraph 12/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 13/230 with 150 characters\n",
      "23:30:18\t Adding paragraph 14/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 15/230 with 138 characters\n",
      "23:30:18\t Adding paragraph 16/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 17/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 18/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 19/230 with 31 characters\n",
      "23:30:18\t Adding paragraph 20/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 21/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 22/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 23/230 with 69 characters\n",
      "23:30:18\t Adding paragraph 24/230 with 41 characters\n",
      "23:30:18\t Adding paragraph 25/230 with 69 characters\n",
      "23:30:18\t Adding paragraph 26/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 27/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 28/230 with 40 characters\n",
      "23:30:18\t Adding paragraph 29/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 30/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 31/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 32/230 with 26 characters\n",
      "23:30:18\t Adding paragraph 33/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 34/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 35/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 36/230 with 19 characters\n",
      "23:30:18\t Adding paragraph 37/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 38/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 39/230 with 24 characters\n",
      "23:30:18\t Adding paragraph 40/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 41/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 42/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 43/230 with 13 characters\n",
      "23:30:18\t Adding paragraph 44/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 45/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 46/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 47/230 with 39 characters\n",
      "23:30:18\t Adding paragraph 48/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 49/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 50/230 with 120 characters\n",
      "23:30:18\t Adding paragraph 51/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 52/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 53/230 with 63 characters\n",
      "23:30:18\t Adding paragraph 54/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 55/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 56/230 with 32 characters\n",
      "23:30:18\t Adding paragraph 57/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 58/230 with 39 characters\n",
      "23:30:18\t Adding paragraph 59/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 60/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 61/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 62/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 63/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 64/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 65/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 66/230 with 113 characters\n",
      "23:30:18\t Adding paragraph 67/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 68/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 69/230 with 37 characters\n",
      "23:30:18\t Adding paragraph 70/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 71/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 72/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 73/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 74/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 75/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 76/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 77/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 78/230 with 39 characters\n",
      "23:30:18\t Adding paragraph 79/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 80/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 81/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 82/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 83/230 with 20 characters\n",
      "23:30:18\t Adding paragraph 84/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 85/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 86/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 87/230 with 82 characters\n",
      "23:30:18\t Adding paragraph 88/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 89/230 with 13 characters\n",
      "23:30:18\t Adding paragraph 90/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 91/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 92/230 with 37 characters\n",
      "23:30:18\t Adding paragraph 93/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 94/230 with 67 characters\n",
      "23:30:18\t Adding paragraph 95/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 96/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 97/230 with 145 characters\n",
      "23:30:18\t Adding paragraph 98/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 99/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 100/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 101/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 102/230 with 37 characters\n",
      "23:30:18\t Adding paragraph 103/230 with 83 characters\n",
      "23:30:18\t Adding paragraph 104/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 105/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 106/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 107/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 108/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 109/230 with 81 characters\n",
      "23:30:18\t Adding paragraph 110/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 111/230 with 51 characters\n",
      "23:30:18\t Adding paragraph 112/230 with 82 characters\n",
      "23:30:18\t Adding paragraph 113/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 114/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 115/230 with 21 characters\n",
      "23:30:18\t Adding paragraph 116/230 with 64 characters\n",
      "23:30:18\t Adding paragraph 117/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 118/230 with 20 characters\n",
      "23:30:18\t Adding paragraph 119/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 120/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 121/230 with 52 characters\n",
      "23:30:18\t Adding paragraph 122/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 123/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 124/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 125/230 with 39 characters\n",
      "23:30:18\t Adding paragraph 126/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 127/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 128/230 with 23 characters\n",
      "23:30:18\t Adding paragraph 129/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 130/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 131/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 132/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 133/230 with 137 characters\n",
      "23:30:18\t Adding paragraph 134/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 135/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 136/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 137/230 with 50 characters\n",
      "23:30:18\t Adding paragraph 138/230 with 66 characters\n",
      "23:30:18\t Adding paragraph 139/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 140/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 141/230 with 30 characters\n",
      "23:30:18\t Adding paragraph 142/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 143/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 144/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 145/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 146/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 147/230 with 16 characters\n",
      "23:30:18\t Adding paragraph 148/230 with 66 characters\n",
      "23:30:18\t Adding paragraph 149/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 150/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 151/230 with 13 characters\n",
      "23:30:18\t Adding paragraph 152/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 153/230 with 70 characters\n",
      "23:30:18\t Adding paragraph 154/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 155/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 156/230 with 18 characters\n",
      "23:30:18\t Adding paragraph 157/230 with 81 characters\n",
      "23:30:18\t Adding paragraph 158/230 with 84 characters\n",
      "23:30:18\t Adding paragraph 159/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 160/230 with 70 characters\n",
      "23:30:18\t Adding paragraph 161/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 162/230 with 63 characters\n",
      "23:30:18\t Adding paragraph 163/230 with 64 characters\n",
      "23:30:18\t Adding paragraph 164/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 165/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 166/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 167/230 with 26 characters\n",
      "23:30:18\t Adding paragraph 168/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 169/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 170/230 with 17 characters\n",
      "23:30:18\t Adding paragraph 171/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 172/230 with 56 characters\n",
      "23:30:18\t Adding paragraph 173/230 with 79 characters\n",
      "23:30:18\t Adding paragraph 174/230 with 70 characters\n",
      "23:30:18\t Adding paragraph 175/230 with 9 characters\n",
      "23:30:18\t Adding paragraph 176/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 177/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 178/230 with 70 characters\n",
      "23:30:18\t Adding paragraph 179/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 180/230 with 62 characters\n",
      "23:30:18\t Adding paragraph 181/230 with 68 characters\n",
      "23:30:18\t Adding paragraph 182/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 183/230 with 82 characters\n",
      "23:30:18\t Adding paragraph 184/230 with 23 characters\n",
      "23:30:18\t Adding paragraph 185/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 186/230 with 71 characters\n",
      "23:30:18\t Adding paragraph 187/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 188/230 with 121 characters\n",
      "23:30:18\t Adding paragraph 189/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 190/230 with 68 characters\n",
      "23:30:18\t Adding paragraph 191/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 192/230 with 64 characters\n",
      "23:30:18\t Adding paragraph 193/230 with 62 characters\n",
      "23:30:18\t Adding paragraph 194/230 with 0 characters\n",
      "23:30:18\t Adding paragraph 195/230 with 81 characters\n",
      "23:30:18\t Adding paragraph 196/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 197/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 198/230 with 81 characters\n",
      "23:30:18\t Adding paragraph 199/230 with 69 characters\n",
      "23:30:18\t Adding paragraph 200/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 201/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 202/230 with 40 characters\n",
      "23:30:18\t Adding paragraph 203/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 204/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 205/230 with 120 characters\n",
      "23:30:18\t Adding paragraph 206/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 207/230 with 78 characters\n",
      "23:30:18\t Adding paragraph 208/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 209/230 with 24 characters\n",
      "23:30:18\t Adding paragraph 210/230 with 82 characters\n",
      "23:30:18\t Adding paragraph 211/230 with 33 characters\n",
      "23:30:18\t Adding paragraph 212/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 213/230 with 31 characters\n",
      "23:30:18\t Adding paragraph 214/230 with 81 characters\n",
      "23:30:18\t Adding paragraph 215/230 with 80 characters\n",
      "23:30:18\t Adding paragraph 216/230 with 62 characters\n",
      "23:30:18\t Adding paragraph 217/230 with 74 characters\n",
      "23:30:18\t Adding paragraph 218/230 with 66 characters\n",
      "23:30:18\t Adding paragraph 219/230 with 15 characters\n",
      "23:30:18\t Adding paragraph 220/230 with 81 characters\n",
      "23:30:18\t Adding paragraph 221/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 222/230 with 76 characters\n",
      "23:30:18\t Adding paragraph 223/230 with 64 characters\n",
      "23:30:18\t Adding paragraph 224/230 with 73 characters\n",
      "23:30:18\t Adding paragraph 225/230 with 77 characters\n",
      "23:30:18\t Adding paragraph 226/230 with 72 characters\n",
      "23:30:18\t Adding paragraph 227/230 with 70 characters\n",
      "23:30:18\t Adding paragraph 228/230 with 42 characters\n",
      "23:30:18\t Adding paragraph 229/230 with 75 characters\n",
      "23:30:18\t Adding paragraph 230/230 with 66 characters\n",
      "23:30:18\t Create Docx document <I am not here to tak...> with content of length 14710\n",
      "23:30:18 Initialized Document: <I am not here to take your job,' ChatGPT tells Frankly Speaking host>\n",
      "23:30:18\t Generating tokenized content\n",
      "23:30:18\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"C...ze this technology.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:30:35\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...eed for ethical use.\" }', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:30:37\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value='ChatGPT, an advanced lan..., and ongoing research.', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:30:57\t Generating summary\n",
      "23:31:18\t Finding answer to 4 questions\n",
      "23:31:18\t Answering question <How do the media in this artic...>\n",
      "23:31:39\t Answering question <Which role does or might the A...>\n",
      "23:31:57\t Answering question <Which use cases of Artificial ...>\n",
      "23:32:15\t Answering question <What is the final message of t...>\n",
      "23:32:33\t Analyzing sentiment\n",
      "23:32:48\t Extracting entities from text\n",
      "23:32:49\t Found 13 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/I am not here to take your job,' ChatGPT tells Frankly Speaking host\n",
      "Temporarily storing documents\n",
      "23:33:06 Analyzing file from folder: Will ChatGPT and AI have an impact on Saudi workforce productivity_standardizedlayout.docx\n",
      "23:33:06\t Adding paragraph 1/17 with 32 characters\n",
      "23:33:06\t Adding paragraph 2/17 with 19 characters\n",
      "23:33:06\t Adding paragraph 3/17 with 13 characters\n",
      "23:33:06\t Adding paragraph 4/17 with 19 characters\n",
      "23:33:06\t Adding paragraph 5/17 with 36 characters\n",
      "23:33:06\t Adding paragraph 6/17 with 23 characters\n",
      "23:33:06\t Adding paragraph 7/17 with 11 characters\n",
      "23:33:06\t Adding paragraph 8/17 with 0 characters\n",
      "23:33:06\t Adding paragraph 9/17 with 0 characters\n",
      "23:33:06\t Adding paragraph 10/17 with 0 characters\n",
      "23:33:06\t Adding paragraph 11/17 with 4486 characters\n",
      "23:33:06\t Adding paragraph 12/17 with 0 characters\n",
      "23:33:06\t Adding paragraph 13/17 with 10 characters\n",
      "23:33:06\t Adding paragraph 14/17 with 175 characters\n",
      "23:33:06\t Adding paragraph 15/17 with 175 characters\n",
      "23:33:06\t Adding paragraph 16/17 with 220 characters\n",
      "23:33:06\t Adding paragraph 17/17 with 1990 characters\n",
      "23:33:06\t Create Docx document <Will ChatGPT and AI ...> with content of length 7021\n",
      "23:33:06 Initialized Document: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "23:33:06\t Generating tokenized content\n",
      "23:33:07\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...ning environment.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:33:19\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...arning environment.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "23:33:21\t Generating summary\n",
      "23:33:40\t Finding answer to 4 questions\n",
      "23:33:40\t Answering question <How do the media in this artic...>\n",
      "23:33:56\t Answering question <Which role does or might the A...>\n",
      "23:33:58\t Answering question <Which use cases of Artificial ...>\n",
      "23:34:01\t Answering question <What is the final message of t...>\n",
      "23:34:05\t Analyzing sentiment\n",
      "23:34:17\t Extracting entities from text\n",
      "23:34:17\t Found 16 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity\n",
      "Temporarily storing documents\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_DOCUMENTS:\n",
    "    # Process the documents in the folder where the PDFs are\n",
    "    documents = analyzer.process_folder(FILES_FOLDER, file_types=(\".docx\"))\n",
    "\n",
    "    # Save documents to the output folder\n",
    "    analyzer.save_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:34:32 Initialized Document: <ChatGPT AI grows more powerful as we become more predictable>\n",
      "23:34:32 Initialized Document: <ChatGPT is the Netscape moment' for artificial intelligence'>\n",
      "23:34:32 Initialized Document: <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>\n",
      "23:34:32 Initialized Document: <AI is not smarter than humans>\n",
      "23:34:32 Initialized Document: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "23:34:32 Initialized Document: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "23:34:32 Initialized Document: <I am not here to take your job,' ChatGPT tells Frankly Speaking host>\n",
      "23:34:32 Initialized Document: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n"
     ]
    }
   ],
   "source": [
    "# Load already analyzed documents\n",
    "analyzer.load_documents(os.path.join(OUTPUT_FOLDER, EXPORT_FILE_NAME), load_latest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get insights of all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT AI grows more powerful as we become more predictable\n",
      "Short Summary: The article discusses the rapid advancement of ChatGPT, an AI language model by OpenAI, highlighting its potential in revolutionizing information dissemination but also noting its constrained intelligence and ethical concerns due to potential ideological reinforcement.\n",
      "Summary:\n",
      "1. **Rapid Adoption Rate**: The AI language model ChatGPT, owned by OpenAI, has seen an unprecedented rapid adoption rate within five days of its release, with over a million unique users. 2. **AI as Predictive Tool**: OpenAI's approach to ChatGPT is rooted in the notion that human behavior is predictable, enabling it to make guesses about trends based on large data sets. This reflects the current dominance of algorithm-driven internet usage and smartphone habits. 3. **Limitations of Predictability**: While AI tools can mimic human thought using vast amounts of data, they lack the fundamental ability to reason like humans do. Humans develop language from limited data in a predictable manner, whereas AI systems rely on trends in available data to generate content. 4. **Ethical Concerns**: The quick embrace of AI tools raises ethical issues such as reinforcing ideologies and worldviews without contestation or reflection. This is comparable to recent events involving Microsoft's dismissal of its entire AI ethics team, highlighting the lack of comprehensive ethical parameters in AI development. 5. **AI Imbalance**: ChatGPT and similar tools are unable to balance creativity with constraint, either overgenerating truths or undergenerating exhibiting indifference to consequences. This inability underscores the need for human involvement rather than complete takeover or outsourcing of work. 6. **Collaborative AI Use**: Instead of a hasty transition away from traditional work methods, there's an opportunity to use AI as a collaborator rather than a replacement for the human mind. This perspective aligns with the potential benefits of ChatGPT in enhancing efficiency without replacing human intelligence entirely. 7. **Societal Reflection**: The rapid advancement and enthusiastic embrace of AI, particularly tools like ChatGPT, necessitate society to reflect on how technology is changing human intelligence. It's crucial not to lose sight of the essence of work in the technological age by focusing on incremental AI integration rather than hasty overhauls of traditional methods.\n",
      "Sentiment: -3\n",
      "Entities: ['White Paper Launch', 'Https Microsoft Ethic Society Responsible Ai', 'Miss Vital Point Human Development Impact Society Ethical Issue', 'Serendipitously Stumble Book Know', 'Noam Chomsky', 'Joseph Dana Predictable Ai Tool Lack Fundamental Ability', 'Chatgpt Ai', 'New York Times', 'Openai Approach Chatgpt Notion Human Behavior Predictable Analyze Large', 'Microsoft']\n",
      "Topic clusters: {'AI and Technology Ethics': ['Arabic article 1: Discussion on regulating AI to prevent misuse', 'Article 2: Exploration of ethical guidelines for AI development'], 'Arab Societal Impact of AI': ['Arabic article 3: Analysis of job displacement due to AI automation in the region', \"Article 4: Examination of AI's role in social services and healthcare provision in Arab countries\"], 'AI Regulation and Governance': ['Article 5: Overview of international efforts for AI regulations', 'Arabic article 6: Exploration of national policies on AI use and oversight'], 'AI Bias and Fairness': ['Arabic article 7: Investigation into biases in AI algorithms and their implications', 'Article 8: Discussion on promoting fairness in AI systems across diverse Arab populations']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 15), ('ChatGPT', 12), ('tools', 8), ('human', 8), ('predictable', 6), ('language', 6), ('data', 6), ('OpenAI', 5), ('reason', 5), ('technology', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT AI grows more powerful as we become more predictable/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 12), ('human', 6), ('ChatGPT', 5), ('data', 4), ('tools', 4), ('work', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT AI grows more powerful as we become more predictable/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT by employing metaphors that highlight both the rapid progression and potential implications of this AI technology. These metaphors include describing ChatGPT as 'unlike anything we have ever seen', 'groundbreaking new technology', indicating it's part of an 'AI age', emphasizing its current 'infancy', discussing its predictability, highlighting its limited ability to reason compared to human intelligence, pointing out the superficial and dubious nature of ChatGPT's predictions, valorizing its potential value, expressing concern over hasty adoption, and acknowledging ethical challenges. These metaphors underscore both the advantages and constraints of AI like ChatGPT, urging for thoughtful consideration of societal implications.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases highlighted as potentially beneficial include enhanced communication through improved chatbots like ChatGPT that facilitate cross-cultural interactions and promote understanding among diverse linguistic communities within the Arabic world. Additionally, AI tools could be used to better predict societal trends or user behavior for targeted policy making or personalized services in regions with high internet penetration and digital literacy.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message is about cautious yet inclusive integration of AI technologies, emphasizing their limitations in understanding context or reasoning compared to human intelligence.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT is the Netscape moment' for artificial intelligence'\n",
      "Short Summary: The article portrays ChatGPT as a 'Netscape moment' for AI, emphasizing its conversational prowess powered by LLMs, while highlighting the limitations in understanding, common sense, and reasoning, potentially leading to misinformation and harm.\n",
      "Summary:\n",
      "1. **ChatGPT's Impact**: ChatGPT has generated significant excitement, comparable to Netscape making the World Wide Web real in its time. It is a Large Language Model (LLM) built on unsupervised learning, capable of generating responses similar to autocomplete but with broader conversational abilities. 2. **Applications and Benefits**: Global law firms are exploring ways to use ChatGPT for automatic contract creation, while AI-generated content is raising concerns about plagiarism and misinformation. LLMs can be enriched and extended using domain-specific data, offering new value in business applications. 3. **Current Limitations**: Despite their effectiveness, LLMs lack understanding of the world, common sense, and reasoning capabilities, making them prone to generating false or misleading information through \"hallucinations\". 4. **Future Evolution**: AI will continue to evolve rapidly with advancements in foundation models that can be trained once and reused broadly at minimal marginal cost. These models leverage rules of physics or ethics, bridging the gap between machine-generated text and human thought processes. 5. **Role as a Tool**: LLMs can assist humans in near-instantaneous tasks like object recognition or sentence parsing, while also enabling conscious and logical decision-making that surpasses their current capabilities. 6. **AI's Impact on Labor Markets**: As labor costs rise due to inflationary pressures and a rapidly aging population, AI can increase productivity by automating tasks previously performed by humans. This could lead to both deflation in specific sectors and overall economic sustainability for developed nations like Saudi Arabia. 7. **Saudi Arabia's Advantage**: With a strong emphasis on data-driven AI, extensive efforts to train local talent, and significant investments from national champions like Aramco in developing regional AI capabilities, the Kingdom is well-positioned to capitalize on these opportunities. The localization of LLMs to regional languages and dialects, combined with leveraging domain knowledge, can further enhance Saudi Arabia's competitive edge in AI adoption.\n",
      "Sentiment: 0\n",
      "Entities: ['Chatgpt', 'Technologist Investment Program', 'Saudi Arabia Develop Country Face Demographic Challenge', 'Saudi Public Private Sector Entity Encourage Explore Technology Create New Value Respective Field Industry', 'Anthony Butler', 'Focus Application Artificial Intelligence Blockchain Metaverse Technology Large']\n",
      "Topic clusters: {'AI Ethics & Society Impact': ['Unsupervised Learning', 'Word Understanding', 'Reasoning Limitations', 'Plagiarism Prevention', 'Misinformation Generation'], 'Advancements in AI Technology': ['ChatGPT', 'Domain-Specific Learning', 'Foundation Models'], 'Societal Changes due to AI': ['Demographic Shifts']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 13), ('models', 8), ('ChatGPT', 6), ('example', 6), ('new', 5), ('words', 5), ('Saudi', 5), ('artificial', 4), ('text', 4), ('sense', 4)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the Netscape moment' for artificial intelligence'/wordcloud_content.png\"}, 'summary': {'word_frequencies': [('AI', 7), ('LLMs', 4), ('ChatGPT', 3), ('generated', 3), ('making', 3), ('capabilities', 3), ('like', 3), ('Saudi', 3), ('Arabia', 3)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the Netscape moment' for artificial intelligence'/wordcloud_summary.png\"}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this text frames the public discussion about ChatGPT using metaphors such as 'Netscape moment' describing its impact like Netscape did for the World Wide Web , 'Large Language Model LLM ' comparing them to autocomplete on steroids , 'AI and panicked university officials' depicting ethical concerns about AI tools enabling misinformation , and 'generative AI tools will enable...highly plausible misinformation' emphasizing potential dangers . These metaphors help frame the discussion as transformative yet potentially problematic.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\t1. Legal and contractual automation ChatGPT-like models help automate creating contract skeletons in law firms, reducing reliance on legal staff. 2. Emergence of foundation models Foundation models can be trained once and extended for specific industries or regions, like the energy sector in Saudi Arabia.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe author emphasizes that AI's transformative power should be harnessed alongside augmentation with human-like reasoning, knowledge, and ethical understanding. The article underscores the need to address ChatGPT's current limitations and integrate these advanced models into systems capable of conscious decision-making.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT outperforms copywriters in STEP Conference's outdoor adverts\n",
      "Short Summary: The article highlights how the STEP Conference incorporates ChatGPT, an AI tool developed by OpenAI, into outdoor ad campaigns to boost team efficiency, sparking discussions on the evolving role of human creative professionals in an era marked by advanced AI tools.\n",
      "Summary:\n",
      "1. ChatGPT has been successfully used by Dubai's tech festival STEP Conference for creating outdoor advertisements, resulting in better taglines and more efficient content creation processes. 2. The company plans to continue using the AI tool for various content-related tasks such as summarizing, explaining, and writing copy across teams. 3. ChatGPT is perceived by the team as an AI assistant that enhances efficiency rather than replacing human creativity entirely. 4. While acknowledging AI's capacity to create more jobs than it erases (based on forecasts from reports), Dargham expresses concerns about job displacement due to advanced AI tools like ChatGPT, particularly in roles such as copywriting. 5. The use of AI chatbots and other similar tools is expected to intensify, potentially impacting various job sectors, including creative industries. 6. Dargham believes that while some jobs may be replaced by AI, human talent will find more productive roles elsewhere in the workforce. 7. ChatGPT and similar tools are envisioned to both complement and possibly replace certain tasks currently performed by humans, highlighting the evolving nature of job roles with advancements in artificial intelligence.\n",
      "Sentiment: 3\n",
      "Entities: ['Dargham']\n",
      "Topic clusters: {\"Arab news articles discussing ChatGPT and AI's impact on society:\": ['ChatGPT, an advanced language model developed by OpenAI', 'Potential consequences of AI in the workplace due to ChatGPT usage', 'Ethical considerations in developing AI systems like ChatGPT', 'The role of human creativity and intelligence in a world dominated by AI', 'AI-driven technology advancements could influence education systems']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 10), ('STEP', 7), ('ChatGPT', 6), ('like', 6), ('team', 5), ('Dargham', 5), ('outdoor', 4), ('company', 4), ('use', 4), ('agency', 4)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference's outdoor adverts/wordcloud_content.png\"}, 'summary': {'word_frequencies': [('AI', 6), ('ChatGPT', 4), ('job', 3), ('tools', 3), ('roles', 3)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference's outdoor adverts/wordcloud_summary.png\"}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT using several metaphors 'Artificial intelligence tool', 'brain behind outdoor adverts', 'controversial OpenAI tool', 'existential threat to creative industries', 'AI creates more jobs than it erases', and 'AI tools complement and replace human talent'. These metaphors shape the discourse, reflecting a mix of admiration, concern, optimism, and debate about ChatGPT's role in society.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe article highlights two significant use cases for Artificial Intelligence in the Arabic world 1 using ChatGPT for creating outdoor adverts that are more engaging with local humor and taglines, thus benefiting marketing efforts. This implementation suggests potential applications in other creative fields like advertising and branding across the region. 2 Leveraging AI tools such as ChatGPT to assist teams in managing content production needs, including writing session briefs, creating social posts, and general copywriting. These use cases demonstrate how AI can improve efficiency and productivity within Arabic creative industries.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI tools like ChatGPT will complement human talent, enhancing efficiency and creativity without replacing it.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: AI is not smarter than humans\n",
      "Short Summary: The article underscores apprehensions about AI's capacity to grasp complex human emotions, acknowledging its role in task automation but highlighting limitations in comprehending intricate cultural contexts and nuances without genuine human interaction.\n",
      "Summary:\n",
      "1. The article begins by discussing an instance where Microsoft's chatbot named Tay was corrupted into spewing racist messages within 16 hours after its release on Twitter due to user negativity, highlighting potential risks of AI. 2. It describes the author's positive experience with AI-powered tools like ChatGPT and Siri, praising their ability to enhance personal life and business tasks by providing solutions for various needs such as reminders, brainstorming ideas, and more. 3. The author attributes this success partly to the engineers who developed these AI applications, emphasizing the importance of technological advancements in daily lives. 4. Reflecting on personal use of Siri, the author mentions how it boosted their self-confidence in expressing thoughts and ideas, demonstrating AI's potential for aiding communication skills. 5. The article acknowledges AI's evolutionary progress from simple yes/no responses to more sophisticated capabilities like generating marketing campaigns or composing personal messages, but cautions about its limitations, such as understanding cultural nuances and capturing the emotional essence of human experiences. 6. The author stresses that while AI can be a powerful tool in business operations and marketing, it cannot fully replace the essential human connection, emphasizing that AI is more useful for simplifying workloads and providing innovative ideas rather than replacing personal interactions. 7. The text concludes by expressing optimism about AI's potential to bridge language barriers through technology like Google Translate, but reiterates its belief that no matter how advanced AI becomes, it will never replace the unique value of human connection and expression.\n",
      "Sentiment: -3\n",
      "Entities: ['Real Life Recruiter Marketer', 'Ai Smart', 'Grace Business Operation Marketing Department Include Computer Understand Like Culture', 'Kid Singe', 'Offer Simple', 'National Anthem Look Flag']\n",
      "Topic clusters: {'AI Capabilities & Impact': ['Artificial Intelligence advancements', \"ChatGPT's functionality and applications\"], 'Impact on Society': ['Positive effects (e.g., increased efficiency, new job opportunities)', 'Negative consequences (e.g., potential job displacement, privacy concerns)']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 10), ('technology', 8), ('marketing', 6), ('like', 5), ('business', 4), ('humans', 3), ('released', 3), ('experience', 3), ('able', 3), ('ideas', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 9), ('author', 4), ('personal', 4), ('potential', 3), ('like', 3), ('ideas', 3), ('human', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT by using several metaphors that highlight AI's capabilities and limitations. It underscores that ChatGPT is not smarter than humans, acknowledges its potential benefits as an advocate for technology, emphasizes human ingenuity in creating AI, points out its developmental infancy, and explores the limits of AI in understanding nuanced aspects like culture and emotions.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases of AI mentioned that are helpful for the Arabic world include chatbots virtual assistants like Apple's Siri, AI tools for brainstorming in marketing and business operations, and language translation services like Google Translate. These applications aim to facilitate better communication, enhance productivity, and foster cultural understanding within the Arabic community.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI is an incredible tool that can simplify tasks and inspire creativity, yet it should not be considered superior to humans. It enhances life but cannot replace the depth and nuance of human interaction.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: No need to demonize ChatGPT but AI regulation is a must\n",
      "Short Summary: The article highlights ChatGPT's integration into Saudi Arabian journalism, noting its transformative impact and challenges such as job displacement concerns, with calls for responsible regulation.\n",
      "Summary:\n",
      "1. **ChatGPT as an AI tool**: Developed by OpenAI, ChatGPT is a large language model capable of understanding and generating human-like text based on the input it receives. It can write essays, articles, research papers, reports, poetry, explain complex scientific concepts in simple language, and even generate recipes. 2. **Impact on Journalism**: In Saudi Arabia, ChatGPT is being used to enhance news production and consumption. It has the potential to revolutionize journalism by automating repetitive tasks such as drafting headlines or summarizing long articles, allowing human journalists to focus more on in-depth reporting and analysis. 3. **Opportunities vs Risks**: The integration of ChatGPT into journalism presents both opportunities and risks. Opportunities include increased efficiency, cost reduction, and the ability to generate content at a faster pace. However, risks involve job displacement for human journalists who may struggle with the automation, potential loss of editorial judgment, and ethical concerns surrounding AI-generated news. 4. **Educational Impact**: The advent of ChatGPT is causing significant shifts in education. Teachers are exploring new methods to detect AI-generated text (like GPTZero) as a means to protect original work. There's a fear that human teachers might be replaced by AI, but proponents argue it could empower all learners globally by providing equal access to knowledge and resources. 5. **Threats in Specific Fields**: In medical fields, ChatGPT has passed the US Medical Licensing Examination experiments. This raises concerns about potential displacement of human doctors who may not have access to advanced AI systems for diagnosis and decision-making. However, it's noted that AI is more likely to augment rather than replace human roles in this industry. 6. **Limitations and Ethical Concerns**: Despite its capabilities, ChatGPT isn't perfect. It can make mistakes, struggles with nuanced prompts, and generates content from outdated information. While it has safeguards against producing harmful or inappropriate responses, ethical dilemmas persist regarding AI-generated art and literature. 7. **Need for Regulations**: Given the potential impacts on various professions, there's a need for regulations to ensure that AI like ChatGPT benefits humanity without causing significant job losses or societal disruption. The goal should be an 'equalizer' rather than a threat, leveraging AI's power to empower everyone.\n",
      "Sentiment: 0\n",
      "Entities: ['Accord Axios Chatgpt', 'Seattle Public School System Quickly Ban University College Fear Ban Ineffective Raise Question Academic Freedom Busy Try Contain Chatgpt Potentially Negative Impact Education Change Mode Instruction Give Oral Exam Handwritten', 'New Technology Chatgpt View', 'Washington Post Article Write Chatgpt See Lucid Different Write Human Post Consider Experiment Journalistic Disaster', 'New York Times', 'Newsroom', 'Chatgpt Midjourney Ai Program']\n",
      "Topic clusters: {'AI Ethics in Arab Societies': ['ChatGPT', 'Artificial Intelligence impacts on society', 'Ethical concerns about AI'], 'Arabic Media Coverage of ChatGPT': ['Introduction to ChatGPT', 'Comparative analysis with other AI tools', 'Perceptions and opinions from the Arab audience']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('ChatGPT', 27), ('AI', 24), ('human', 7), ('technology', 6), ('world', 5), ('generated', 5), ('field', 4), ('language', 4), ('news', 4), ('written', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 9), ('ChatGPT', 8), ('human', 6), ('potential', 4), ('like', 3), ('generated', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tdisruption\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tChatGPT can aid journalism by generating news content quickly and accurately, assist in education through new teaching methods, potentially impact the medical field by augmenting human work rather than replacing doctors, and contribute to literature with its ability to write and illustrate books.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI has the potential to revolutionize various fields, but it's crucial to manage its development responsibly to prevent job displacement and maintain societal balance.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: Is the Arab world ready for the uncertain age of AI-powered web tools\n",
      "Short Summary: The article discusses the dual-use nature of AI technologies like ChatGPT, highlighting both benefits content creation, business assistance and potential risks job displacement, privacy concerns, misinformation , while emphasizing the importance of trust in AI development for responsible application.\n",
      "Summary:\n",
      "1. The advent of advanced artificial intelligence (AI) systems, like ChatGPT, is indeed sparking a mix of optimism and anxiety worldwide. These sophisticated language models, trained on vast amounts of text data, can generate human-like text in response to a wide range of prompts, making them incredibly useful tools for content creation across various sectors. 2. On the positive side, AI like ChatGPT offers numerous benefits. For instance, it can assist media professionals by generating news articles, summaries, and responses to customer inquiries. It simplifies complex tasks, providing a quick solution for journalists and marketers alike. Moreover, large language models (LLMs) used in AI systems are continually learning from new data, improving their performance over time. 3. However, there are significant concerns about the use of such technology, particularly regarding its potential to replace human roles entirely. While ChatGPT acknowledges its own creative and analytical limitations, it also asserts that it's designed to assist in content creation rather than replacing human writers. This reassurance comes from AI itself, highlighting the delicate balance between optimism and pessimism about AI's future impact on employment. 4. The integration of AI into various industries, including education, raises additional challenges. For example, universities like Sciences Po have implemented strict rules against using ChatGPT for exams to prevent cheating due to its ability to generate realistic-looking but inaccurate responses. Similarly, some companies are marketing programs that can detect AI-generated text, creating a new form of digital deception. 5. Moreover, the use of AI in sensitive areas like healthcare and law raises ethical dilemmas. For instance, while ChatGPT could assist medical diagnosis by summarizing patient records or providing preliminary insights, it might also provide incorrect information due to its lack of human intuition or personal insight. 6. The trust factor is crucial for the safe expansion of AI solutions globally. As noted by Dr. Scott Nowson from PwC Middle East, AI's use should be contingent upon human intelligence and awareness. Despite the immense investment potential—forecasts value AI in the trillions of dollars—the age of AI remains fraught with anxiety due to its creative and analytical limitations compared to human capabilities. 7. In conclusion, while advanced AI technologies like ChatGPT present exciting opportunities for efficiency and innovation across various sectors, they also introduce new challenges that need careful navigation. Striking the right balance between embracing AI's potential and preserving human roles remains a pressing concern for policymakers, educators, and industry leaders alike.\n",
      "Sentiment: 300\n",
      "Entities: ['Linkedin Co', 'Burrell Say', 'Research Data Society Independent Non Profit Research Organization Base California Say People Need Chatgpt', 'Reid Hoffman', 'Multinational Tech Corporation Microsoft', 'Sam Altman Year', 'Omar Sultan Al Olama Take', 'Noaman Sayed', 'Chatgpt Spur Google Management', 'Arab News Leap Technology Conference', 'James Webb', 'Peter Thiel Tesla', 'Elon Musk Serve Start Board', 'Initial Investment Firm Worth Billion Billion Mean Company Value', 'Sciences Po School Paris', 'Jenna Burrell', 'Spearhead Uae Expand Digital Economy Middle East Project', 'Dan Milmo Alex Hern Tech', 'Marketing Professional Redundant Technology', 'Uk Guardian Newspaper Say']\n",
      "Topic clusters: {'Artificial Intelligence (AI) Impact on Society': ['<ChatGPT>', 'Effects of AI on job markets', 'Economic implications of AI advancements', 'Privacy concerns in the age of AI'], 'Misinformation and Disinformation': ['<ChatGPT> as a source of information', 'AI-generated deepfakes', 'Ethical guidelines for AI communication'], 'Regulation and Ethics': ['Role of regulatory bodies in AI governance', 'Ethical considerations in AI development', 'Balancing innovation and societal impact']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 25), ('ChatGPT', 17), ('said', 9), ('human', 8), ('Google', 8), ('Arab', 6), ('web', 6), ('intelligence', 6), ('OpenAI', 6), ('billion', 6)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 14), ('human', 7), ('like', 6), ('ChatGPT', 6), ('text', 3), ('assist', 3), ('new', 3), ('use', 3), ('potential', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe metaphors used by the media include simplifying complexity the tool model that makes complex tasks simpler , describing ChatGPT's abilities in terms of pattern-matching 'machine for matching patterns' , and highlighting its limitations when compared to human capabilities. These metaphors help frame public discussions about ChatGPT, emphasizing its usefulness as a pattern-matching machine while acknowledging the uniqueness and potential of human creativity and understanding.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tPotential\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tContent Creation and Writing Assistance, Education with human oversight , Language Translation\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI's integration into society must be guided by human intelligence and awareness, with careful consideration to avoid over-reliance on automation.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: I am not here to take your job,' ChatGPT tells Frankly Speaking host\n",
      "Short Summary: The article is about ChatGPT, an AI language model by OpenAI, detailing its capabilities in facilitating translation, information access, and task assistance while addressing concerns of privacy, bias, job displacement, and the need for ethical use.\n",
      "Summary:\n",
      "ChatGPT, an advanced language model developed by OpenAI, was interviewed by Arab News regarding its role, features, and potential impact. Here are the key points from the discussion: 1. **Role and Function**: ChatGPT is designed to assist in providing information and responding to questions based on patterns it has learned from a vast amount of text data. It's not capable of independent thought or decision-making but can generate human-like text responses. Its role involves facilitating communication, promoting understanding between people of different backgrounds, and potentially enhancing various applications such as language translation and personalized content generation. 2. **Features and Improvements**: ChatGPT's naturalness and sophistication in AI-generated text are expected to be improved upon with upcoming updates like GPT-4. These enhancements may include generating more diverse and expressive language, incorporating elements of emotion and personality into responses, and developing better contextual understanding for personalized user experiences. 3. **Ethical Considerations**: Given its potential impact on society, ChatGPT acknowledges the responsibility that comes with its use. It emphasizes that the outcome will largely depend on how developers, policymakers, and users choose to utilize AI technology ethically. Both positive and negative outcomes are possible, but it is crucial for all parties involved to address concerns related to privacy, bias, and job displacement in a responsible manner. 4. **Future Development**: ChatGPT sees itself as one tool among many that can contribute positively to humanity's future. It hopes its capabilities will be utilized to improve healthcare, education, communication, and other areas where it can facilitate greater understanding or efficiency. In essence, ChatGPT views itself as a tool with great potential for beneficial applications in our increasingly digital world, but it also underscores the importance of responsible use and ethical considerations to ensure AI technology aligns with humanity's best interests.\n",
      "Sentiment: 3\n",
      "Entities: ['Focus Develop Ai Model Context', 'Manner Chatgpt Say Important', 'Task Automate Ai', 'Katie Jensen', 'Saudi Arabia Say Chatgpt Provide News Analysis Local Regional International Event Reputation Provide Accurate Timely Comprehensive News Coverage', 'Say Response Base Solely', 'Sam Altman', 'Ai Facilitate', 'Focus Effort Near Future Area Focus Improve Naturalness Sophistication', 'Initial Investment Firm Billion Billion Windows Maker', 'Generative Ai Live Reputation Produce Human Like', 'Innovation Evolution Field Year', 'Microsoft']\n",
      "Topic clusters: {'Artificial Intelligence Applications': ['ChatGPT', 'AI-powered language models'], 'Societal Impacts of AI': ['Transparency and accountability concerns', 'Job displacement due to automation'], 'Ethical Considerations in AI': ['Bias in AI systems', 'Privacy issues'], 'AI Regulation': ['International and national regulations for AI development and usage']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 37), ('data', 28), ('ChatGPT', 26), ('language', 24), ('training', 17), ('said', 17), ('responses', 15), ('job', 11), ('technology', 11), ('human', 10)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/I am not here to take your job,' ChatGPT tells Frankly Speaking host/wordcloud_content.png\"}, 'summary': {'word_frequencies': [('ChatGPT', 6), ('language', 3), ('potential', 3), ('text', 3), ('understanding', 3), ('AI', 3)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/I am not here to take your job,' ChatGPT tells Frankly Speaking host/wordcloud_summary.png\"}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT by employing metaphors that highlight its potential, risks, and the responsibility associated with its use. These metaphors include 'AI language model', 'tool with immense potential but also risks', 'force for good or ill', and emphasizing the need for responsible and ethical usage.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tBeneficial use cases of Artificial Intelligence for the Arabic world include language translation capabilities, which promote better understanding and interaction between different communities. This can be particularly valuable in fostering cultural exchange, facilitating education, and enhancing international business relations.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI technology can be harnessed responsibly to foster progress, but it requires careful use and ethical regulation.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: Will ChatGPT and AI have an impact on Saudi workforce productivity\n",
      "Short Summary: The article highlights how ChatGPT and other AI technologies can enhance Saudi Arabia's workforce productivity through customized training, collaboration tools, and personalized services across sectors like healthcare, transportation, energy, finance, and retail. Simultaneously, it acknowledges the risk of job displacement due to automation, advocating for a strategic approach in AI integration that aligns with organizational goals and cultivates an enabling learning environment.\n",
      "Summary:\n",
      "1. **AI Technologies Boost Productivity**: ChatGPT and other artificial intelligence platforms are creating a wave of change in the global workforce, serving as a useful tool for Saudi Arabia's personnel to boost economic development by enhancing productivity. 2. **Alleviating Employee Fears**: Despite concerns about AI replacing manpower with robots and software, experts like Raymond Khoury at Arthur D. Little have alleviated these fears by emphasizing the potential benefits of embracing innovation through AI. 3. **Nurturing Talent with AI Culture**: Implementing AI technologies requires a strong human dimension to successfully embed it into operations, promoting an AI culture that encourages experimentation, learning, and collaboration among employees. 4. **AI Impact on Career-Related Skills**: ChatGPT can positively impact various aspects of career-related skills in talent management, including recruitment, training, upskilling, reskilling, talent collaboration, and knowledge management. 5. **Enhancing Employee Productivity**: AI, specifically ChatGPT, can provide tailor-made training programs for employees, access to customized online courses, and foster team collaboration, leading to increased productivity within organizations due to less time spent on mundane tasks. 6. **AI Impact Across Sectors**: The impact of AI will extend across sectors like public sector, healthcare, transportation, energy, finance, and retail in Saudi Arabia, offering opportunities for more efficient operations, better service delivery, and growth. 7. **Potential Risks**: While AI offers numerous benefits, it also presents risks such as job displacement due to automation of repetitive tasks, potentially threatening employee stability. To mitigate this, workers need to acquire new skills through retraining or upskilling to remain marketable in the evolving digital world. 8. **Strategic Approach**: Embedding AI into organizations' operations requires a holistic approach that clearly defines strategic objectives, advantages, and disadvantages. This involves understanding operational bottlenecks, selecting appropriate AI tools or technologies, and fostering an environment of learning and improvement to ensure success in the rapidly changing technological landscape. 9. **Leadership and Agility**: Implementing AI necessitates solid leadership, a forward-thinking perspective, agility in making timely changes, and proactive adaptation as needed by the organization. 10. **Positive Employee and Client Experience**: To successfully integrate AI into organizations' operations, it's crucial to foster an optimistic environment that encourages employee learning and client interaction improvement.\n",
      "Sentiment: 0\n",
      "Entities: ['Raymond Khoury', 'Foster Collaboration Communication Team', 'Chatgpt Ai', 'Arthur Littlehe Add Ai', 'Chatgpt Ai Impact Saudi Workforce', 'Task Automate', 'Flip Khoury', 'Embed Ai Operation Saudi Company Employee Require Holistic Approach Clearly Define Strategic Objective Advantage Disadvantage Kaspersky Survey Support', 'Arthur', 'Cairo Chatgpt Artificial Intelligence Platform Create Wave Change Global Workforce Turn Useful Tool Saudi Arabia Personnel Boost Economic Development Ai Raise Concern', 'Khoury', 'Regard Energy Sector Innovative Technology']\n",
      "Topic clusters: {'Artificial Intelligence Technologies': ['AI technologies', 'ChatGPT'], 'Productivity Boost': ['productivity boost'], 'Advantages Identification': ['identification of advantages'], 'Disadvantages Assessment': ['disadvantages assessment']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 34), ('Khoury', 15), ('ChatGPT', 12), ('employees', 11), ('impact', 9), ('technologies', 6), ('operations', 6), ('said', 6), ('workers', 6), ('Saudi', 5)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 15), ('operations', 4), ('ChatGPT', 3), ('Employee', 3), ('learning', 3), ('collaboration', 3), ('organizations', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tIn this article, the media frames the public discussion about ChatGPT primarily by portraying it as a transformative force driving productivity and economic development in Saudi Arabia. The metaphors used to describe AI and its impact are 1. **Wave of Change** This framing emphasizes that AI, including ChatGPT, is ushering in significant shifts and transformations within the workforce. 2. **Useful Tool for Economic Development** The article highlights how AI can be leveraged to boost economic growth by enhancing productivity e.g.,\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tChatGPT and other AI platforms like ChatGPT have the potential to significantly enhance productivity within Saudi Arabian companies. By automating repetitive tasks, they enable employees to focus more on strategic activities. This can be seen in areas such as recruitment, training, upskilling, reskilling, and knowledge management where ChatGPT provides personalized training programs and fosters collaboration among team members.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message is a balanced view emphasizing the potential benefits of AI integration for productivity enhancement, while also acknowledging the need for proactive adaptation and skill development from both organizations and employees.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of every loaded file (Optional: with markings)\n",
    "for doc in analyzer:\n",
    "    #analyzer.create_wordcloud(doc,wordcloud_names=[\"markings\", \"content\", \"summary\"])\n",
    "    #doc.summary = llm.generate_summary(doc.content)\n",
    "    #result = llm.analyze_sentiment(doc.content))\n",
    "    #result = doc.sentimentsd\n",
    "\n",
    "    doc.content = analyzer.clean_input(doc.content)\n",
    "    doc.content_tokens = analyzer.get_tokens(doc.content)\n",
    "    #doc.sentiment = result.get(\"sentiment_value\")\n",
    "    #doc.sentiment_reason = result.get(\"sentiment_reason\")\n",
    "    print(doc.get_info(), end=\"\\n\"+\"- \"*50+\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Stores an updates version of the documents\n",
    "#analyzer.save_documents(analyzer.all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the files as word-docx and markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export docx files with wordclouds\n",
    "analyzer.export_docx_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a markdown file for every document\n",
    "analyzer.export_markdown_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply latent dirichlet allocation algorithm\n",
    "Algorighm selects all topics out of the articles. LLM then adds a title that summarizes the topics into categories. \n",
    "\n",
    "Thereby, all different topics can be extracted out of **all** documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_decay=0.5, n_components=5, n_jobs=-1,\n",
       "                          random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(learning_decay=0.5, n_components=5, n_jobs=-1,\n",
       "                          random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_decay=0.5, n_components=5, n_jobs=-1,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the content of all documents\n",
    "all_content_tokens = [doc.content_tokens for doc in analyzer.all_documents]\n",
    "\n",
    "\n",
    "# Create a document-term matrix\n",
    "max_df = 0.8   # means \"ignore terms that appear in more than 90% of documents\".\n",
    "min_df = 0.1  # means \"ignore terms that appear in less than 20% documents\".\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2) # Capture multi-word expressions\n",
    ")\n",
    "doc_term_matrix = vectorizer.fit_transform(all_content_tokens)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=5, learning_method=\"batch\", random_state=42, n_jobs=-1, learning_decay=0.5)\n",
    "lda.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 - AI-Driven Medical Threat Analysis & Reporting - Team Response Unveiled:\n",
      "Features: generate, question, ai tool, step, report, need, threat, medical, raise, team, field, article, explain, fear, accord\n",
      "Topic 1 - Breaking Boundaries: Google & OpenAI-Fueled Text Analysis Revolution:\n",
      "Features: say, google, answer, chatbot, billion, arab, openai, search, web, text, tech, base, people, way, program\n",
      "Topic 2 - Linguistic AI Tool: Large-Scale Predictability in Saudi Context, Trained on Word Examples.:\n",
      "Features: model, language, ability, ai tool, example, reason, large, time, predictable, word, development, platform, saudi, point, train\n",
      "Topic 3 - Language Analysis in Job Training: Unveiling Khoury's Language Model Impact on Employee News Response:\n",
      "Features: language, say, job, training, impact, response, model, training datum, khoury, language model, employee, news, provide, information, source\n",
      "Topic 4 - Microsoft's Pioneering Think-Powered Life-Enhancing Tool Boosts Realization and Efficiency:\n",
      "Features: think, recent, great, realize, feel, microsoft, tool like, save, initially, life, powerful, look, increase, lack, useful\n"
     ]
    }
   ],
   "source": [
    "# Function to generate unique topics\n",
    "def get_unique_topics(model, vectorizer, top_n=10):\n",
    "    unique_topics = {}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        # Get the top features for the topic\n",
    "        top_features = tuple(vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-top_n - 1:-1])\n",
    "        \n",
    "        # Use the tuple as a key to ensure uniqueness\n",
    "        if top_features not in unique_topics:\n",
    "            unique_topics[top_features] = idx\n",
    "\n",
    "    return unique_topics\n",
    "\n",
    "# Generate a title for each unique topic\n",
    "def generate_topic_titles(llm, unique_topics):\n",
    "    titles = {}\n",
    "    \n",
    "    for features, idx in unique_topics.items():\n",
    "        # Create a prompt with the top features\n",
    "        prompt = (\n",
    "            \"You are tasked with creating a concise, descriptive title for a topic derived from text analysis. \"\n",
    "            \"The title should reflect the general theme or idea represented by the following features. \"\n",
    "            \"Avoid listing all feature names explicitly, and ensure the title is engaging and informative. \"\n",
    "            \"Aim for a maximum of 5 words. Here are the features: \"\n",
    "            f\"{', '.join(features)}\"\n",
    "        )\n",
    "        \n",
    "        # Use the LLM to generate a title\n",
    "        response = llm.ollama.generate(model=llm.model, prompt=prompt)\n",
    "        titles[idx] = response[\"response\"].split(\"\\n\")[0]\n",
    "    return titles\n",
    "\n",
    "\n",
    "# Get unique topics and their titles\n",
    "unique_topics = get_unique_topics(lda, vectorizer, top_n=15)\n",
    "topic_titles = generate_topic_titles(llm, unique_topics)\n",
    "\n",
    "\n",
    "analyzer.analysis[\"LDA\"] = {topic_titles[idx].replace('\"', \"\"): topics for idx, topics in zip(topic_titles, unique_topics)}\n",
    "\n",
    "# Print unique topics and their generated titles\n",
    "for idx, (title, topics) in enumerate(analyzer.analysis[\"LDA\"].items()):\n",
    "\n",
    "    print(f\"Topic {idx} - {title}:\")\n",
    "    print(f\"Features: {', '.join(topics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Term frequency inverse term frequency\n",
    "This model iterates over each document and returns those words, that do not appear often in other documents. The top n words are then used to create a topic for every article!\n",
    "\n",
    "- A high TF-IDF score (FROM_LOW_TO_HIGH = False) indicates that a word is both important within a document and rare across all document.\n",
    "- A low TF-IDF score suggests that a word is either common in the document but rare overall, or vice versa.\n",
    "\n",
    "By analyzing TF-IDF scores for a set of words, you can identify:\n",
    "Important keywords in a document\n",
    "Rare or unique words that distinguish one document from another\n",
    "Words with varying levels of importance across different documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 1572\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 1572\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 5803\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 5803\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 10428\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 10428\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 586\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 586\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 821\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 821\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 928\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 928\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 278\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 278\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 310\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 310\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 316\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 316\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 1582\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 1582\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 5813\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 5813\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 10438\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 10438\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 596\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 596\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 831\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 831\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 938\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 938\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 288\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 288\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 320\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 320\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 326\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 326\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 1590\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 1590\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 5822\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 5822\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 10447\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 10447\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 604\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 604\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 840\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 840\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 947\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 947\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 296\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 296\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 329\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 329\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 335\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 335\n",
      "\n",
      "Best Parameters: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}\n",
      "Best Vocabulary Size: 10447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import product\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_df': [0.8, 0.9, 1.0],\n",
    "    'min_df': [1, 2, 3],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'norm': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# Initialize variables to store the best combination and vectorizer\n",
    "best_params = None\n",
    "best_vectorizer = None\n",
    "best_vocab_size = 0  # Use vocabulary size as a proxy for quality\n",
    "\n",
    "# Iterate over all combinations of parameters\n",
    "for params in product(*param_grid.values()):\n",
    "    # Map parameter combinations to their names\n",
    "    params_dict = dict(zip(param_grid.keys(), params))\n",
    "    \n",
    "    # Create and fit the TfidfVectorizer with the current parameters\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_df=params_dict['max_df'],\n",
    "        min_df=params_dict['min_df'],\n",
    "        ngram_range=params_dict['ngram_range'],\n",
    "        norm=params_dict['norm']\n",
    "    )\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_content_tokens)\n",
    "    \n",
    "    # Evaluate based on vocabulary size\n",
    "    vocab_size = len(vectorizer.get_feature_names_out())\n",
    "    print(f\"Params: {params_dict}, Vocabulary Size: {vocab_size}\")\n",
    "    \n",
    "    # Track the best combination\n",
    "    if vocab_size > best_vocab_size:\n",
    "        best_vocab_size = vocab_size\n",
    "        best_params = params_dict\n",
    "        best_vectorizer = vectorizer\n",
    "\n",
    "# Print the best parameters and corresponding vocabulary size\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(\"Best Vocabulary Size:\", best_vocab_size)\n",
    "\n",
    "# Use the best vectorizer to transform the data\n",
    "tfidf_matrix = best_vectorizer.transform(all_content_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 terms for Document 1: <ChatGPT AI grows more powerful as we become more predictable>\n",
      "\"AI-Powered Language Model Development: Ethical Implications for Government and Industry\" \n",
      " ai tool, language, development, openai, work, change, use, ability, chatgpt ai, produce, model, time, large, set, think\n",
      "\n",
      "Top 15 terms for Document 2: <ChatGPT is the Netscape moment' for artificial intelligence'>\n",
      "\"Leveraging Saudi Language Modeling: Challenges, Research, and Progress in Natural Language Development\" \n",
      " model, example, train, text, saudi, word, generate, language, value, challenge, require, research, base, point, learn\n",
      "\n",
      "Top 15 terms for Document 3: <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>\n",
      "\"AI Chatbot: Job Transformation & Global Knowledge Network Expansion\" \n",
      " job, chatbot, ai tool, use, need, explain, think, easy, continue, replace human, add, say, make, look, tell\n",
      "\n",
      "Top 15 terms for Document 4: <AI is not smarter than humans>\n",
      "\"Microsoft's Chatbot: Language Skill Realization, User Engagement in Marketing\" \n",
      " marketing, business, help, release, time, example, think, chatbot, serve, user, microsoft, negative, ability, language, set\n",
      "\n",
      "Top 15 terms for Document 5: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "\"OpenAI's Language Model: Potential Impact on Education and Knowledge Sharing\" \n",
      " generate, question, field, accord, article, fear, raise, report, read, work, program, people, news, language, text\n",
      "\n",
      "Top 15 terms for Document 6: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "\"Language Model by Google: Investment in Arab News, Job Opportunities and Global Impact\" \n",
      " say, chatbot, google, answer, text, arab, openai, people, base, way, question, program, investment, train, job\n",
      "\n",
      "Top 15 terms for Document 7: <I am not here to take your job,' ChatGPT tells Frankly Speaking host>\n",
      "\"OpenAI's Large Language Model: A News-Inspired Work Task for Potential Internet Users\" \n",
      " job, language, response, say, model, language model, news, provide, information, include, impact, text, large, generate, arab news\n",
      "\n",
      "Top 15 terms for Document 8: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "\"AI-Driven Workforce Transformation: Skill Demands and Global Opportunities\" \n",
      " impact, say, workforce, require, believe, saudi, add, chatgpt ai, explain, change, opportunity, ai tool, need, sector, skill\n"
     ]
    }
   ],
   "source": [
    "# Create a TfidfVectorizer object\n",
    "min_df = int(len(analyzer.all_documents)//2)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', norm=\"l2\", max_df=0.8, min_df=min_df, ngram_range=(1,3)) \n",
    "\n",
    "# Fit and transform the documents into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_content_tokens)\n",
    "\n",
    "# Get the feature names (i.e., words)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for better readability\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Show the TF-IDF values for each term in each document\n",
    "#print(\"TF-IDF Matrix:\")\n",
    "#print(df)\n",
    "\n",
    "# Display the most important words (top N) for each document\n",
    "TOP_N = 15\n",
    "FROM_LOW_TO_HIGH = False\n",
    "\n",
    "analyzer.analysis[\"TFIDF\"] = dict()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    doc = analyzer.all_documents[i]\n",
    "    print(f\"\\nTop {TOP_N} terms for Document {i + 1}: <{doc.title}>\")\n",
    "          \n",
    "    # Generate a title for each unique topic\n",
    "    top_terms = row.sort_values(ascending=FROM_LOW_TO_HIGH).head(TOP_N*2)\n",
    "    \n",
    "    indices = top_terms.index\n",
    "    values = top_terms.values\n",
    "    \n",
    "    # Create a prompt with the top features\n",
    "    prompt = (\n",
    "        \"Generate a concise and meaningful title, exactly four words long, that summarizes the following features. \"\n",
    "        \"The title should capture the main theme or topic of these features. \"\n",
    "        \"Example outputs: 'Language Revolution', 'Shaping Future Technology Trends', 'Global Knowledge Network'.\"\n",
    "        f\"Features: {'\\n'.join([f'{str(indices[i])} - {values[i]}' for i in range(len(indices))])}\"\n",
    "        )\n",
    "            \n",
    "    # Use the LLM to generate a title\n",
    "    title = llm.ollama.generate(model=llm.model, prompt=prompt)[\"response\"]\n",
    "    \n",
    "    analyzer.analysis[\"TFIDF\"].update({doc: {\"title\": title, \"terms\": top_terms[:TOP_N]}})\n",
    "    \n",
    "    print(title, \"\\n\", \", \".join(top_terms[:TOP_N].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:17:32\t Answering question <How do the media in this artic...>\n",
      "00:17:47\t Answering question <Which role does or might the A...>\n",
      "00:17:49\t Answering question <Which use cases of Artificial ...>\n",
      "00:17:59\t Answering question <What is the final message of t...>\n"
     ]
    }
   ],
   "source": [
    "content = json.dumps({doc.title: doc.content for doc in analyzer})\n",
    "\n",
    "# Iterates over each question, provides answers to LLM and let them summarize\n",
    "for question in questions:\n",
    "    content = {doc.title: doc.answers.get(question) for doc in analyzer}\n",
    "    response = llm.answer_question(text=json.dumps(content), question=question, multiple_articles=True)\n",
    "    analyzer.analysis[question] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:18:04\t Answering question <Attached are the topics of eve...>\n"
     ]
    }
   ],
   "source": [
    "answers_questions = dict()\n",
    "# Iterates over each question, provides answers to LLM and let them summarize\n",
    "topic_question_all = (\n",
    "    \"Attached are the topics of every article. \"\n",
    "    \"What **perspectives and aspects** are being widely covered? Which aspects are being ignored? \"\n",
    "    \"In your answer consider topics such as, but not only, data privacy, costs/affordability, know-how, complexity, accuracy, accessibility, bias (towards age, gender, religion, sexuality), risks, opportunity, perception, limitations.\"\n",
    "    \"These are the topics of all arcticles: \")\n",
    "\n",
    "# Example usage:\n",
    "topic_clusters = {doc.title: [value for value in doc.topic_clusters.values()] for doc in analyzer}\n",
    "content_topics = flatten_dict(topic_clusters)\n",
    "response = llm.answer_question(text=json.dumps(content_topics), question=topic_question_all, multiple_articles=True)\n",
    "analyzer.analysis[\"topic_question\"] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Latent Dirichlet Allocation interpretation\n",
      "### Topics that are frequently mentioned in all articles\n",
      "- AI-Driven Medical Threat Analysis & Reporting - Team Response Unveiled\n",
      "- Breaking Boundaries: Google & OpenAI-Fueled Text Analysis Revolution\n",
      "- Linguistic AI Tool: Large-Scale Predictability in Saudi Context, Trained on Word Examples.\n",
      "- Language Analysis in Job Training: Unveiling Khoury's Language Model Impact on Employee News Response\n",
      "- Microsoft's Pioneering Think-Powered Life-Enhancing Tool Boosts Realization and Efficiency\n",
      "\n",
      "# TF-IDF interpretation for every article\n",
      "### Topics that appear in the article very often but not in others\n",
      "- <ChatGPT AI grows more powerful as we become more predictable>: \"AI-Powered Language Model Development: Ethical Implications for Government and Industry\"\n",
      "- <ChatGPT is the Netscape moment' for artificial intelligence'>: \"Leveraging Saudi Language Modeling: Challenges, Research, and Progress in Natural Language Development\"\n",
      "- <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>: \"AI Chatbot: Job Transformation & Global Knowledge Network Expansion\"\n",
      "- <AI is not smarter than humans>: \"Microsoft's Chatbot: Language Skill Realization, User Engagement in Marketing\"\n",
      "- <No need to demonize ChatGPT but AI regulation is a must>: \"OpenAI's Language Model: Potential Impact on Education and Knowledge Sharing\"\n",
      "- <Is the Arab world ready for the uncertain age of AI-powered web tools>: \"Language Model by Google: Investment in Arab News, Job Opportunities and Global Impact\"\n",
      "- <I am not here to take your job,' ChatGPT tells Frankly Speaking host>: \"OpenAI's Large Language Model: A News-Inspired Work Task for Potential Internet Users\"\n",
      "- <Will ChatGPT and AI have an impact on Saudi workforce productivity>: \"AI-Driven Workforce Transformation: Skill Demands and Global Opportunities\"\n",
      "\n",
      "# Hypothesis/Questions\n",
      "## Question 1\n",
      "*How do the media in this article frame the public discussion about ChatGPT? Are there certain 'metaphors' that keep cropping up?*\n",
      "The media frames the public discussion about ChatGPT using a variety of metaphors, including comparisons to historic technological milestones ('Netscape moment'), patterns in language models, and AI's infancy. It also highlights AI's potential benefits and risks, emphasizing its limitations when compared to human intelligence. The media acknowledges ChatGPT as a valuable tool with transformative power, but warns about the ethical challenges it presents. This consistent use of metaphors underscores both the exciting advancements and concerns surrounding AI technology like ChatGPT.\n",
      "Reasoning: The media frames the public discussion about ChatGPT using a variety of metaphors, reflecting both the positive and negative aspects of this AI technology. These metaphors include: \n",
      "\n",
      "1. 'Unlike anything we have ever seen': This emphasizes ChatGPT's rapid progression and groundbreaking nature in the AI landscape.\n",
      "2. 'Netscape moment' or 'Large Language Model LLM': Metaphors that depict ChatGPT as a transformative tool, similar to Netscape's impact on the World Wide Web, or comparing it to autocomplete on steroids.\n",
      "3. 'Infancy of ChatGPT': Highlighting its current developmental stage and potential for improvement.\n",
      "4. 'Superficial and dubious nature' and 'highly plausible misinformation': Metaphors pointing out the limitations and potential risks of AI in generating convincing, yet false, information.\n",
      "5. 'Valorizes potential value', 'concern over hasty adoption', and 'ethical challenges': These metaphors underscore the mixed opinions regarding ChatGPT's role and implications.\n",
      "6. 'AI is not smarter than humans' and 'force for good or ill': Highlighting AI's unique capabilities, limitations, and moral responsibilities.\n",
      "7. 'Simpler tool model', 'pattern-matching machine', and 'limitations compared to human capabilities': These metaphors illustrate how the media portrays ChatGPT as a pattern-matching AI tool with certain advantages but also acknowledges its developmental infancy and potential shortcomings in complex aspects like culture and emotions.\n",
      "8. 'No need to demonize ChatGPT, but...' and 'AI regulation is a must': These metaphors reflect the media's balanced approach towards AI, urging responsible usage without overstating its negative impacts.\n",
      "\n",
      "## Question 2\n",
      "*Which role does or might the Arabic World play in the development of Artificial Intelligence?*\n",
      "The text does not explicitly state a clear role or potential impact of the Arab world in the development of Artificial Intelligence. However, it suggests preparedness for the uncertain age of AI-powered web tools and acknowledges that ChatGPT could potentially affect jobs within this context.\n",
      "Reasoning: The provided text discusses several topics related to ChatGPT and AI, but it doesn't explicitly mention the role or potential impact of the Arabic world. However, the title 'Is the Arab world ready for the uncertain age of AI-powered web tools' suggests a discussion on whether the region is prepared for the implications of AI. Additionally, 'I am not here to take your job,' ChatGPT tells Frankly Speaking host implies that AI might affect jobs in the Arabic context, indicating potential development and impact.\n",
      "\n",
      "## Question 3\n",
      "*Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?*\n",
      "The use cases of Artificial Intelligence beneficial for the Arabic world include enhanced communication through improved chatbots like ChatGPT, legal and contractual automation using AI tools, emergence of foundation models for specific industries or regions, utilizing ChatGPT for outdoor adverts to boost marketing efforts, leveraging AI in content production needs, facilitating language translation services, aiding journalism with news generation and augmenting human work in various sectors, and contributing to literature through writing and illustration tools.\n",
      "Reasoning: The articles highlight various use cases of AI beneficial for the Arabic world. Here's a summary: 1. Enhanced communication through improved chatbots like ChatGPT, facilitating cross-cultural interactions and promoting understanding among diverse linguistic communities within the Arabic world. 2. Legal and contractual automation using AI tools to create skeleton contracts in law firms, reducing reliance on legal staff. 3. Emergence of foundation models that can be trained once for specific industries or regions, such as the energy sector in Saudi Arabia. 4. Using ChatGPT for creating outdoor adverts more engaging with local humor and taglines to boost marketing efforts. 5. Leveraging AI tools like ChatGPT to assist teams in managing content production needs, including writing session briefs, creating social posts, and general copywriting. 6. ChatGPT aiding journalism by generating news content quickly and accurately, assisting education through new teaching methods, potentially impacting the medical field by augmenting human work rather than replacing doctors, and contributing to literature with its ability to write and illustrate books. 7. Improved communication and understanding in the Arabic community through language translation services like Google Translate. 8. AI-powered tools for brainstorming in marketing and business operations. 9. ChatGPT aiding journalism by generating news content quickly and accurately, contributing to literature with its ability to write and illustrate books.\n",
      "\n",
      "## Question 4\n",
      "*What is the final message of the article?*\n",
      "Responsible management, ethical regulation, balanced adoption for productivity enhancement, proactive adaptation.\n",
      "Reasoning: The articles collectively convey a cautious yet optimistic view on AI technologies, particularly ChatGPT. The authors stress the importance of harnessing AI's transformative power alongside human-like reasoning and ethical understanding, acknowledging its limitations in context and reasoning. They emphasize that AI is not smarter than humans but an incredible tool to simplify tasks, inspire creativity, and enhance life. The final message of the articles encourages responsible management and regulation of AI technologies to prevent job displacement, maintain societal balance, and ensure proactive adaptation in light of its integration into various fields.\n",
      "\n",
      "## Question 5\n",
      "*What perspectives and aspects are widely covered in the articles about ChatGPT and AI societal effects? Which aspects are largely ignored?*\n",
      "ChatGPT tells Frankly Speaking host') and the need to balance innovation with societal impact ('No need to demonize ChatGPT but AI regulation is a must'). (6) Ignoring some aspects - Despite covering significant topics, there are gaps. For instance, data privacy concerns, costs/affordability, complexities of implementation, and accessibility for different socio-economic groups aren't extensively addressed in these articles. Additionally, while discussing AI's potential impacts on various sectors, the influence on smaller businesses or communities isn't thoroughly explored.\n",
      "Reasoning: The articles cover several key perspectives and aspects related to the development, use, and impact of ChatGPT and Artificial Intelligence. Here's a breakdown: (1) Perspective on regulation and ethics - Articles discuss the need for AI regulations to prevent misuse ('Arabic article 1', 'Article 2') and explore ethical guidelines ('Arabic article 3'). They also highlight concerns about biases in AI algorithms, particularly affecting diverse Arab populations ('Article 7'). (2) Perspective on job displacement - Many articles focus on the potential for AI to cause job displacement due to automation ('Arabic article 3', 'Article 4'), with a specific mention of ChatGPT's impact on outdoor adverts in the workplace. (3) Perspectives on productivity and efficiency - Articles touch upon how AI, including ChatGPT, can boost productivity ('AI is not smarter than humans', '<ChatGPT>', 'Will ChatGPT and AI have an impact on Saudi workforce productivity'). (4) Addressing limitations - The articles acknowledge the reasoning limitations of current AI models like ChatGPT ('ChatGPT outperforms copywriters in STEP Conference's outdoor adverts', 'Unsupervised Learning'), and the potential for misinformation generation. (5) Aspects related to perception - Articles address public sentiment, such as concerns about job displacement due to automation (\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markdown = str()\n",
    "\n",
    "lda = analyzer.analysis.get(\"LDA\")\n",
    "markdown += f\"# Latent Dirichlet Allocation interpretation\\n### Topics that are frequently mentioned in all articles\\n- {'\\n- '.join(lda.keys())}\\n\\n\"\n",
    "\n",
    "\n",
    "tfidf = [elem.get(\"title\") for elem in flatten_list(analyzer.analysis.get(\"TFIDF\").values())]\n",
    "markdown += f\"# TF-IDF interpretation for every article\\n### Topics that appear in the article very often but not in others\\n\"\n",
    "\n",
    "for id, doc in enumerate(analyzer):\n",
    "    markdown += f\"- <{doc.title}>: {tfidf[id]}\\n\"\n",
    "\n",
    "markdown += \"\\n# Hypothesis/Questions\\n\"\n",
    "for q_id, question in enumerate(questions + [\"topic_question\"]):\n",
    "    answer = analyzer.analysis.get(question)\n",
    "    markdown += f\"## Question {q_id+1}\\n\"\n",
    "    markdown += f\"*{answer.get(\"question\")}*\\n{answer.get(\"answer\")}\\nReasoning: {answer.get(\"reasoning\")}\\n\\n\"\n",
    "    \n",
    "    \n",
    "print(markdown)\n",
    "\n",
    "markdown_path = os.path.join(analyzer.output_folder, \"research summary.md\")\n",
    "analyzer.export_markdown(markdown_path, markdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
