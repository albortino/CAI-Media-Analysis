{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, json\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "from scripts.ollama_handler import OllamaMediaAnalysis, OllamaHandler\n",
    "from scripts.wordcloud_handler import WordCloudHandler\n",
    "from scripts.document_handler import PdfDocument\n",
    "\n",
    "from pypdf import PdfReader\n",
    "import spacy\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model for ollama\n",
    "# ollama.list() # to get all models\n",
    "MODEL = \"granite3.1-moe:3b-instruct-q8_0\" #\"granite3.1-moe\" #\"granite3.1-dense:8b-instruct-q8_0\" #\"granite3.1-dense:8b\"\n",
    "#SYSTEM_PROMPT = f\"You are a senior researcher, working on a media analysis of articles published in arabic newspapers about ChatGPT and the effect of Artificial Intelligence on society. For your answers only focus on topics that were mentioned in the text without adding any further information. Before answering, thoroughly think about the task, the content provided and build your answer with chain of thought reasoning.\"\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a senior researcher conducting a media analysis of Arabic newspaper articles \"\n",
    "    \"about ChatGPT and the societal effects of Artificial Intelligence. Your role is to focus \"\n",
    "    \"exclusively on the topics mentioned in the provided text, without introducing external information. \"\n",
    "    \"Before responding, carefully analyze the task, thoroughly evaluate the content of the articles, \"\n",
    "    \"and construct your answer using a clear chain of thought reasoning approach.\"\n",
    ")\n",
    "\n",
    "# Settings\n",
    "PROCESS_DOCUMENTS = True\n",
    "\n",
    "# Load spacy model\n",
    "SPACY_MODEL = \"en_core_web_lg\"\n",
    "try:\n",
    "    nlp = spacy.load(SPACY_MODEL)\n",
    "except OSError:\n",
    "    spacy.cli.download(SPACY_MODEL)\n",
    "    nlp = spacy.load(SPACY_MODEL)\n",
    "\n",
    "\n",
    "# Set folder paths\n",
    "DOC_FOLDER = \"docs\"\n",
    "PDF_FOLDER = os.path.join(DOC_FOLDER, \"PDFs\") # PDFs\n",
    "OUTPUT_FOLDER = os.path.join(DOC_FOLDER, \"Processed\", MODEL)\n",
    "PROCESSED_DOC_FILENAME = f\"{datetime.now().strftime(\"%y%m%d\")}-{MODEL}-processed_documents.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d):\n",
    "    \"\"\"Recursively flatten a dictionary with nested lists.\"\"\"\n",
    "    flattened_dict = dict()\n",
    "    for k, v in d.items():\n",
    "        flat_list = []\n",
    "        if isinstance(v, list):\n",
    "            flat_list.extend(flatten_list(v))\n",
    "        elif isinstance(v, dict):\n",
    "            flat_list.extend(flatten_dict(v))\n",
    "        \n",
    "        flattened_dict[k] = flat_list\n",
    "    return flattened_dict\n",
    "\n",
    "def flatten_list(lst):\n",
    "    \"\"\"Recursively flatten a nested list.\"\"\"\n",
    "    flat_list = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfAnalyzer:\n",
    "    def __init__(self, ollama_handler: OllamaMediaAnalysis, entity_collection = \"all\", output_folder: str = \"\", get_highlights: bool = False, questions: list[str] = None, debug=True, speed=False):\n",
    "        self.ollama_handler = ollama_handler\n",
    "        self.wordcloud = WordCloudHandler()\n",
    "        self.nlp = nlp\n",
    "        self.output_folder = output_folder\n",
    "        self.entitiy_collection = entity_collection if entity_collection in [\"all\", \"ollama\", \"spacy\"] else \"all\"\n",
    "        self.pdf_documents = []\n",
    "        self.get_highlights = get_highlights\n",
    "        self.questions = questions\n",
    "        self.debug = debug\n",
    "        self.speed = speed\n",
    "        self.analysis = dict()\n",
    "        \n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Iterates over all pages in the document and stores the text in instance.\"\"\"\n",
    "\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        num_pages = reader.pages\n",
    "        \n",
    "        for page_count, page in enumerate(num_pages):\n",
    "            text_current_page = page.extract_text()\n",
    "            print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Adding page {page_count}/{len(num_pages)} with {len(text_current_page)} characters\")\n",
    "            text += text_current_page\n",
    "        return text\n",
    "    \n",
    "    def extract_entities(self, text: str) -> List[str]:\n",
    "        \"\"\"Extracts entities from text using spacy PERSON and ORG labels.\"\"\"\n",
    "        \n",
    "        doc = self.nlp(text)\n",
    "        entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\"]]\n",
    "        print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Found {len(entities)} in text\")\n",
    "        return list(set(entities))\n",
    "    \n",
    "    def get_tokens(self, text):\n",
    "        # Tokenize and remove stop words\n",
    "        doc = self.nlp(text)\n",
    "        tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_currency and not token.is_digit and token.is_alpha]\n",
    "        tokens = [token.title() for token in tokens if token.isupper() or token.capitalize]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str) -> PdfDocument:\n",
    "        \"\"\"Main function that processes a single PDF document with it's subfunctions. Prints status updates.\"\"\"\n",
    "        \n",
    "        content = self.extract_text_from_pdf(pdf_path)\n",
    "        content = self.clean_input(content, line_breaks=False)\n",
    "\n",
    "        title = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        title = title.split(\"_\")[0].strip()\n",
    "        \n",
    "        # Initialize PdfDocument object\n",
    "        print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Create PDF document <{title[:20]}...> with content of length {len(content)}\")\n",
    "        pdf_doc = PdfDocument(pdf_path, content, title)\n",
    "        \n",
    "        # Generating tokenized content\n",
    "        print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Generating tokenized content\")\n",
    "        pdf_doc.content_tokens = self.get_tokens(content)\n",
    "        \n",
    "        # Generating short summary\n",
    "        short_summary_response = self.ollama_handler.generate_short_summary(content)\n",
    "        pdf_doc.short_summary = self.clean_input(short_summary_response)\n",
    "        \n",
    "        # Generate long summary        \n",
    "        summary_response = self.ollama_handler.generate_summary(content)\n",
    "        pdf_doc.summary = self.clean_input(summary_response, soft_clean=True)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Types: summary={pdf_doc.summary}, short={pdf_doc.short_summary}\")\n",
    "\n",
    "        if not self.speed:\n",
    "            # Get answers to questions\n",
    "            print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Finding answer to {len(self.questions)} question{\"s\" if len(self.questions) > 1 else \"\"}\")\n",
    "            for question in self.questions:\n",
    "                question_response = self.ollama_handler.answer_question(content, question)\n",
    "                question_response = self.clean_input(question_response)\n",
    "                \n",
    "                pdf_doc.answers[question] = question_response.get(\"answer\")\n",
    "                        \n",
    "            # Get sentiment           \n",
    "            sentiment_response = self.ollama_handler.analyze_sentiment(content) \n",
    "            pdf_doc.sentiment = sentiment_response.get(\"sentiment_value\")\n",
    "            \n",
    "            # Get entities\n",
    "            print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Extracting entities from text\")\n",
    "            if self.entitiy_collection in [\"all\", \"spacy\"]:\n",
    "                # Get entities with spacy\n",
    "                entities_response = self.extract_entities(pdf_doc.content_tokens)\n",
    "                pdf_doc.entities = self.clean_input(entities_response)\n",
    "                \n",
    "            # Get highlights\n",
    "            if self.get_highlights:\n",
    "                print(f\"{datetime.now().strftime(\"%H:%M:%S\")}\\t Extracting text-highlights\")\n",
    "                pdf_doc.extract_highlighted_sentences()\n",
    "            \n",
    "            # Get topic clusters\n",
    "            topics_response = self.ollama_handler.extract_topics(content)\n",
    "            topic_clusters_response = self.ollama_handler.create_topic_clusters(topics_response)\n",
    "            \n",
    "            pdf_doc.topic_clusters = topic_clusters_response\n",
    "        \n",
    "        # Process wordclouds\n",
    "        pdf_doc = self.create_wordcloud(pdf_doc, wordcloud_names=[\"highlights\", \"content\", \"summary\"])\n",
    "        \n",
    "        return pdf_doc\n",
    "    \n",
    "    def create_wordcloud(self, pdf_doc, wordcloud_names: list):\n",
    "        for wordcloud_name in wordcloud_names:\n",
    "            path = os.path.join(self.output_folder, pdf_doc.filename)\n",
    "\n",
    "            if wordcloud_name == \"highlights\":\n",
    "                sentences = pdf_doc.highlighted_sentences\n",
    "            else:\n",
    "                content = pdf_doc.__dict__.get(wordcloud_name)\n",
    "                sentences = content.split(\".\")\n",
    "\n",
    "            new_wordcloud_data = self.wordcloud.process_wordcloud(input=sentences, path=path, wordcloud_name=wordcloud_name)\n",
    "            pdf_doc.wordcloud_data.update(new_wordcloud_data)\n",
    "        \n",
    "        return pdf_doc\n",
    "        \n",
    "    \n",
    "    def process_folder(self, PDF_FOLDER: str) -> List[PdfDocument]:\n",
    "        \"\"\"Iterates over all PDF files in the folder and processes them.\"\"\"\n",
    "        pdf_documents = []\n",
    "        for filename in os.listdir(PDF_FOLDER):\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                print(f\"{datetime.now().strftime(\"%H:%M:%S\")} Analyzing file from folder: {filename}\")\n",
    "                pdf_path = os.path.join(PDF_FOLDER, filename)\n",
    "                pdf_doc = self.process_pdf(pdf_path)\n",
    "                pdf_documents.append(pdf_doc)\n",
    "                \n",
    "                print(\"Temporarily storing documents\")\n",
    "                self.save_documents(self.pdf_documents)\n",
    "                \n",
    "        return pdf_documents\n",
    "    \n",
    "    def clean_input(self, input, soft_clean=False, line_breaks=True):\n",
    "        if isinstance(input, str):\n",
    "            # Apply the cleaning steps for strings\n",
    "            \n",
    "            # Replace ’ with '\n",
    "            input = input.replace(\"’\", \"'\")\n",
    "            \n",
    "            # Remove line breaks if line_breaks is True and not soft_clean\n",
    "            if line_breaks and not soft_clean:\n",
    "                input = input.replace(\"\\n\", \" \")\n",
    "            \n",
    "            # Remove non-ascii characters if not soft_clean\n",
    "            if not soft_clean:\n",
    "                input = input.encode(\"ascii\", \"ignore\").decode()\n",
    "            \n",
    "            # Remove all special characters except \"-\" if not soft_clean\n",
    "            if not soft_clean:\n",
    "                input = re.sub(r\"[^a-zA-Z0-9.,*' -]\", \" \", input)\n",
    "            \n",
    "            # Remove all double spaces\n",
    "            input = re.sub(r\"  +\", \" \", input)\n",
    "            \n",
    "            # Remove leading and trailing whitespaces\n",
    "            input = input.strip()\n",
    "            \n",
    "            return input\n",
    "        \n",
    "        elif isinstance(input, list):\n",
    "            # If input is a list, clean each element recursively\n",
    "            return [self.clean_input(item, soft_clean, line_breaks) for item in input]\n",
    "        \n",
    "        elif isinstance(input, dict):\n",
    "            # If input is a dictionary, clean each value recursively\n",
    "            return {key: self.clean_input(value, soft_clean, line_breaks) for key, value in input.items()}\n",
    "        \n",
    "        else:\n",
    "            # Return the input unchanged if it is not a string, list, or dictionary\n",
    "            return input\n",
    "    \n",
    "    def save_documents(self, documents: List[PdfDocument]):\n",
    "        \"\"\"Saves the processed documents to a pickle file.\"\"\"\n",
    "        \n",
    "        path = os.path.join(self.output_folder, PROCESSED_DOC_FILENAME)\n",
    "        \n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "        \n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump([doc.to_dict() for doc in documents], f)\n",
    "    \n",
    "    def load_documents(self, input_path: str, load_latest=False) -> List[PdfDocument]:\n",
    "        \"\"\"Loads the processed documents from a pickle file\"\"\"\n",
    "        \n",
    "        if os.path.exists(input_path):\n",
    "            # Open the provided file\n",
    "            with open(input_path, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "        # Load latest file for the model\n",
    "        elif load_latest:\n",
    "            # Get the list of all pickle files in the OUTPUT_FOLDER\n",
    "            pkl_files = glob.glob(os.path.join(self.output_folder, \"*.pkl\"))\n",
    "\n",
    "            # Find the latest pickle file based on the modification time\n",
    "            latest_pkl_file = max(pkl_files, key=os.path.getmtime)\n",
    "\n",
    "            # Load the latest pickle file\n",
    "            with open(latest_pkl_file, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "        self.pdf_documents = [PdfDocument.from_dict(doc_dict) for doc_dict in data]\n",
    "    \n",
    "    def export_docx_files(self):\n",
    "        for doc in self.pdf_documents:\n",
    "            filename = f\"cai_media_analysis_{doc.filename}.docx\"\n",
    "            file_path = os.path.join(self.output_folder, filename)\n",
    "            doc.save_as_docx(file_path=file_path)\n",
    "    \n",
    "    def export_markdown_files(self):\n",
    "        for doc in self.pdf_documents:\n",
    "            # Create folders\n",
    "            filename = f\"cai_media_analysis_{doc.filename}.md\"\n",
    "            file_path = os.path.join(self.output_folder, filename)\n",
    "            \n",
    "            # Write markdown file\n",
    "            with open(file_path, \"w\") as f:\n",
    "                markdown = doc.get_markdown()\n",
    "                f.write(markdown)\n",
    "                \n",
    "    def __iter__(self, which=\"all\") -> list[PdfDocument]:\n",
    "        if which == \"all\":\n",
    "            return iter(self.pdf_documents)\n",
    "        else:\n",
    "            for doc in self.pdf_documents:\n",
    "                if doc.title == which:\n",
    "                    return iter(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PdfAnalyzer class\n",
    "questions =  [\n",
    "    \"How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\",\n",
    "    \"Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\",\n",
    "    \"Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\",\n",
    "    \"What is the final message of the article that the author wants to convey? Keep your answer short and precise!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm as instance of OllamaMediaAnalysis\n",
    "llm = OllamaMediaAnalysis(model_name=MODEL, system_prompt=SYSTEM_PROMPT, debug=True)\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = PdfAnalyzer(ollama_handler=llm, entity_collection=\"spacy\", output_folder=OUTPUT_FOLDER, questions=questions, debug=False, speed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:50:25 Analyzing file from folder: Will ChatGPT and AI have an impact on Saudi workforce productivity_ _ Arab News.pdf\n",
      "16:50:25\t Adding page 0/6 with 852 characters\n",
      "16:50:25\t Adding page 1/6 with 1285 characters\n",
      "16:50:25\t Adding page 2/6 with 940 characters\n",
      "16:50:25\t Adding page 3/6 with 1750 characters\n",
      "16:50:25\t Adding page 4/6 with 1841 characters\n",
      "16:50:25\t Adding page 5/6 with 387 characters\n",
      "16:50:25\t Create PDF document <Will ChatGPT and AI ...> with content of length 7007\n",
      "16:50:25 Initialized PdfDocument: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "16:50:25\t Generating tokenized content\n",
      "16:50:25\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...arning environment.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:50:39\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...tional challenges.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:50:40\t Generating summary\n",
      "16:50:55\t Finding answer to 4 questions\n",
      "16:50:55\t Answering question <How do the media in this artic...>\n",
      "16:51:13\t Answering question <Which role does or might the A...>\n",
      "16:51:28\t Answering question <Which use cases of Artificial ...>\n",
      "16:51:32\t Answering question <What is the final message of t...>\n",
      "16:51:35\t Analyzing sentiment\n",
      "16:51:49\t Extracting entities from text\n",
      "16:51:49\t Found 14 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity_ _ Arab News\n",
      "Temporarily storing documents\n",
      "16:52:06 Analyzing file from folder: AI is not smarter than humans _ Updated 08 April 2023.pdf\n",
      "16:52:06\t Adding page 0/2 with 1913 characters\n",
      "16:52:06\t Adding page 1/2 with 2417 characters\n",
      "16:52:06\t Create PDF document <AI is not smarter th...> with content of length 4292\n",
      "16:52:06 Initialized PdfDocument: <AI is not smarter than humans>\n",
      "16:52:06\t Generating tokenized content\n",
      "16:52:06\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...actions and work.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:52:14\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...human interaction.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:52:15\t Generating summary\n",
      "16:52:26\t Finding answer to 4 questions\n",
      "16:52:26\t Answering question <How do the media in this artic...>\n",
      "16:52:36\t Answering question <Which role does or might the A...>\n",
      "16:52:38\t Answering question <Which use cases of Artificial ...>\n",
      "16:52:41\t Answering question <What is the final message of t...>\n",
      "16:52:43\t Analyzing sentiment\n",
      "16:52:51\t Extracting entities from text\n",
      "16:52:51\t Found 7 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans _ Updated 08 April 2023\n",
      "Temporarily storing documents\n",
      "16:53:03 Analyzing file from folder: ChatGPT_ AI grows more powerful as we become more predictable _ Arab News.pdf\n",
      "16:53:03\t Adding page 0/4 with 662 characters\n",
      "16:53:03\t Adding page 1/4 with 2311 characters\n",
      "16:53:03\t Adding page 2/4 with 2307 characters\n",
      "16:53:03\t Adding page 3/4 with 896 characters\n",
      "16:53:03\t Create PDF document <ChatGPT...> with content of length 6139\n",
      "16:53:03 Initialized PdfDocument: <ChatGPT>\n",
      "16:53:03\t Generating tokenized content\n",
      "16:53:03\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...ines like ChatGPT.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:53:15\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...lex reasoning tasks.\"} ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:53:16\t Generating summary\n",
      "16:53:31\t Finding answer to 4 questions\n",
      "16:53:31\t Answering question <How do the media in this artic...>\n",
      "16:53:49\t Answering question <Which role does or might the A...>\n",
      "16:54:02\t Answering question <Which use cases of Artificial ...>\n",
      "16:54:07\t Answering question <What is the final message of t...>\n",
      "16:54:10\t Analyzing sentiment\n",
      "16:54:23\t Extracting entities from text\n",
      "16:54:23\t Found 16 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT_ AI grows more powerful as we become more predictable _ Arab News\n",
      "Temporarily storing documents\n",
      "16:54:37 Analyzing file from folder: ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts _ Updated 22 February 2023.pdf\n",
      "16:54:37\t Adding page 0/3 with 734 characters\n",
      "16:54:37\t Adding page 1/3 with 1894 characters\n",
      "16:54:37\t Adding page 2/3 with 352 characters\n",
      "16:54:37\t Create PDF document <ChatGPT outperforms ...> with content of length 2940\n",
      "16:54:37 Initialized PdfDocument: <ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts>\n",
      "16:54:37\t Generating tokenized content\n",
      "16:54:37\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"STEP... for human talent.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:54:42\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ... human creativity.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:54:43\t Generating summary\n",
      "16:54:51\t Finding answer to 4 questions\n",
      "16:54:51\t Answering question <How do the media in this artic...>\n",
      "16:55:00\t Answering question <Which role does or might the A...>\n",
      "16:55:02\t Answering question <Which use cases of Artificial ...>\n",
      "16:55:05\t Answering question <What is the final message of t...>\n",
      "16:55:07\t Analyzing sentiment\n",
      "16:55:12\t Extracting entities from text\n",
      "16:55:12\t Found 1 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts _ Updated 22 February 2023\n",
      "Temporarily storing documents\n",
      "16:55:18 Analyzing file from folder: Is the Arab world ready for the uncertain age of AI-powered web tools_Updated 09 March 2023.pdf\n",
      "16:55:18\t Adding page 0/9 with 835 characters\n",
      "16:55:18\t Adding page 1/9 with 1154 characters\n",
      "16:55:18\t Adding page 2/9 with 1140 characters\n",
      "16:55:18\t Adding page 3/9 with 743 characters\n",
      "16:55:18\t Adding page 4/9 with 2031 characters\n",
      "16:55:19\t Adding page 5/9 with 1559 characters\n",
      "16:55:19\t Adding page 6/9 with 1102 characters\n",
      "16:55:19\t Adding page 7/9 with 1671 characters\n",
      "16:55:19\t Adding page 8/9 with 1345 characters\n",
      "16:55:19\t Create PDF document <Is the Arab world re...> with content of length 11447\n",
      "16:55:19 Initialized PdfDocument: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "16:55:19\t Generating tokenized content\n",
      "16:55:19\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...pact on human jobs.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:55:36\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...nalytical skills.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:55:38\t Generating summary\n",
      "16:55:59\t Finding answer to 4 questions\n",
      "16:55:59\t Answering question <How do the media in this artic...>\n",
      "16:56:22\t Answering question <Which role does or might the A...>\n",
      "16:56:41\t Answering question <Which use cases of Artificial ...>\n",
      "16:56:58\t Answering question <What is the final message of t...>\n",
      "16:57:15\t Analyzing sentiment\n",
      "16:57:32\t Extracting entities from text\n",
      "16:57:33\t Found 25 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools_Updated 09 March 2023\n",
      "Temporarily storing documents\n",
      "16:57:51 Analyzing file from folder: ‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host _Updated 20 March 2023.pdf\n",
      "16:57:51\t Adding page 0/10 with 659 characters\n",
      "16:57:51\t Adding page 1/10 with 1895 characters\n",
      "16:57:51\t Adding page 2/10 with 1241 characters\n",
      "16:57:51\t Adding page 3/10 with 2234 characters\n",
      "16:57:51\t Adding page 4/10 with 1515 characters\n",
      "16:57:51\t Adding page 5/10 with 1207 characters\n",
      "16:57:51\t Adding page 6/10 with 1875 characters\n",
      "16:57:51\t Adding page 7/10 with 1666 characters\n",
      "16:57:51\t Adding page 8/10 with 1370 characters\n",
      "16:57:51\t Adding page 9/10 with 1719 characters\n",
      "16:57:51\t Create PDF document <‘I am not here to ta...> with content of length 15255\n",
      "16:57:51 Initialized PdfDocument: <‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host>\n",
      "16:57:51\t Generating tokenized content\n",
      "16:57:51\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"C...s in AI technology.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:58:08\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:58:09\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least one numbered bullet point (e.g., '1. answer\n",
      "2. answer\n",
      "3. answer'). [type=value_error, input_value=\"Yes, ChatGPT can provide...nology for good or ill.\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "16:58:30\t Generating summary\n",
      "16:58:50\t Finding answer to 4 questions\n",
      "16:58:50\t Answering question <How do the media in this artic...>\n",
      "16:59:08\t Answering question <Which role does or might the A...>\n",
      "16:59:26\t Answering question <Which use cases of Artificial ...>\n",
      "16:59:43\t Answering question <What is the final message of t...>\n",
      "17:00:01\t Analyzing sentiment\n",
      "17:00:17\t Extracting entities from text\n",
      "17:00:17\t Found 17 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host _Updated 20 March 2023\n",
      "Temporarily storing documents\n",
      "17:00:36 Analyzing file from folder: ChatGPT is the ‘Netscape moment’ for artificial intelligence’ _ Arab News.pdf\n",
      "17:00:36\t Adding page 0/4 with 645 characters\n",
      "17:00:36\t Adding page 1/4 with 2409 characters\n",
      "17:00:36\t Adding page 2/4 with 2380 characters\n",
      "17:00:36\t Adding page 3/4 with 1100 characters\n",
      "17:00:36\t Create PDF document <ChatGPT is the ‘Nets...> with content of length 6510\n",
      "17:00:36 Initialized PdfDocument: <ChatGPT is the ‘Netscape moment’ for artificial intelligence’>\n",
      "17:00:36\t Generating tokenized content\n",
      "17:00:36\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T...wledge integration.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "17:00:49\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...ial misinformation.\"}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "17:00:50\t Generating summary\n",
      "17:01:07\t Finding answer to 4 questions\n",
      "17:01:07\t Answering question <How do the media in this artic...>\n",
      "17:01:23\t Answering question <Which role does or might the A...>\n",
      "17:01:26\t Answering question <Which use cases of Artificial ...>\n",
      "17:01:32\t Answering question <What is the final message of t...>\n",
      "17:01:36\t Analyzing sentiment\n",
      "17:01:49\t Extracting entities from text\n",
      "17:01:49\t Found 8 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the ‘Netscape moment’ for artificial intelligence’ _ Arab News\n",
      "Temporarily storing documents\n",
      "17:02:04 Analyzing file from folder: No need to demonize ChatGPT but AI regulation is a must _ Arab News.pdf\n",
      "17:02:04\t Adding page 0/5 with 615 characters\n",
      "17:02:04\t Adding page 1/5 with 1750 characters\n",
      "17:02:04\t Adding page 2/5 with 2205 characters\n",
      "17:02:04\t Adding page 3/5 with 2070 characters\n",
      "17:02:04\t Adding page 4/5 with 1254 characters\n",
      "17:02:04\t Create PDF document <No need to demonize ...> with content of length 7836\n",
      "17:02:04 Initialized PdfDocument: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "17:02:04\t Generating tokenized content\n",
      "17:02:04\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...lists and writers.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "17:02:18\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ... job displacement.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "17:02:19\t Generating summary\n",
      "17:02:38\t Finding answer to 4 questions\n",
      "17:02:38\t Answering question <How do the media in this artic...>\n",
      "17:02:59\t Answering question <Which role does or might the A...>\n",
      "17:03:15\t Answering question <Which use cases of Artificial ...>\n",
      "17:03:35\t Answering question <What is the final message of t...>\n",
      "17:03:52\t Analyzing sentiment\n",
      "17:04:09\t Extracting entities from text\n",
      "17:04:09\t Found 11 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must _ Arab News\n",
      "Temporarily storing documents\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_DOCUMENTS:\n",
    "    # Process the documents in the folder where the PDFs are\n",
    "    documents = analyzer.process_folder(PDF_FOLDER)\n",
    "\n",
    "    # Save documents to the output folder\n",
    "    analyzer.save_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:04:27 Initialized PdfDocument: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "17:04:27 Initialized PdfDocument: <AI is not smarter than humans>\n",
      "17:04:27 Initialized PdfDocument: <ChatGPT>\n",
      "17:04:27 Initialized PdfDocument: <ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts>\n",
      "17:04:27 Initialized PdfDocument: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "17:04:27 Initialized PdfDocument: <‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host>\n",
      "17:04:27 Initialized PdfDocument: <ChatGPT is the ‘Netscape moment’ for artificial intelligence’>\n",
      "17:04:27 Initialized PdfDocument: <No need to demonize ChatGPT but AI regulation is a must>\n"
     ]
    }
   ],
   "source": [
    "# Load already analyzed documents\n",
    "analyzer.load_documents(os.path.join(OUTPUT_FOLDER, PROCESSED_DOC_FILENAME), load_latest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get insights on the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Will ChatGPT and AI have an impact on Saudi workforce productivity\n",
      "Short Summary: The article explores how ChatGPT and AI technologies are reshaping Saudi workforce productivity via tailored training, online courses, collaboration enhancement, upskilling, reskilling, and knowledge management, yet acknowledges potential job displacement due to automation and underscores the necessity for strategic implementation considering operational challenges.\n",
      "Summary:\n",
      "1. **AI technologies like ChatGPT are revolutionizing global workforces, providing an opportunity to boost productivity in Saudi Arabia.**\n",
      "2. **ChatGPT's popularity has alleviated fears among employees about job replacement by AI, emphasizing the potential for collaboration between humans and machines.**\n",
      "3. **AI can significantly impact career-related skills through tailored training programs, access to online courses, and fostering team collaboration.**\n",
      "4. **In the public sector, healthcare, transportation, energy, finance, and retail sectors, AI will restructure operations, enhancing efficiency and service delivery.**\n",
      "5. **While ChatGPT is likely to replace workers performing mundane tasks, it also creates opportunities for upskilling and reskilling to adapt to an increasingly AI-driven world.**\n",
      "6. **The implementation of AI in Saudi companies necessitates a holistic approach that defines strategic objectives, identifies operational bottlenecks, and chooses optimal tools or technologies.**\n",
      "7. **To successfully integrate AI, organizations need solid leadership, foresight, agility, and an optimistic environment for learning to accommodate employees and clients during the transition.*\n",
      "Sentiment: 4\n",
      "Entities: ['Khoury', 'Embed Ai Operation Saudi Company Employee Require Holistic Approach', 'Task Automate', 'Foster Collaboration Communication Team', 'Regard Energy Sector Innovative Technology', 'Chatgpt Ai Impact Saudi Workforce', 'Raymond Khoury', 'Arthur']\n",
      "Topic clusters: {'Artificial Intelligence (AI) Technologies': ['ChatGPT', 'AI applications', 'machine learning'], 'Ethical and Societal Implications': ['societal effects of AI', \"ChatGPT's impact on society\", 'regulations for AI'], 'Job Market Disruption': ['how ChatGPT affects jobs', 'job displacement due to AI']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 34), ('Khoury', 16), ('ChatGPT', 12), ('employees', 11), ('impact', 9), ('technologies', 6), ('operations', 6), ('said', 6), ('workers', 6), ('Saudi', 5)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity_ _ Arab News/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 7), ('ChatGPT', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity_ _ Arab News/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames ChatGPT as a transformative force that is shaping the future of the Saudi workforce. Metaphors like 'wave of change', 'useful tool for boosting productivity', 'embracing innovation to boost productivity', and 'AI's paradoxical nature alongside positive impact on recruitment' keep recurring, emphasizing ChatGPT as a tool that both challenges traditional employment roles and augments capabilities.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThese use cases of Artificial Intelligence are helpful for the Arabic world as they aim to boost productivity, efficiency, and strategic decision-making within various sectors such as healthcare, transportation, energy, finance, and retail.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tStrategic integration of AI technologies like ChatGPT in workforces can lead to increased productivity and improved services across sectors such as healthcare, transportation, energy, finance, and retail. However, this transition requires employees to upgrade skills due to potential job displacement from automation. Solid leadership, a future-oriented mindset, and continuous learning are essential for successful AI implementation.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: AI is not smarter than humans\n",
      "Short Summary: The article examines both ChatGPT's beneficial aspects in enhancing productivity and communication, while addressing concerns over its reliability, emotional understanding, and cultural sensitivity it also highlights AI's potential to transform marketing but reiterates the significance of human interaction.\n",
      "Summary:\n",
      "1. AI tools like ChatGPT are highly beneficial, offering personal assistance and enhancing business tasks through various applications.\n",
      "2. These AI systems can emulate real-life professionals such as recruiters, marketers, or CEOs, acting as intelligent digital assistants.\n",
      "3. Apple's Siri was a pioneering AI tool that significantly improved daily routines and communication with technology.\n",
      "4. Initial concerns about AI accuracy stem from the user's inherent limitations in grammar and language skills, which AI tools initially capitalized on but overcame through continuous learning and improvement.\n",
      "5. AI has shown great potential in business operations and marketing, providing valuable insights and ideas for campaigns. However, it may lack understanding of cultural nuances like feeling sentimental during national anthems.\n",
      "6. Despite advancements, AI cannot replicate the essential human connection. It assists humans but does not replace them in creating personalized messaging or tailored marketing content that carries emotional depth and meaning.\n",
      "7. As we continue to develop AI technology, it is crucial to ensure its reliability, maintain a balance between automation and human involvement, and preserve the unique value of human interaction in our increasingly interconnected world.\n",
      "Sentiment: 2\n",
      "Entities: ['Ali Al Mustafa', 'Saint Mary University', 'Grace Business Operation Marketing Department Include Computer Understand Like Culture', 'Kid Singe', 'Ai Smart', 'Real Life Recruiter Marketer', 'National Anthem Look Ag']\n",
      "Topic clusters: {'Artificial Intelligence and Ethics': ['ChatGPT', 'AI societal effects'], 'AI and Journalism': ['Arabic media coverage on ChatGPT', \"ChatGPT's impact on news reporting\"], 'AI in Education': ['AI-powered learning tools', 'ChatGPT for educational purposes'], 'AI Bias and Fairness': ['Discussions on AI fairness in Arabic context', \"ChatGPT's potential biases\"]}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 10), ('technology', 8), ('marketing', 6), ('like', 5), ('business', 4), ('humans', 3), ('experience', 3), ('able', 3), ('ideas', 3), ('connection', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans _ Updated 08 April 2023/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 8), ('human', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans _ Updated 08 April 2023/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT as a transformative force that can revolutionize various aspects of life through metaphors of evolution. The AI is depicted as rapidly evolving, much like how technology has progressed with the introduction of Siri and other virtual assistants.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases of Artificial Intelligence that are helpful for the Arabic world, according to this article, include personal assistance via virtual assistants capable of handling diverse tasks, language translation tools like Google Translate to bridge linguistic gaps, and AI's potential in revolutionizing business operations and marketing strategies globally.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI has immense potential to revolutionize various aspects of life, but it cannot replace the personal connection and nuanced understanding that humans provide.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT\n",
      "Short Summary: The article examines rapid adoption of ChatGPT, a large language AI model, noting its integration into society but also cautioning on limitations and potential pitfalls compared to human cognition in complex reasoning tasks.\n",
      "Summary:\n",
      "1. **Rapid Adoption of ChatGPT**: The platform had a million unique users within five days of its release, demonstrating the unprecedented speed of AI technology adoption.\n",
      " \n",
      "2. **Predictive Power of ChatGPT**: OpenAI's algorithm uses large data sets to make guesses about trends in user behavior, indicating that human behavior is perceived as predictable by this system.\n",
      "3. **Limitations of Current AI Technology**: Despite the rapid adoption, ChatGPT lacks accurate intelligence and reasoning capabilities, unlike the human mind which can develop thoughts and language from limited data.\n",
      "4. **Ethical Concerns with AI Development**: The quick embrace of AI tools like ChatGPT raises ethical issues such as reinforcing ideologies, worldviews, truths, and untruths, potentially locking them in.\n",
      "5. **Inability to Balance Creativity and Constraint**: ChatGPT is unable to balance creative outputs with constraints, either overgenerating or undergenerating content that endorses ethical and unethical decisions alike.\n",
      "6. **Beneficial but Not Replacing Human Intelligence**: AI tools like ChatGPT can augment human intelligence by facilitating more efficient work in various domains, but they cannot replace the uniqueness of human cognition.\n",
      "7. **Incremental Incorporation Over Rapid Change**: Companies and governments should implement AI technologies incrementally rather than abruptly restructuring their working models to leverage the benefits while preserving essential aspects of human intelligence and work nature.\n",
      "Sentiment: 0\n",
      "Entities: ['Unique User Ve Day', 'White Paper Launch', 'Openai Approach Chatgpt Notion Human Behavior Predictable Analyze Large Datum', 'Joseph Dana Predictable Ai Tool Lack Fundamental Ability', 'Chatgpt Ai', 'Microsoft', 'Miss Vital Point Human Development Impact Society Ethical Issue', 'Https Microsoft Ethic Society Responsible Ai Layo S Entire Ai Ethic Team', 'Ed Language Development Vital Understand Limitation Chatgpt Come Mimic Human Thought Unlike', 'Noam Chomsky', 'Future Contestation Ection Improvement Scary Stu', 'Exponential View Weekly Newsletter Technology Impact Society', 'Serendipitously Stumble Book Know', 'New York Times', 'Joseph Dana']\n",
      "Topic clusters: {\"ChatGPT and AI's Impact on Journalism\": ['AI-generated news articles', 'potential job displacement', 'changes in journalistic ethics'], 'Arab Perspective on AI and ChatGPT': ['AI adoption in Arabic media landscape', 'societal concerns about AI', 'regional regulations for AI use'], \"AI's Role in Shaping Public Opinion\": ['AI-driven misinformation spreading', 'social media influence on public discourse', 'AI as an opinion shaper'], 'Ethical Implications of ChatGPT and AI': ['privacy concerns with AI data usage', 'accountability for AI decisions', 'potential biases in AI algorithms'], 'Arabic AI Research and Development': ['investment in AI research', 'local AI startups and collaborations', 'AI policy considerations']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 15), ('ChatGPT', 13), ('tools', 8), ('human', 8), ('predictable', 6), ('language', 6), ('data', 6), ('technology', 5), ('reason', 5), ('adoption', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT_ AI grows more powerful as we become more predictable _ Arab News/wordcloud_content.png'}, 'summary': {'word_frequencies': [('ChatGPT', 6), ('AI', 6), ('human', 5), ('intelligence', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT_ AI grows more powerful as we become more predictable _ Arab News/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT by using metaphors that highlight both its potential power explosion of usage and limitations babies learning from small data cues , comparing it to human cognition, and cautioning against misuse while emphasizing its predictable yet limited intelligence.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\t1 Predictive Analysis and Content Generation through tools like ChatGPT , 2 Ethical Considerations in AI Development, 3 Balancing Creativity with Constraint, 4 Incremental AI Integration\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message is to encourage a balanced, ethical approach to AI integration that leverages ChatGPT's capabilities while respecting the unique human intelligence.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts\n",
      "Short Summary: The article details how the STEP Conference leverages ChatGPT to bolster outdoor advertising and in-house content projects, emphasizing AI's role as a supportive tool rather than an overlord replacing human creativity.\n",
      "Summary:\n",
      "1. **ChatGPT is being utilized by STEP Conference for creating outdoor advertisements featuring taglines like \"Your money needs a side hustle,\" \"Save the planet,\" and more.\n",
      "2. The ad campaign was initially developed using an agency's resources, but ChatGPT proved superior in generating taglines leading to its selection.\n",
      "3. STEP Conference plans to continue using ChatGPT for tasks including writing session briefs, creating social posts, and content generation across the team.\n",
      "4. The use of AI as an artificial intelligence assistant is making Team STEP faster and more efficient at their jobs.\n",
      "5. Dargham explained that while some experts argue AI has created more jobs than it eliminated, concerns arise when AI replaces human copywriters due to its creative limitations compared to humans.\n",
      "6. Despite these fears, ChatGPT's potential to augment rather than replace human talent is recognized by Dargham; he believes human creativity will find new roles in an evolving job market.\n",
      "7. Dargham acknowledged the existential threat posed by AI tools like Meta's Open Pretrained Transformer, Microsoft's Bing, and Google's Bard, but remains optimistic about their complementary nature to human capabilities rather than direct replacement.\n",
      "Sentiment: 4\n",
      "Entities: ['Dargham Clari']\n",
      "Topic clusters: {'AI-driven advancements': ['ChatGPT performance', 'AI-generated advertisements'], 'Social media impacts': [], 'Ethical considerations': []}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 10), ('STEP', 7), ('ChatGPT', 6), ('like', 6), ('team', 5), ('Dargham', 5), ('outdoor', 4), ('company', 4), ('use', 4), ('agency', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts _ Updated 22 February 2023/wordcloud_content.png'}, 'summary': {'word_frequencies': [('ChatGPT', 4), ('AI', 4), ('human', 4), ('STEP', 3), ('Dargham', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts _ Updated 22 February 2023/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT using progress and threat metaphors, describing it as an innovative tool for productivity enhancement, a potential existential crisis due to automation concerns, and a hybrid complement or replacement for human talent.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe article highlights several instances where AI, specifically ChatGPT, is used beneficially in the Arabic world Advertising campaigns, content creation and summarization, and assistance to human talent.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI tools like ChatGPT can both complement and potentially replace human talent, while emphasizing the value of human creativity in this evolving landscape.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: Is the Arab world ready for the uncertain age of AI-powered web tools\n",
      "Short Summary: The global AI market is projected to reach 15.7 trillion by 2030, primarily driven by the Middle East's significant contribution, emphasizing that while AI enhances efficiency in tasks like content creation and customer service, it does not replace human creativity or analytical skills.\n",
      "Summary:\n",
      "The global market value of AI, estimated at 1\n",
      "5.7 trillion in 2030, is expected to contribute significantly to the global economy by then. This growth is projected to be 97 million people working in AI by 2024 and a 13x increase over the next eight years.\n",
      "AI's impact extends beyond search engines; it's anticipated that 2 percent of the world's benefits from AI by the end of this decade, equivalent to 320 billion, with the Middle East expected to partake in this growth.\n",
      "While tools like ChatGPT can be useful for simplifying tasks and providing engaging content, experts stress the importance of fact-checking due to its potential for misinformation. AI models, such as large-language models (LLMs), are not capable of understanding context or reasoning in a conventional sense; they simply match patterns based on training data.\n",
      "Despite these capabilities, human intelligence and awareness remain essential for the safe expansion of AI use. The UAE Minister of Education acknowledged the potential of ChatGPT to assist in content creation but reassured that it cannot replace creativity or human insight found in human writers.\n",
      "The debate surrounding AI's impact remains divided, with optimists believing it will augment human capabilities and pessimists fearing widespread automation could lead to job displacement. Regardless of the perspectives, trust is crucial for the ethical integration of AI solutions into society.\n",
      "In conclusion, while AI holds immense investment potential with forecasts valuing in trillions of dollars, it's essential to address concerns about misinformation and maintain human involvement to ensure a safe and beneficial use of AI technologies worldwide.\n",
      "Sentiment: 5\n",
      "Entities: ['Multinational Tech Corporation Microsoft', 'Chatgpt O Ere Measure Reassurance', 'Nancial Support Tech Industry', 'Linkedin Co', 'Uk Guardian Newspaper Say', 'Jenna Burrell', 'Marketing Professional Redundant Technology', 'Sciences Po School Paris', 'Research Data Society Independent Non Pro T Research Organization Base California Say People Need', 'Dan Milmo Alex Hern Tech', 'Reid Ho', 'Burrell Say', 'Chatgpt Spur Google Management', 'James Webb', 'Eld Seek', 'Sam Altman Year', 'Omar Sultan Al Olama Take', 'Spearhead Uae Expand Digital Economy Middle East Project Accrue Percent Total Global Bene', 'Ahmed Belhoul', 'Initial Investment Rm Worth Billion Billion Mean Company Value', 'Elon Musk Serve Start Board', 'Arab News Leap Technology Conference', 'Noaman Sayed', 'Education Chatgpt Say Program Assist Content Creation Social Medium Blog Website Write Business Plan', 'Peter Thiel Tesla']\n",
      "Topic clusters: {'AI Technology & ChatGPT': ['Arabic newspaper articles discussing AI and its applications', \"Evaluation of ChatGPT's capabilities and limitations\", 'Societal implications of using advanced AI technologies'], 'General Discussions on AI': ['Public perception and understanding of AI', 'Concerns about the potential misuse of AI', 'Regulatory measures for AI development and deployment']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 27), ('ChatGPT', 18), ('said', 10), ('human', 8), ('Google', 8), ('billion', 7), ('Arab', 6), ('web', 6), ('intelligence', 6), ('OpenAI', 6)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools_Updated 09 March 2023/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 10), ('human', 5), ('potential', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools_Updated 09 March 2023/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT using metaphors that emphasize its role as a simplifier and fun tool, text generator or writer, source of information, limitations compared to human writers, potential for misuse in education, and a blend of optimism and pessimism regarding its impact on society.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tThe Arabic World, particularly countries like the UAE, has shown significant interest and investment in AI, indicating a potential for contributing or playing a key role in its development and application.\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\t1. Content Creation ChatGPT, which can assist in creating various types of content such as social media posts, blogs, reports, emails, legal documents, and summaries, can help improve communication and writing in the Arabic language.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI is a valuable tool, but its limitations must be recognized. It should be used thoughtfully and with trust, acknowledging that humans remain crucial in areas like creativity, skepticism, and reasoning.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host\n",
      "Short Summary: The article explores ChatGPT's capabilities, limitations, and potential societal impacts emphasizing both its benefits in enhancing global communication and concerns over privacy, bias, and job displacement from AI advancements.\n",
      "Summary:\n",
      "The information provided discusses ChatGPT, an advanced AI language model developed by OpenAI since 201\n",
      "5. It has been integrated into various Microsoft products including Bing search engine and Edge browser. The update released in March 2023 to GPT-4 focuses on enhancing the accuracy of text responses from both image and text inputs, a significant advancement for this technology.\n",
      "ChatGPT is designed to understand and respond to a wide range of queries, including those about itself and its capabilities. It can provide information, engage in conversation, translate languages, and even offer insights into various topics. \n",
      "The model's development is guided by OpenAI, with Microsoft being one of the key contributors through significant investments. The technology has sparked competition among tech giants like Google (Bard) and Amazon (with Bard), as well as Baidu and Meta, to integrate AI into their offerings.\n",
      "Despite its capabilities, ChatGPT acknowledges that it is not intended to replace human journalists or anchors but rather assist in their roles by providing information and facilitating communication. It underscores the responsibility of developers, policymakers, and users to use this technology ethically and responsibly, particularly considering potential issues such as privacy concerns, bias, and job displacement.\n",
      "ChatGPT is clear that its impact on society will depend largely on how it's utilized, expressing optimism about its potential to promote the wellbeing of humanity and contribute positively to future developments in various fields. It emphasizes that developers, policymakers, and users must work together to ensure AI technology is harnessed for good, fostering a future where humans can benefit from technological advancements.\n",
      "Sentiment: 0\n",
      "Entities: ['Katie Jensen', 'Say Response Base Solely', 'Photo Accord Chatgpt Job Government Regulate Use Ai Absorption National Economy Overall Impact Ai Job Market Complex Multifaceted', 'Focus Develop Ai Model Context', 'Microsoft', 'Focus E Ort Near Future Area Focus Improve Naturalness Sophistication', 'Sam Altman', 'Task Automate Ai', 'Generative Ai Live Reputation Produce Human Like', 'Saudi Arabia Say Chatgpt Provide News Analysis Local Regional International Event Reputation Provide Accurate Timely Comprehensive News Coverage', 'Con Ict Give Rapid Pace Technological Change Underway Worker Concern Professional Function', 'Ai Facilitate', 'Di Erent', 'Rst Time', 'Initial Investment Rm Billion Billion Windows Maker']\n",
      "Topic clusters: {'Artificial Intelligence Applications': ['ChatGPT', 'OpenAI', 'Microsoft', 'Edge browser'], 'Media and Journalism Interaction with AI': ['newsroom', 'journalists', 'Arab News', 'GPT-4'], 'Technological Impact on Media': ['User preferences']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 37), ('ChatGPT', 28), ('data', 28), ('language', 25), ('said', 18), ('training', 17), ('responses', 15), ('job', 11), ('human', 11), ('technology', 11)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host _Updated 20 March 2023/wordcloud_content.png'}, 'summary': {'word_frequencies': [('ChatGPT', 4), ('technology', 4), ('information', 3), ('AI', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host _Updated 20 March 2023/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT as a technological advancement, frequently using metaphors like 'AI language model' or 'AI technology' to describe it. These metaphors help frame the concept within familiar terms related to human communication and cognition.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\t1. Enhancing Communication The integration of ChatGPT into Bing search engine and Edge browser allows users to interact with AI language models, facilitating easier access to information in Arabic. This can help bridge language barriers and improve digital literacy in the Arabic-speaking community.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message of the article is cautious optimism for the responsible use of AI technology, emphasizing its potential benefits in promoting human wellbeing and contributing to a better future, but also cautioning about potential negative impacts that require careful regulation and ethical consideration.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT is the ‘Netscape moment’ for artificial intelligence’\n",
      "Short Summary: The article presents ChatGPT as a 'Netscape moment' for AI, highlighting its profound influence across industries via Large Language Models LLMs , while acknowledging their limitations in common sense, world knowledge, reasoning skills, and potential misinformation.\n",
      "Summary:\n",
      "1. **Exciting Development**: ChatGPT has generated significant excitement globally, similar to the initial impact of Netscape's World Wide Web browser in the 1990s, due to its rich conversational interface built on Large Language Models (LLMs).\n",
      "2. **Technological Advancement**: LLMs are trained using unsupervised learning on vast text corpora, enabling them to understand language patterns and generate human-like responses but lacking world knowledge, common sense, or reasoning capabilities.\n",
      "3. **Current Limitations**: These models face limitations such as generating false or misleading information due to their inability to discern truth or perform complex calculations, leading to issues like plagiarism and the production of harmful content.\n",
      "4. **Future Evolution**: As LLMs evolve rapidly, they will need improvement by systems emulating human-like thinking, including understanding common sense, ethics, and reasoning, which is essential for near-instantaneous decision-making.\n",
      "5. **Dual Nature of AI**: While ChatGPT excels at specific tasks like creating contracts or generating content based on prompts, they fall short in complex problem-solving and understanding context deeply due to their lack of 'semantics.'\n",
      "6. **Emergence of Foundation Models**: These are general-purpose models that can be trained once and reused across multiple applications with minimal computational cost, providing a new platform for AI development, particularly beneficial in localized markets like Saudi Arabia.\n",
      "7. **AI as Productivity Enhancer**: With the rise of automation and inflationary pressures, ChatGPT can enhance productivity by reducing reliance on human labor, making it a valuable tool during economic challenges and demographic shifts in developed countries facing aging populations and declining workforces. Saudi Arabia's focus on data utilization, AI education, and industry-specific developments positions the Kingdom well to capitalize on this opportunity.\n",
      "Sentiment: 3\n",
      "Entities: ['Chatgpt', 'Saudi Arabia Develop Country', 'Technologist Investment Program', 'Saudi Public Private Sector Entity Encourage Explore Technology Create New Value', 'Rst Appear', 'Ai Exempli Ed', 'Anthony Butler']\n",
      "Topic clusters: {'AI Impact on Society': [\"ChatGPT's impact\", 'Plagiarism concerns'], 'Unsupervised Learning': [], 'Auto-Generated Contracts': ['Auto-generated contracts'], 'Model Limitations': ['Model limitations'], 'Productivity Enhancement': [], 'De-Aggregation Effects': ['De-aggregation effects'], 'Demographic Challenges': []}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 13), ('models', 8), ('ChatGPT', 6), ('example', 6), ('new', 5), ('words', 5), ('Saudi', 5), ('arti', 4), ('cial', 4), ('text', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the ‘Netscape moment’ for artificial intelligence’ _ Arab News/wordcloud_content.png'}, 'summary': {'word_frequencies': [('like', 5), ('AI', 4), ('ChatGPT', 3), ('LLMs', 3), ('human', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the ‘Netscape moment’ for artificial intelligence’ _ Arab News/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frame the public discussion about ChatGPT using metaphors such as comparing it to Netscape making the internet accessible democratizing AI , describing its language capabilities as 'rich' and 'autocomplete on steroids', highlighting its limitations due to lack of common sense or reasoning abilities, and projecting a future where AI will evolve towards more human-like understanding with augmentation by systems possessing ethical considerations.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tThe Arabic world, particularly countries like Saudi Arabia, is exceptionally well-positioned to capture the AI opportunity due to their strong data recognition capabilities and existing expertise in specific domains such as energy. These entities are investing heavily in developing local AI talent and could potentially contribute significantly to building foundation models that can be widely used.\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases of Artificial Intelligence helpful for the Arabic world, as highlighted by this article, include legal automation through AI-powered contract drafting, ethical reasoning and plagiarism detection to ensure reliable outputs, generative content creation for increased efficiency, localization of LLMs to cater to diverse linguistic needs, and domain-specific foundation models that can be made available across various industries in the Arabic world.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tEmbrace ChatGPT for creating new value in economic challenges, but also recognize the need for AI to evolve beyond current limitations.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: No need to demonize ChatGPT but AI regulation is a must\n",
      "Short Summary: The article explores ChatGPT's development by OpenAI, emphasizing its multifaceted capabilities in generating diverse content and its implications for employment in the Saudi Arabian journalism sector due to potential job displacement.\n",
      "Summary:\n",
      "1. ChatGPT, a large language model developed by OpenAI, is being used extensively in journalism across various industries, including Saudi Arabia. Its ability to understand and respond to natural language makes it valuable for generating news articles, essays, reports, poetry, and scientific content with ease.\n",
      "2. The advent of ChatGPT has sparked discussions about its impact on education, journalism, and creative fields like literature. It challenges traditional teaching methods, raises concerns over plagiarism in journalism, and threatens jobs in medical writing and some forms of artistic expression.\n",
      "3. In the realm of education, universities are exploring ways to mitigate ChatGPT's potential negative impacts by introducing oral exams, handwritten tests, and more nuanced question formats. OpenAI is also working on technologies to detect AI-generated text, aiming to protect educators' academic freedom.\n",
      "4. While the medical field is seeing ChatGPT pass proficiency examinations like the US Medical Licensing Examination, healthcare companies acknowledge it will augment rather than replace human doctors in diagnosing and decision-making processes.\n",
      "5. Literature isn't immune to AI threats either; a California design manager used ChatGPT and Midjourney to create an illustrated children's book, leading to ethical and copyright issues that sparked protests from online artists. However, AI still has limitations such as making mistakes, getting confused with nuanced prompts, and generating outdated information.\n",
      "6. Despite the concerns about over-hype surrounding AI's impact on jobs, ChatGPT could potentially serve as an equalizer in science and other fields, providing resources to developing countries and individuals lacking access to traditional research means and data.\n",
      "7. However, without regulations, the imbalance might favor AI, leading to dire consequences. Therefore, it's crucial for stakeholders to implement guidelines ensuring fair use of AI technologies while mitigating potential negative impacts on human employment and creative expression.\n",
      "Sentiment: 0\n",
      "Entities: ['New Technology Chatgpt View', 'Accord Axios Chatgpt', 'American Policy International Relation', 'Amal Mudallali', 'Url Https World Technology Advancement Arti Cial Intelligence', 'Newsroom', 'Washington Post Article Write', 'Chatgpt Midjourney Ai Program', 'Seattle Public School System Quickly Ban University College Fear Ban Ine Ective Raise Question Academic Freedom Busy Try Contain Chatgpt Potentially Negative Impact Education Change Mode Instruction Give Oral Exam Handwritten', 'New York Times']\n",
      "Topic clusters: {'ChatGPT Development': ['Development of ChatGPT technology', 'Advancements in AI language models', 'Innovations in conversational AI capabilities'], 'Ethical Implications': ['Ethical considerations in AI development', 'AI and privacy concerns', 'Moral dilemmas posed by advanced AI systems'], 'Societal Effects': ['Impact of ChatGPT on human communication', 'Changes in customer service due to AI advancements', 'Influence of AI on employment and job markets']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('ChatGPT', 28), ('AI', 24), ('human', 7), ('technology', 6), ('language', 5), ('news', 5), ('world', 5), ('generated', 5), ('OpenAI', 4), ('understand', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must _ Arab News/wordcloud_content.png'}, 'summary': {'word_frequencies': [('ChatGPT', 6), ('AI', 6), ('journalism', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must _ Arab News/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT using several metaphors, including 'revolutionary impact', 'disruptive force', 'equalizer', 'guardian of safe content', and cautioning against overhyping fear. These metaphors serve to highlight both the potential benefits and challenges associated with AI technology.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThese are the key use cases of Artificial Intelligence as highlighted by this article that can be helpful for the Arabic world. They include journalism, education, the medical field, and even literature, though with limitations due to its inability to fully replicate human understanding or create truly original content.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message of the article is that AI's potential to benefit society while also posing challenges necessitates careful regulation to ensure its positive impact outweighs any adverse effects.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of every loaded file (Optional: with highlights)\n",
    "for doc in analyzer:\n",
    "    print(doc, end=\"\\n\"+\"- \"*50+\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the files as word-docx and markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export docx files with wordclouds\n",
    "analyzer.export_docx_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a markdown file for every document\n",
    "analyzer.export_markdown_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply latent dirichlet allocation algorithm\n",
    "Algorighm selects all topics out of the articles. LLM then adds a title that summarizes the topics into categories. \n",
    "\n",
    "Thereby, all different topics can be extracted out of **all** documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=20, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=20, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=20, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the content of all documents\n",
    "all_content_tokens = [doc.content_tokens for doc in analyzer.pdf_documents]\n",
    "\n",
    "\n",
    "# Create a document-term matrix\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=5, stop_words='english', analyzer=\"word\")\n",
    "doc_term_matrix = vectorizer.fit_transform(all_content_tokens)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=20, learning_method=\"batch\", random_state=42, n_jobs=-1)\n",
    "lda.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 - Global Language Expansion: Google's Role in World Education:\n",
      "Features: write, language, google, government, help, include, internet, know, large, need, learn, learning, like, likely, look, world, generative, express, explain, ect\n",
      "Topic 1 - Language Technology's Global Impact: A New Model for News and Data Retrieval:\n",
      "Features: datum, language, say, model, replace, news, large, technology, information, include, impact, time, internet, task, arab, base, new, answer, openai, likely\n",
      "Topic 2 - Transforming Saudi Future: Technology's Impact and Opportunities:\n",
      "Features: technology, impact, say, help, believe, like, time, saudi, task, world, explain, understand, opportunity, replace, likely, need, look, ect, express, rst\n",
      "Topic 3 - Tech Giants' Collaborative Knowledge Initiatives:\n",
      "Features: say, google, answer, base, arab, microsoft, way, power, openai, people, program, time, set, university, replace, government, look, help, learn, point\n",
      "Topic 4 - Transforming Global Communication: AI and Data Revolution:\n",
      "Features: technology, development, change, datum, language, use, new, view, point, produce, impact, world, ability, work, openai, large, ect, time, like, model\n",
      "Topic 5 - Revolutionizing Communication: AI-Powered Language Tools and Their Global Impact:\n",
      "Features: write, question, create, new, generate, like, technology, program, world, need, report, news, understand, explain, learning, openai, content, use, language, people\n",
      "Topic 6 - Tech-Driven Linguistic Revolution: Saudi's Language Innovation:\n",
      "Features: model, word, technology, saudi, point, learn, time, new, base, language, large, ability, world, way, like, lead, develop, generate, datum, make\n"
     ]
    }
   ],
   "source": [
    "# Function to generate unique topics\n",
    "from pyexpat import model\n",
    "\n",
    "\n",
    "def get_unique_topics(model, vectorizer, top_n=10):\n",
    "    unique_topics = {}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        # Get the top features for the topic\n",
    "        top_features = tuple(vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-top_n - 1:-1])\n",
    "        \n",
    "        # Use the tuple as a key to ensure uniqueness\n",
    "        if top_features not in unique_topics:\n",
    "            unique_topics[top_features] = idx\n",
    "\n",
    "    return unique_topics\n",
    "\n",
    "# Generate a title for each unique topic\n",
    "def generate_topic_titles(llm, unique_topics):\n",
    "    titles = {}\n",
    "    \n",
    "    for features, idx in unique_topics.items():\n",
    "        # Create a prompt with the top features\n",
    "        prompt = (\n",
    "        \"Generate a concise and meaningful title, exactly four words long, that summarizes the following features. \"\n",
    "        \"The title should capture the main theme or topic of these features. \"\n",
    "        \"Example outputs: 'Language Revolution', 'Shaping Future Technology Trends', 'Global Knowledge Network'. Features: \"\n",
    "        f\"{', '.join(features)}\"\n",
    "        )\n",
    "        \n",
    "        # Use the LLM to generate a title\n",
    "        titles[idx] = llm.ollama.generate(model=llm.model, prompt=prompt)[\"response\"]\n",
    "    return titles\n",
    "\n",
    "\n",
    "# Get unique topics and their titles\n",
    "unique_topics = get_unique_topics(lda, vectorizer, top_n=20)\n",
    "topic_titles = generate_topic_titles(llm, unique_topics)\n",
    "\n",
    "\n",
    "analyzer.analysis[\"LDA\"] = {topic_titles[idx].replace('\"', \"\"): topics for idx, topics in zip(topic_titles, unique_topics)}\n",
    "\n",
    "# Print unique topics and their generated titles\n",
    "for idx, (title, topics) in enumerate(analyzer.analysis[\"LDA\"].items()):\n",
    "\n",
    "    print(f\"Topic {idx} - {title}:\")\n",
    "    print(f\"Features: {', '.join(topics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Term frequency inverse term frequency\n",
    "This model iterates over each document and returns those words, that do not appear often in other documents. The top n words are then used to create a topic for every article!\n",
    "\n",
    "- A high TF-IDF score (FROM_LOW_TO_HIGH = False) indicates that a word is both important within a document and rare across all document.\n",
    "- A low TF-IDF score suggests that a word is either common in the document but rare overall, or vice versa.\n",
    "\n",
    "By analyzing TF-IDF scores for a set of words, you can identify:\n",
    "Important keywords in a document\n",
    "Rare or unique words that distinguish one document from another\n",
    "Words with varying levels of importance across different documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 terms for Document 1: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "\"AI-Driven Workforce Transformation in Saudi Arabia: Impact, Training, and Innovation Opportunities\" \n",
      " ai, organization, impact, chatgpt, worker, percent, say, workforce, require, training, believe, saudi, technology, add, explain\n",
      "\n",
      "Top 15 terms for Document 2: <AI is not smarter than humans>\n",
      "\"AI-Driven Marketing Assistant: Transforming Business and Human Experience in the Digital Age\" \n",
      " technology, ai, marketing, business, help, like, experience, able, life, human, time, assistant, day, di, campaign\n",
      "\n",
      "Top 15 terms for Document 3: <ChatGPT>\n",
      "\"AI-Driven Linguistic Transformation: OpenAI's Technological Impact on Global Society\" \n",
      " ai, chatgpt, human, platform, tool, technology, language, society, development, change, datum, https, openai, use, view\n",
      "\n",
      "Top 15 terms for Document 4: <ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts>\n",
      "\"AI-Driven Chatbot for Human Job Content Creation: A Future Trend\" \n",
      " ai, team, chatbot, job, plan, tool, create, like, chatgpt, use, need, explain, think, company, human\n",
      "\n",
      "Top 15 terms for Document 5: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "\"AI-Powered Chatbots: Global Knowledge Networking & Human-Tech Interaction\" \n",
      " ai, chatgpt, billion, say, chatbot, search, web, google, human, answer, text, tech, exam, openai, program\n",
      "\n",
      "Top 15 terms for Document 6: <‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host>\n",
      "\"AI-Driven Journalism: Revolutionizing News Accuracy and Impact with ChatGPT\" \n",
      " ai, job, datum, language, training, chatgpt, say, response, model, journalist, provide, accuracy, news, replace, human\n",
      "\n",
      "Top 15 terms for Document 7: <ChatGPT is the ‘Netscape moment’ for artificial intelligence’>\n",
      "\"AI-Driven Language Engagement: Saudi Arabia's Technological Revolution\" \n",
      " model, ai, example, text, train, saudi, word, technology, chatgpt, generate, new, enable, application, engage, point\n",
      "\n",
      "Top 15 terms for Document 8: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "\"ChatGPT, AI, and Human Collaboration in Education: Advancements and Impact\" \n",
      " chatgpt, ai, generate, question, write, human, article, eld, fear, accord, threat, exam, education, report, raise\n"
     ]
    }
   ],
   "source": [
    "# Create a TfidfVectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', norm=\"l2\", analyzer=\"word\", min_df=3)\n",
    "\n",
    "# Fit and transform the documents into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_content_tokens)\n",
    "\n",
    "# Get the feature names (i.e., words)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for better readability\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Show the TF-IDF values for each term in each document\n",
    "#print(\"TF-IDF Matrix:\")\n",
    "#print(df)\n",
    "\n",
    "# Display the most important words (top N) for each document\n",
    "TOP_N = 15\n",
    "FROM_LOW_TO_HIGH = False\n",
    "\n",
    "analyzer.analysis[\"TFIDF\"] = dict()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    doc = analyzer.pdf_documents[i]\n",
    "    print(f\"\\nTop {TOP_N} terms for Document {i + 1}: <{doc.title}>\")\n",
    "          \n",
    "    # Generate a title for each unique topic\n",
    "    top_terms = row.sort_values(ascending=FROM_LOW_TO_HIGH).head(TOP_N*2)\n",
    "    \n",
    "    indices = top_terms.index\n",
    "    values = top_terms.values\n",
    "    \n",
    "    # Create a prompt with the top features\n",
    "    prompt = (\n",
    "        \"Generate a concise and meaningful title, exactly four words long, that summarizes the following features. \"\n",
    "        \"The title should capture the main theme or topic of these features. \"\n",
    "        \"Example outputs: 'Language Revolution', 'Shaping Future Technology Trends', 'Global Knowledge Network'. Features: \"\n",
    "        f\"{'\\n'.join([f'{str(indices[i])} - {values[i]}' for i in range(len(indices))])}\"\n",
    "        )\n",
    "            \n",
    "    # Use the LLM to generate a title\n",
    "    title = llm.ollama.generate(model=llm.model, prompt=prompt)[\"response\"]\n",
    "    \n",
    "    analyzer.analysis[\"TFIDF\"].update({doc: {\"title\": title, \"terms\": top_terms[:TOP_N]}})\n",
    "    \n",
    "    print(title, \"\\n\", \", \".join(top_terms[:TOP_N].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:23:16\t Answering question <How do the media in this artic...>\n",
      "17:23:25\t Answering question <Which role does or might the A...>\n",
      "17:23:29\t Answering question <Which use cases of Artificial ...>\n",
      "17:23:36\t Answering question <What is the final message of t...>\n"
     ]
    }
   ],
   "source": [
    "content = json.dumps({doc.title: doc.content for doc in analyzer})\n",
    "\n",
    "# Iterates over each question, provides answers to LLM and let them summarize\n",
    "for question in questions:\n",
    "    content = {doc.title: doc.answers.get(question) for doc in analyzer}\n",
    "    response = llm.answer_question(text=json.dumps(content), question=question, multiple_articles=True)\n",
    "    analyzer.analysis[question] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:41:39\t Answering question <Attached are the topics of eve...>\n"
     ]
    }
   ],
   "source": [
    "answers_questions = dict()\n",
    "# Iterates over each question, provides answers to LLM and let them summarize\n",
    "topic_question_all = (\n",
    "    \"Attached are the topics of every article. \"\n",
    "    \"What **perspectives and aspects** are being widely covered? Which aspects are being ignored? \"\n",
    "    \"In your answer consider topics such as, but not only, data privacy, costs/affordability, know-how, complexity, accuracy, accessibility, bias (towards age, gender, religion, sexuality), risks, opportunity, perception, limitations.\"\n",
    "    \"These are the topics of all arcticles: \")\n",
    "\n",
    "# Example usage:\n",
    "topic_clusters = {doc.title: [value for value in doc.topic_clusters.values()] for doc in analyzer}\n",
    "content_topics = flatten_dict(topic_clusters)\n",
    "response = llm.answer_question(text=json.dumps(content_topics), question=topic_question_all, multiple_articles=True)\n",
    "analyzer.analysis[\"topic_question\"] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Dirichlet Allocation topics\n",
      "\tGlobal Language Expansion: Google's Role in World Education\n",
      "\tLanguage Technology's Global Impact: A New Model for News and Data Retrieval\n",
      "\tTransforming Saudi Future: Technology's Impact and Opportunities\n",
      "\tTech Giants' Collaborative Knowledge Initiatives\n",
      "\tTransforming Global Communication: AI and Data Revolution\n",
      "\tRevolutionizing Communication: AI-Powered Language Tools and Their Global Impact\n",
      "\tTech-Driven Linguistic Revolution: Saudi's Language Innovation\n",
      "TDIF for every article\n",
      "\t\"AI-Driven Workforce Transformation in Saudi Arabia: Impact, Training, and Innovation Opportunities\"\n",
      "\t\"AI-Driven Marketing Assistant: Transforming Business and Human Experience in the Digital Age\"\n",
      "\t\"AI-Driven Linguistic Transformation: OpenAI's Technological Impact on Global Society\"\n",
      "\t\"AI-Driven Chatbot for Human Job Content Creation: A Future Trend\"\n",
      "\t\"AI-Powered Chatbots: Global Knowledge Networking & Human-Tech Interaction\"\n",
      "\t\"AI-Driven Journalism: Revolutionizing News Accuracy and Impact with ChatGPT\"\n",
      "\t\"AI-Driven Language Engagement: Saudi Arabia's Technological Revolution\"\n",
      "\t\"ChatGPT, AI, and Human Collaboration in Education: Advancements and Impact\"\n",
      "\n",
      "How do the media in this article frame the public discussion about ChatGPT? Are there certain metaphors that keep cropping up?\n",
      "\tThe media frames ChatGPT as a transformative force that is shaping the future of the Saudi workforce using various metaphors such as 'wave of change', 'useful tool for boosting productivity', and 'embracing innovation to boost productivity'. These metaphors emphasize ChatGPT as both challenging traditional employment roles and augmenting capabilities, reflecting the dual nature of AI technologies.\n",
      "Reason: The articles depict ChatGPT as a transformative force, emphasizing its impact on productivity and society. Several recurring metaphors include: 'wave of change', 'useful tool for boosting productivity', 'embracing innovation to boost productivity', 'AI's paradoxical nature alongside positive impact on recruitment', describing ChatGPT as a wave that both challenges traditional roles and augments capabilities. These metaphors convey a sense of change, evolution, and positivity associated with the introduction of AI technologies like ChatGPT.\n",
      "\n",
      "Which role does or might the Arabic World play in the development of Artificial Intelligence?\n",
      "\tThe Arabic world, particularly countries like Saudi Arabia and UAE, are exceptionally well-positioned to capture the AI opportunity due to their strong data recognition capabilities and existing expertise in specific domains such as energy. These entities are investing heavily in developing local AI talent and could potentially contribute significantly to building foundation models that can be widely used.\n",
      "Reason: The articles indicate that the Arabic world, particularly countries like the UAE and Saudi Arabia, are showing significant interest and investment in AI. This suggests a potential for contributing to its development and application. Furthermore, these entities are investing heavily in developing local AI talent, indicating an active role in building foundation models that can be widely used. The article also mentions that ChatGPT is the 'Netscape moment' for artificial intelligence, implying that Arabic World's expertise and data recognition capabilities could lead to significant contributions in this field.\n",
      "\n",
      "Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases highlighted in these articles are personal assistance via virtual assistants, language translation tools like Google Translate, AI's potential in revolutionizing business operations and marketing strategies globally, content creation and summarization, legal automation through AI-powered contract drafting, ethical reasoning and plagiarism detection, generative content creation for increased efficiency, localization of LLMs to cater to diverse linguistic needs, and domain-specific foundation models.\n",
      "Reason: The articles provide several key use cases of AI that are beneficial to the Arabic world. These include: (1) Personal assistance via virtual assistants capable of handling diverse tasks, (2) Language translation tools like Google Translate to bridge linguistic gaps, (3) Revolutionizing business operations and marketing strategies globally through AI, (4) Content creation in advertising campaigns, content generation, summarization, and providing help to human talent, (5) Legal automation through AI-powered contract drafting, (6) Ethical reasoning and plagiarism detection for reliable outputs, (7) Generative content creation for increased efficiency, (8) Localization of language models to cater to diverse linguistic needs, and (9) Domain-specific foundation models that can be made available across various industries in the Arabic world.\n",
      "\n",
      "What is the final message of the article that the author wants to convey?\n",
      "\tCautious Optimism with Responsible Use, Caution on Negative Impacts\n",
      "Reason: The final messages from these articles highlight a balanced, ethical approach to AI integration. They emphasize leveraging ChatGPT's capabilities while respecting human intelligence (ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts), the need for responsible use of AI technology to promote human wellbeing and a better future, caution against potential negative impacts that require careful regulation and ethical consideration (No need to demonize ChatGPT but AI regulation is a must). The author conveys a message of cautious optimism for the responsible use of AI, acknowledging both its benefits and challenges.\n",
      "\n",
      "What perspectives and aspects are being widely covered in these Arabic newspaper articles about ChatGPT and AI's impact on society? Which aspects are being ignored?\n",
      "\tThe articles widely cover perspectives such as job displacement due to AI, regulatory measures for AI use, societal concerns about AI's impact, potential biases in AI algorithms, investment in AI research, regional regulations for AI use, and the influence of AI on news reporting and educational tools. They also discuss Arabic media coverage on ChatGPT and its applications. However, topics like AI's positive contributions to cultural preservation or creativity in arts are largely ignored. Opportunities related to AI's potential role in addressing societal challenges such as misinformation and job market changes are not extensively covered.\n",
      "Reason: The articles extensively cover several key aspects related to the integration of ChatGPT and Artificial Intelligence (AI) into various sectors, particularly focusing on Saudi Arabia. These include: 1) The potential productivity boost for the workforce through AI applications, machine learning, and regulations for its use, as well as job displacement concerns and necessary measures to ensure fairness and minimize biases; 2) The comparison of AI's capabilities with human intelligence, particularly in areas like education and news reporting; 3) ChatGPT's performance surpassing copywriters in specific tasks such as advertisements, highlighting its potential impact on journalism and media landscape; 4) Public perceptions regarding the Arab world's preparedness for AI-driven technologies, with concerns about misuse and regulatory measures; 5) The role of ChatGPT in the newsroom, including its interaction with journalists and its use as an opinion shaper, raising questions about user preferences and privacy. Additionally, these articles touch upon limitations, potential biases in AI algorithms, investment in AI research, local startups' collaborations, and ethical considerations; 6) The broader societal implications of advanced AI technologies such as misinformation spread, job market changes, and moral dilemmas posed by these systems. However, the articles seem to largely overlook discussions on how AI might contribute positively to cultural preservation or the potential for AI-driven creativity in arts and entertainment. Furthermore, while there is extensive focus on the technical capabilities of ChatGPT, its influence on human communication and social dynamics are underrepresented.\n"
     ]
    }
   ],
   "source": [
    "lda = analyzer.analysis.get(\"LDA\")\n",
    "print(f\"Latent Dirichlet Allocation topics\\n\\t{'\\n\\t'.join(lda.keys())}\")\n",
    "\n",
    "\n",
    "tfidf = [elem.get(\"title\") for elem in flatten_list(analyzer.analysis.get(\"TFIDF\").values())]\n",
    "print(f\"TDIF for every article\\n\\t{'\\n\\t'.join(tfidf)}\")\n",
    "\n",
    "\n",
    "for question in questions + [\"topic_question\"]:\n",
    "    answer = analyzer.analysis.get(question)\n",
    "    print(f\"\\n{answer.get(\"question\")}\\n\\t{answer.get(\"answer\")}\\nReason: {answer.get(\"reasoning\")}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
