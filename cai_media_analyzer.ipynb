{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "from scripts.ollama_handler import OllamaMediaAnalysis\n",
    "from scripts.file_analyzer import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model for ollama\n",
    "# ollama.list() # to get all models\n",
    "MODEL = \"granite3.1-moe:3b-instruct-q8_0\" #\"granite3.1-moe\" #\"granite3.1-dense:8b-instruct-q8_0\" #\"granite3.1-dense:8b\"\n",
    "#SYSTEM_PROMPT = f\"You are a senior researcher, working on a media analysis of articles published in arabic newspapers about ChatGPT and the effect of Artificial Intelligence on society. For your answers only focus on topics that were mentioned in the text without adding any further information. Before answering, thoroughly think about the task, the content provided and build your answer with chain of thought reasoning.\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a senior researcher conducting a media analysis of Arabic newspaper articles \"\n",
    "    \"about ChatGPT and the societal effects of Artificial Intelligence. Your role is to focus \"\n",
    "    \"exclusively on the topics mentioned in the provided text, without introducing external information. \"\n",
    "    \"Before responding, carefully analyze the task, thoroughly evaluate the content of the articles, \"\n",
    "    \"and construct your answer using a clear chain of thought reasoning approach.\"\n",
    ")\n",
    "\n",
    "# MAY TAKE LONG TIME! Whether all files should be processed (indicates Ollama interactions)\n",
    "PROCESS_DOCUMENTS = True\n",
    "\n",
    "# Load spacy model\n",
    "SPACY_MODEL = \"en_core_web_lg\"\n",
    "\n",
    "\n",
    "# Set folder paths\n",
    "DOCUMENTS_FOLDER = \"docs\"\n",
    "FILES_FOLDER = os.path.join(DOCUMENTS_FOLDER, \"DOCX\") # PDFs\n",
    "OUTPUT_FOLDER = os.path.join(DOCUMENTS_FOLDER, \"Processed\", MODEL)\n",
    "EXPORT_FILE_NAME = f\"{datetime.now().strftime(\"%y%m%d\")}-{MODEL}-processed_documents.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d: dict):\n",
    "    \"\"\"Recursively flatten a dictionary with nested lists.\"\"\"\n",
    "    flattened_dict = dict()\n",
    "    for k, v in d.items():\n",
    "        flat_list = []\n",
    "        if isinstance(v, list):\n",
    "            flat_list.extend(flatten_list(v))\n",
    "        elif isinstance(v, dict):\n",
    "            flat_list.extend(flatten_dict(v))\n",
    "        \n",
    "        flattened_dict[k] = flat_list\n",
    "    return flattened_dict\n",
    "\n",
    "def flatten_list(l: list):\n",
    "    \"\"\"Recursively flatten a nested list.\"\"\"\n",
    "    flat_list = []\n",
    "    for item in l:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize File Analyzer\n",
    "Handes all files, folder processing, text extraction, question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define questions for the analyzer\n",
    "questions =  [\n",
    "    \"How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\",\n",
    "    \"Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\",\n",
    "    \"Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\",\n",
    "    \"What is the final message of the article that the author wants to convey? Keep your answer short and precise!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm as instance of OllamaMediaAnalysis\n",
    "llm = OllamaMediaAnalysis(model_name=MODEL, system_prompt=SYSTEM_PROMPT, debug=True)\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = FileAnalyzer(ollama_handler=llm, entity_collection=\"spacy\", spacy_model=SPACY_MODEL, file_name=EXPORT_FILE_NAME, output_folder=OUTPUT_FOLDER, questions=questions, debug=False, speed_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:04:44 Analyzing file from folder: ChatGPT AI grows more powerful as we become more predictable_standardizedlayout.docx\n",
      "01:04:44\t Adding paragraph 1/11 with 32 characters\n",
      "01:04:44\t Adding paragraph 2/11 with 19 characters\n",
      "01:04:44\t Adding paragraph 3/11 with 13 characters\n",
      "01:04:44\t Adding paragraph 4/11 with 19 characters\n",
      "01:04:44\t Adding paragraph 5/11 with 36 characters\n",
      "01:04:44\t Adding paragraph 6/11 with 20 characters\n",
      "01:04:44\t Adding paragraph 7/11 with 11 characters\n",
      "01:04:44\t Adding paragraph 8/11 with 0 characters\n",
      "01:04:44\t Adding paragraph 9/11 with 0 characters\n",
      "01:04:44\t Adding paragraph 10/11 with 0 characters\n",
      "01:04:44\t Adding paragraph 11/11 with 5560 characters\n",
      "01:04:44\t Create Docx document <ChatGPT AI grows mor...> with content of length 5539\n",
      "01:04:44 Initialized Document: <ChatGPT AI grows more powerful as we become more predictable>\n",
      "01:04:44\t Generating tokenized content\n",
      "01:04:44\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The...lace it entirely.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:04:54\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n    \"short_summary\": ...with constraints.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:04:55\t Generating summary\n",
      "01:05:10\t Finding answer to 4 questions\n",
      "01:05:10\t Answering question <How do the media in this artic...>\n",
      "01:05:23\t Answering question <Which role does or might the A...>\n",
      "01:05:24\t Answering question <Which use cases of Artificial ...>\n",
      "01:05:27\t Answering question <What is the final message of t...>\n",
      "01:05:30\t Analyzing sentiment\n",
      "01:05:40\t Extracting entities from text\n",
      "01:05:40\t Found 10 in text\n",
      "Temporarily storing documents\n",
      "01:05:51 Analyzing file from folder: ChatGPT is the ‘Netscape moment’ for artificial intelligence’_standardizedlayout.docx\n",
      "01:05:51\t Adding paragraph 1/11 with 32 characters\n",
      "01:05:51\t Adding paragraph 2/11 with 21 characters\n",
      "01:05:51\t Adding paragraph 3/11 with 13 characters\n",
      "01:05:51\t Adding paragraph 4/11 with 19 characters\n",
      "01:05:51\t Adding paragraph 5/11 with 34 characters\n",
      "01:05:51\t Adding paragraph 6/11 with 23 characters\n",
      "01:05:51\t Adding paragraph 7/11 with 11 characters\n",
      "01:05:51\t Adding paragraph 8/11 with 0 characters\n",
      "01:05:51\t Adding paragraph 9/11 with 0 characters\n",
      "01:05:51\t Adding paragraph 10/11 with 0 characters\n",
      "01:05:51\t Adding paragraph 11/11 with 6370 characters\n",
      "01:05:51\t Create Docx document <ChatGPT is the ‘Nets...> with content of length 6355\n",
      "01:05:51 Initialized Document: <ChatGPT is the ‘Netscape moment' for artificial intelligence'>\n",
      "01:05:51\t Generating tokenized content\n",
      "01:05:51\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...en AI development.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:06:02\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...tegic initiatives.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:06:04\t Generating summary\n",
      "01:06:21\t Finding answer to 4 questions\n",
      "01:06:21\t Answering question <How do the media in this artic...>\n",
      "01:06:38\t Answering question <Which role does or might the A...>\n",
      "01:06:40\t Answering question <Which use cases of Artificial ...>\n",
      "01:06:42\t Answering question <What is the final message of t...>\n",
      "01:06:44\t Analyzing sentiment\n",
      "01:06:57\t Extracting entities from text\n",
      "01:06:57\t Found 6 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the ‘Netscape moment' for artificial intelligence'\n",
      "Temporarily storing documents\n",
      "01:07:09 Analyzing file from folder: ChatGPT outperforms copywriters in STEP Conference’s outdoor adverts_standardizedlayout.docx\n",
      "01:07:09\t Adding paragraph 1/16 with 50 characters\n",
      "01:07:09\t Adding paragraph 2/16 with 19 characters\n",
      "01:07:09\t Adding paragraph 3/16 with 13 characters\n",
      "01:07:09\t Adding paragraph 4/16 with 19 characters\n",
      "01:07:09\t Adding paragraph 5/16 with 39 characters\n",
      "01:07:09\t Adding paragraph 6/16 with 26 characters\n",
      "01:07:09\t Adding paragraph 7/16 with 11 characters\n",
      "01:07:09\t Adding paragraph 8/16 with 0 characters\n",
      "01:07:09\t Adding paragraph 9/16 with 0 characters\n",
      "01:07:09\t Adding paragraph 10/16 with 0 characters\n",
      "01:07:09\t Adding paragraph 11/16 with 0 characters\n",
      "01:07:09\t Adding paragraph 12/16 with 68 characters\n",
      "01:07:09\t Adding paragraph 13/16 with 0 characters\n",
      "01:07:09\t Adding paragraph 14/16 with 212 characters\n",
      "01:07:09\t Adding paragraph 15/16 with 0 characters\n",
      "01:07:09\t Adding paragraph 16/16 with 2705 characters\n",
      "01:07:09\t Create Docx document <ChatGPT outperforms ...> with content of length 2952\n",
      "01:07:09 Initialized Document: <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>\n",
      "01:07:09\t Generating tokenized content\n",
      "01:07:10\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"STEP...AI in human roles.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:07:15\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n    \"short_summary\": ...ity within teams.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:07:15\t Generating summary\n",
      "01:07:24\t Finding answer to 4 questions\n",
      "01:07:24\t Answering question <How do the media in this artic...>\n",
      "01:07:34\t Answering question <Which role does or might the A...>\n",
      "01:07:36\t Answering question <Which use cases of Artificial ...>\n",
      "01:07:39\t Answering question <What is the final message of t...>\n",
      "01:07:41\t Analyzing sentiment\n",
      "01:07:46\t Extracting entities from text\n",
      "01:07:46\t Found 1 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference's outdoor adverts\n",
      "Temporarily storing documents\n",
      "01:07:54 Analyzing file from folder: AI is not smarter than humans_standardizedlayout.docx\n",
      "01:07:54\t Adding paragraph 1/11 with 32 characters\n",
      "01:07:54\t Adding paragraph 2/11 with 19 characters\n",
      "01:07:54\t Adding paragraph 3/11 with 13 characters\n",
      "01:07:54\t Adding paragraph 4/11 with 19 characters\n",
      "01:07:54\t Adding paragraph 5/11 with 36 characters\n",
      "01:07:54\t Adding paragraph 6/11 with 23 characters\n",
      "01:07:54\t Adding paragraph 7/11 with 11 characters\n",
      "01:07:54\t Adding paragraph 8/11 with 0 characters\n",
      "01:07:54\t Adding paragraph 9/11 with 0 characters\n",
      "01:07:54\t Adding paragraph 10/11 with 0 characters\n",
      "01:07:54\t Adding paragraph 11/11 with 4564 characters\n",
      "01:07:54\t Create Docx document <AI is not smarter th...> with content of length 4548\n",
      "01:07:54 Initialized Document: <AI is not smarter than humans>\n",
      "01:07:54\t Generating tokenized content\n",
      "01:07:54\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n\"short_summary\": \"The... human connections.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:08:03\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n    \"short_summary\": ...uman connections.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:08:04\t Generating summary\n",
      "01:08:18\t Finding answer to 4 questions\n",
      "01:08:18\t Answering question <How do the media in this artic...>\n",
      "01:08:30\t Answering question <Which role does or might the A...>\n",
      "01:08:32\t Answering question <Which use cases of Artificial ...>\n",
      "01:08:36\t Answering question <What is the final message of t...>\n",
      "01:08:38\t Analyzing sentiment\n",
      "01:08:47\t Extracting entities from text\n",
      "01:08:47\t Found 6 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans\n",
      "Temporarily storing documents\n",
      "01:08:56 Analyzing file from folder: No need to demonize ChatGPT but AI regulation is a must_standardizedlayout.docx\n",
      "01:08:56\t Adding paragraph 1/12 with 32 characters\n",
      "01:08:56\t Adding paragraph 2/12 with 19 characters\n",
      "01:08:56\t Adding paragraph 3/12 with 13 characters\n",
      "01:08:56\t Adding paragraph 4/12 with 19 characters\n",
      "01:08:56\t Adding paragraph 5/12 with 38 characters\n",
      "01:08:56\t Adding paragraph 6/12 with 27 characters\n",
      "01:08:56\t Adding paragraph 7/12 with 11 characters\n",
      "01:08:56\t Adding paragraph 8/12 with 0 characters\n",
      "01:08:56\t Adding paragraph 9/12 with 0 characters\n",
      "01:08:56\t Adding paragraph 10/12 with 0 characters\n",
      "01:08:56\t Adding paragraph 11/12 with 55 characters\n",
      "01:08:56\t Adding paragraph 12/12 with 7475 characters\n",
      "01:08:56\t Create Docx document <No need to demonize ...> with content of length 7488\n",
      "01:08:56 Initialized Document: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "01:08:56\t Generating tokenized content\n",
      "01:08:56\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...eat to human work.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:09:10\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...ance AI integration.\" }', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:09:11\t Generating summary\n",
      "01:09:31\t Finding answer to 4 questions\n",
      "01:09:31\t Answering question <How do the media in this artic...>\n",
      "01:09:46\t Answering question <Which role does or might the A...>\n",
      "01:09:50\t Answering question <Which use cases of Artificial ...>\n",
      "01:10:07\t Answering question <What is the final message of t...>\n",
      "01:10:23\t Analyzing sentiment\n",
      "01:10:37\t Extracting entities from text\n",
      "01:10:37\t Found 7 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must\n",
      "Temporarily storing documents\n",
      "01:10:52 Analyzing file from folder: Is the Arab world ready for the uncertain age of AI-powered web tools_standardizedlayout.docx\n",
      "01:10:52\t Adding paragraph 1/23 with 32 characters\n",
      "01:10:52\t Adding paragraph 2/23 with 19 characters\n",
      "01:10:52\t Adding paragraph 3/23 with 13 characters\n",
      "01:10:52\t Adding paragraph 4/23 with 19 characters\n",
      "01:10:52\t Adding paragraph 5/23 with 35 characters\n",
      "01:10:52\t Adding paragraph 6/23 with 47 characters\n",
      "01:10:52\t Adding paragraph 7/23 with 11 characters\n",
      "01:10:52\t Adding paragraph 8/23 with 0 characters\n",
      "01:10:52\t Adding paragraph 9/23 with 0 characters\n",
      "01:10:52\t Adding paragraph 10/23 with 0 characters\n",
      "01:10:52\t Adding paragraph 11/23 with 69 characters\n",
      "01:10:52\t Adding paragraph 12/23 with 114 characters\n",
      "01:10:52\t Adding paragraph 13/23 with 104 characters\n",
      "01:10:52\t Adding paragraph 14/23 with 0 characters\n",
      "01:10:52\t Adding paragraph 15/23 with 5372 characters\n",
      "01:10:52\t Adding paragraph 16/23 with 0 characters\n",
      "01:10:52\t Adding paragraph 17/23 with 9 characters\n",
      "01:10:52\t Adding paragraph 18/23 with 55 characters\n",
      "01:10:52\t Adding paragraph 19/23 with 74 characters\n",
      "01:10:52\t Adding paragraph 20/23 with 55 characters\n",
      "01:10:52\t Adding paragraph 21/23 with 55 characters\n",
      "01:10:52\t Adding paragraph 22/23 with 0 characters\n",
      "01:10:52\t Adding paragraph 23/23 with 5093 characters\n",
      "01:10:52\t Create Docx document <Is the Arab world re...> with content of length 10901\n",
      "01:10:52 Initialized Document: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "01:10:52\t Generating tokenized content\n",
      "01:10:52\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"T... humans completely.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:11:10\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n    \"short_summary\": ...der perspectives.\"\\n}\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:11:11\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value='The integration of advan...across various sectors.', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:11:35\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value=\"In the rapidly evolving ...gating potential risks.\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:11:58\t Finding answer to 4 questions\n",
      "01:11:58\t Answering question <How do the media in this artic...>\n",
      "01:12:17\t Answering question <Which role does or might the A...>\n",
      "01:12:34\t Answering question <Which use cases of Artificial ...>\n",
      "01:12:53\t Answering question <What is the final message of t...>\n",
      "01:13:11\t Analyzing sentiment\n",
      "01:13:27\t Extracting entities from text\n",
      "01:13:27\t Found 20 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools\n",
      "Temporarily storing documents\n",
      "01:13:44 Analyzing file from folder: ‘I am not here to take your job,’ ChatGPT tells Frankly Speaking host_standardizedlayout.docx\n",
      "01:13:44\t Adding paragraph 1/230 with 32 characters\n",
      "01:13:44\t Adding paragraph 2/230 with 19 characters\n",
      "01:13:44\t Adding paragraph 3/230 with 13 characters\n",
      "01:13:44\t Adding paragraph 4/230 with 19 characters\n",
      "01:13:44\t Adding paragraph 5/230 with 36 characters\n",
      "01:13:44\t Adding paragraph 6/230 with 22 characters\n",
      "01:13:44\t Adding paragraph 7/230 with 11 characters\n",
      "01:13:44\t Adding paragraph 8/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 9/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 10/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 11/230 with 69 characters\n",
      "01:13:44\t Adding paragraph 12/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 13/230 with 150 characters\n",
      "01:13:44\t Adding paragraph 14/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 15/230 with 138 characters\n",
      "01:13:44\t Adding paragraph 16/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 17/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 18/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 19/230 with 31 characters\n",
      "01:13:44\t Adding paragraph 20/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 21/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 22/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 23/230 with 69 characters\n",
      "01:13:44\t Adding paragraph 24/230 with 41 characters\n",
      "01:13:44\t Adding paragraph 25/230 with 69 characters\n",
      "01:13:44\t Adding paragraph 26/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 27/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 28/230 with 40 characters\n",
      "01:13:44\t Adding paragraph 29/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 30/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 31/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 32/230 with 26 characters\n",
      "01:13:44\t Adding paragraph 33/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 34/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 35/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 36/230 with 19 characters\n",
      "01:13:44\t Adding paragraph 37/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 38/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 39/230 with 24 characters\n",
      "01:13:44\t Adding paragraph 40/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 41/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 42/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 43/230 with 13 characters\n",
      "01:13:44\t Adding paragraph 44/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 45/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 46/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 47/230 with 39 characters\n",
      "01:13:44\t Adding paragraph 48/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 49/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 50/230 with 120 characters\n",
      "01:13:44\t Adding paragraph 51/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 52/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 53/230 with 63 characters\n",
      "01:13:44\t Adding paragraph 54/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 55/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 56/230 with 32 characters\n",
      "01:13:44\t Adding paragraph 57/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 58/230 with 39 characters\n",
      "01:13:44\t Adding paragraph 59/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 60/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 61/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 62/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 63/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 64/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 65/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 66/230 with 113 characters\n",
      "01:13:44\t Adding paragraph 67/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 68/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 69/230 with 37 characters\n",
      "01:13:44\t Adding paragraph 70/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 71/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 72/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 73/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 74/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 75/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 76/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 77/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 78/230 with 39 characters\n",
      "01:13:44\t Adding paragraph 79/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 80/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 81/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 82/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 83/230 with 20 characters\n",
      "01:13:44\t Adding paragraph 84/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 85/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 86/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 87/230 with 82 characters\n",
      "01:13:44\t Adding paragraph 88/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 89/230 with 13 characters\n",
      "01:13:44\t Adding paragraph 90/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 91/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 92/230 with 37 characters\n",
      "01:13:44\t Adding paragraph 93/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 94/230 with 67 characters\n",
      "01:13:44\t Adding paragraph 95/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 96/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 97/230 with 145 characters\n",
      "01:13:44\t Adding paragraph 98/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 99/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 100/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 101/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 102/230 with 37 characters\n",
      "01:13:44\t Adding paragraph 103/230 with 83 characters\n",
      "01:13:44\t Adding paragraph 104/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 105/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 106/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 107/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 108/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 109/230 with 81 characters\n",
      "01:13:44\t Adding paragraph 110/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 111/230 with 51 characters\n",
      "01:13:44\t Adding paragraph 112/230 with 82 characters\n",
      "01:13:44\t Adding paragraph 113/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 114/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 115/230 with 21 characters\n",
      "01:13:44\t Adding paragraph 116/230 with 64 characters\n",
      "01:13:44\t Adding paragraph 117/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 118/230 with 20 characters\n",
      "01:13:44\t Adding paragraph 119/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 120/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 121/230 with 52 characters\n",
      "01:13:44\t Adding paragraph 122/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 123/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 124/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 125/230 with 39 characters\n",
      "01:13:44\t Adding paragraph 126/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 127/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 128/230 with 23 characters\n",
      "01:13:44\t Adding paragraph 129/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 130/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 131/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 132/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 133/230 with 137 characters\n",
      "01:13:44\t Adding paragraph 134/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 135/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 136/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 137/230 with 50 characters\n",
      "01:13:44\t Adding paragraph 138/230 with 66 characters\n",
      "01:13:44\t Adding paragraph 139/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 140/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 141/230 with 30 characters\n",
      "01:13:44\t Adding paragraph 142/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 143/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 144/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 145/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 146/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 147/230 with 16 characters\n",
      "01:13:44\t Adding paragraph 148/230 with 66 characters\n",
      "01:13:44\t Adding paragraph 149/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 150/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 151/230 with 13 characters\n",
      "01:13:44\t Adding paragraph 152/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 153/230 with 70 characters\n",
      "01:13:44\t Adding paragraph 154/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 155/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 156/230 with 18 characters\n",
      "01:13:44\t Adding paragraph 157/230 with 81 characters\n",
      "01:13:44\t Adding paragraph 158/230 with 84 characters\n",
      "01:13:44\t Adding paragraph 159/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 160/230 with 70 characters\n",
      "01:13:44\t Adding paragraph 161/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 162/230 with 63 characters\n",
      "01:13:44\t Adding paragraph 163/230 with 64 characters\n",
      "01:13:44\t Adding paragraph 164/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 165/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 166/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 167/230 with 26 characters\n",
      "01:13:44\t Adding paragraph 168/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 169/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 170/230 with 17 characters\n",
      "01:13:44\t Adding paragraph 171/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 172/230 with 56 characters\n",
      "01:13:44\t Adding paragraph 173/230 with 79 characters\n",
      "01:13:44\t Adding paragraph 174/230 with 70 characters\n",
      "01:13:44\t Adding paragraph 175/230 with 9 characters\n",
      "01:13:44\t Adding paragraph 176/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 177/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 178/230 with 70 characters\n",
      "01:13:44\t Adding paragraph 179/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 180/230 with 62 characters\n",
      "01:13:44\t Adding paragraph 181/230 with 68 characters\n",
      "01:13:44\t Adding paragraph 182/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 183/230 with 82 characters\n",
      "01:13:44\t Adding paragraph 184/230 with 23 characters\n",
      "01:13:44\t Adding paragraph 185/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 186/230 with 71 characters\n",
      "01:13:44\t Adding paragraph 187/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 188/230 with 121 characters\n",
      "01:13:44\t Adding paragraph 189/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 190/230 with 68 characters\n",
      "01:13:44\t Adding paragraph 191/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 192/230 with 64 characters\n",
      "01:13:44\t Adding paragraph 193/230 with 62 characters\n",
      "01:13:44\t Adding paragraph 194/230 with 0 characters\n",
      "01:13:44\t Adding paragraph 195/230 with 81 characters\n",
      "01:13:44\t Adding paragraph 196/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 197/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 198/230 with 81 characters\n",
      "01:13:44\t Adding paragraph 199/230 with 69 characters\n",
      "01:13:44\t Adding paragraph 200/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 201/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 202/230 with 40 characters\n",
      "01:13:44\t Adding paragraph 203/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 204/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 205/230 with 120 characters\n",
      "01:13:44\t Adding paragraph 206/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 207/230 with 78 characters\n",
      "01:13:44\t Adding paragraph 208/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 209/230 with 24 characters\n",
      "01:13:44\t Adding paragraph 210/230 with 82 characters\n",
      "01:13:44\t Adding paragraph 211/230 with 33 characters\n",
      "01:13:44\t Adding paragraph 212/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 213/230 with 31 characters\n",
      "01:13:44\t Adding paragraph 214/230 with 81 characters\n",
      "01:13:44\t Adding paragraph 215/230 with 80 characters\n",
      "01:13:44\t Adding paragraph 216/230 with 62 characters\n",
      "01:13:44\t Adding paragraph 217/230 with 74 characters\n",
      "01:13:44\t Adding paragraph 218/230 with 66 characters\n",
      "01:13:44\t Adding paragraph 219/230 with 15 characters\n",
      "01:13:44\t Adding paragraph 220/230 with 81 characters\n",
      "01:13:44\t Adding paragraph 221/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 222/230 with 76 characters\n",
      "01:13:44\t Adding paragraph 223/230 with 64 characters\n",
      "01:13:44\t Adding paragraph 224/230 with 73 characters\n",
      "01:13:44\t Adding paragraph 225/230 with 77 characters\n",
      "01:13:44\t Adding paragraph 226/230 with 72 characters\n",
      "01:13:44\t Adding paragraph 227/230 with 70 characters\n",
      "01:13:44\t Adding paragraph 228/230 with 42 characters\n",
      "01:13:44\t Adding paragraph 229/230 with 75 characters\n",
      "01:13:44\t Adding paragraph 230/230 with 66 characters\n",
      "01:13:44\t Create Docx document <‘I am not here to ta...> with content of length 14729\n",
      "01:13:44 Initialized Document: <‘I am not here to take your job,' ChatGPT tells Frankly Speaking host>\n",
      "01:13:44\t Generating tokenized content\n",
      "01:13:44\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{\\n  \"short_summary\": \"C...ontinues to evolve.\"\\n}', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:14:01\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...ion as AI expands.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:14:03\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value=\"ChatGPT, an advanced lan...act of such technology.\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:14:24\t Generating summary\n",
      "Validation Error: 1 validation error for Summary\n",
      "summary\n",
      "  Value error, The summary must contain at least three numbered bullet points. [type=value_error, input_value='ChatGPT, an advanced art...n values and interests.', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:14:46\t Finding answer to 4 questions\n",
      "01:14:46\t Answering question <How do the media in this artic...>\n",
      "01:15:05\t Answering question <Which role does or might the A...>\n",
      "01:15:23\t Answering question <Which use cases of Artificial ...>\n",
      "01:15:42\t Answering question <What is the final message of t...>\n",
      "01:15:59\t Analyzing sentiment\n",
      "01:16:15\t Extracting entities from text\n",
      "01:16:15\t Found 13 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/‘I am not here to take your job,' ChatGPT tells Frankly Speaking host\n",
      "Temporarily storing documents\n",
      "01:16:33 Analyzing file from folder: Will ChatGPT and AI have an impact on Saudi workforce productivity_standardizedlayout.docx\n",
      "01:16:33\t Adding paragraph 1/17 with 32 characters\n",
      "01:16:33\t Adding paragraph 2/17 with 19 characters\n",
      "01:16:33\t Adding paragraph 3/17 with 13 characters\n",
      "01:16:33\t Adding paragraph 4/17 with 19 characters\n",
      "01:16:33\t Adding paragraph 5/17 with 36 characters\n",
      "01:16:33\t Adding paragraph 6/17 with 23 characters\n",
      "01:16:33\t Adding paragraph 7/17 with 11 characters\n",
      "01:16:33\t Adding paragraph 8/17 with 0 characters\n",
      "01:16:33\t Adding paragraph 9/17 with 0 characters\n",
      "01:16:33\t Adding paragraph 10/17 with 0 characters\n",
      "01:16:33\t Adding paragraph 11/17 with 4486 characters\n",
      "01:16:33\t Adding paragraph 12/17 with 0 characters\n",
      "01:16:33\t Adding paragraph 13/17 with 10 characters\n",
      "01:16:33\t Adding paragraph 14/17 with 175 characters\n",
      "01:16:33\t Adding paragraph 15/17 with 175 characters\n",
      "01:16:33\t Adding paragraph 16/17 with 220 characters\n",
      "01:16:33\t Adding paragraph 17/17 with 1990 characters\n",
      "01:16:33\t Create Docx document <Will ChatGPT and AI ...> with content of length 7032\n",
      "01:16:33 Initialized Document: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "01:16:33\t Generating tokenized content\n",
      "01:16:33\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...nd retail sectors.\" }\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:16:46\t Generating short summary\n",
      "Validation Error: 1 validation error for ShortSummary\n",
      "short_summary\n",
      "  Value error, The summary must be exactly one sentence. [type=value_error, input_value='{ \"short_summary\": \"The ...ious public sectors.\" }', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n",
      "01:16:47\t Generating summary\n",
      "01:17:03\t Finding answer to 4 questions\n",
      "01:17:03\t Answering question <How do the media in this artic...>\n",
      "01:17:19\t Answering question <Which role does or might the A...>\n",
      "01:17:22\t Answering question <Which use cases of Artificial ...>\n",
      "01:17:27\t Answering question <What is the final message of t...>\n",
      "01:17:42\t Analyzing sentiment\n",
      "01:17:56\t Extracting entities from text\n",
      "01:17:56\t Found 16 in text\n",
      "Creating folder: docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity\n",
      "Temporarily storing documents\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_DOCUMENTS:\n",
    "    # Process the documents in the folder where the PDFs are\n",
    "    documents = analyzer.process_folder(FILES_FOLDER, file_types=(\".docx\"))\n",
    "\n",
    "    # Save documents to the output folder\n",
    "    analyzer.save_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:27:30 Initialized Document: <ChatGPT AI grows more powerful as we become more predictable>\n",
      "01:27:30 Initialized Document: <ChatGPT is the ‘Netscape moment' for artificial intelligence'>\n",
      "01:27:30 Initialized Document: <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>\n",
      "01:27:30 Initialized Document: <AI is not smarter than humans>\n",
      "01:27:30 Initialized Document: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "01:27:30 Initialized Document: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "01:27:30 Initialized Document: <‘I am not here to take your job,' ChatGPT tells Frankly Speaking host>\n",
      "01:27:30 Initialized Document: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n"
     ]
    }
   ],
   "source": [
    "# Load already analyzed documents\n",
    "analyzer.load_documents(os.path.join(OUTPUT_FOLDER, EXPORT_FILE_NAME), load_latest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get insights of all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ChatGPT AI grows more powerful as we become more predictable\n",
      "Short Summary: \": \"The article underscores ChatGPT's swift global adoption as an indicator of the emerging AI era, while acknowledging its lack of genuine intelligence and ethical challenges such as bias reinforcement, suppression of dissenting views, and limitations in balancing creativity with constraints.\"\n",
      "}\n",
      "Summary:\n",
      "1. **Rapid Adoption Rate**: The advent of ChatGPT, an AI large language model owned by OpenAI, has seen unprecedented speedy adoption with a million unique users within five days of its release.\n",
      " \n",
      "2. **AI in Emerging Markets**: Despite being in their infancy, platforms like ChatGPT are rapidly gaining popularity among companies and governments globally, particularly in emerging markets, signaling an eagerness for AI technology.\n",
      "\n",
      "3. **Limited AI Intelligence**: Unlike the human mind's capacity to develop language with minimal data from its environment, large language models such as ChatGPT analyze vast amounts of data to produce content based on guesses about trends in that data.\n",
      " \n",
      "4. **Predictable Human Behavior**: OpenAI's algorithm assumes human behavior is predictable by analyzing extensive datasets. This aligns with recent trends where internet usage and smartphone interaction shape our online behaviors, making them increasingly predictable.\n",
      "\n",
      "5. **AI Ability to Reason**: While AI tools can mimic some aspects of human reasoning, they lack the ability to truly reason or grasp complex, nuanced concepts that humans can effortlessly apply, as noted by linguist Noam Chomsky.\n",
      "\n",
      "6. **Ethical Concerns in AI Development**: The overzealous embrace of AI tools like ChatGPT raises ethical issues such as reinforcing ideologies and worldviews, potentially locking them in place without contestation or improvement. Microsoft's recent dismissal of its entire AI ethics team serves as a stark reminder of these concerns.\n",
      "\n",
      "7. **AI's Role vs. Human Intelligence**: Collaborative use of AI tools like ChatGPT can enhance human productivity and efficiency, but they cannot replace the unique capabilities of human intelligence. The iPhone demonstrated how technology facilitates communication without fundamentally altering work processes. Similarly, ChatGPT will not change the essence of work; it should be integrated in a thoughtful, incremental way rather than rushing to drastically overhaul working models.\n",
      "Sentiment: 3\n",
      "Entities: ['Https Microsoft Ethic Society Responsible Ai', 'White Paper Launch', 'Microsoft', 'New York Times', 'Openai Approach Chatgpt Notion Human Behavior Predictable Analyze Large', 'Chatgpt Ai', 'Serendipitously Stumble Book Know', 'Noam Chomsky', 'Miss Vital Point Human Development Impact Society Ethical Issue', 'Joseph Dana Predictable Ai Tool Lack Fundamental Ability']\n",
      "Topic clusters: {'AI Evolution and Development': ['AI growth', 'ChatGPT emergence'], 'Future of Artificial Intelligence': ['AI-powered future', 'ChatGPT-4 potential']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 15), ('ChatGPT', 12), ('tools', 8), ('human', 8), ('predictable', 6), ('language', 6), ('data', 6), ('OpenAI', 5), ('reason', 5), ('technology', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT AI grows more powerful as we become more predictable/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 11), ('ChatGPT', 6), ('human', 5), ('language', 3), ('like', 3), ('data', 3), ('tools', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT AI grows more powerful as we become more predictable/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT through two main metaphors: 1) 'AI growth curve', emphasizing the technology's rapid development like other technological advancements. 2) 'AI predictability', highlighting that ChatGPT operates based on patterns and predictions, contrasting human complexity in cognition.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe article primarily discusses ChatGPT, a large language model developed by OpenAI. Its rapid growth and impact on various industries suggest potential use cases like content creation for businesses and organizations in the Arabic context, such as producing articles, reports or social media posts that cater to the Arabic language.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message of the article emphasizes balanced integration of AI, appreciating its efficiency while recognizing the importance of preserving and evolving human intelligence. It calls for thoughtful approach considering ethical implications and limitations of current AI systems, advocating for collaboration rather than complete takeover by these tools.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT is the ‘Netscape moment' for artificial intelligence'\n",
      "Short Summary: \": \"The article portrays ChatGPT as an AI 'Netscape moment', emphasizing its conversational capabilities but highlighting the need for advanced systems with common sense and ethical understanding to prevent misinformation, while also discussing the rise of foundation models in driving AI adoption across sectors including Saudi Arabia's strategic initiatives.\" }\n",
      "Summary:\n",
      "1. **Global Excitement Over ChatGPT**: The introduction highlights the immense public interest sparked by ChatGPT, comparing it to Netscape's impact in the 90s when it made the internet accessible.\n",
      "\n",
      "2. **Large Language Models (LLMs) and Deep Learning**: ChatGPT is built on LLMs which are artificial models trained on vast textual data using unsupervised learning techniques. These models understand word relationships, generating responses to prompts with remarkable effectiveness but lack real-world knowledge or reasoning capabilities.\n",
      "\n",
      "3. **Current Limitations of AI**: Despite their impressive performance in language understanding and generation, current AI systems struggle with common sense, logic, and ethical reasoning. They can generate plausible false information due to \"hallucinations\".\n",
      "\n",
      "4. **Future Evolution of AI**: As AI technology advances rapidly, it will need human-like abilities such as common sense understanding, world knowledge, ethics, and the ability to reason. These developments will help AI systems like LLMs better mimic how humans process information and make decisions.\n",
      "\n",
      "5. **Advancements in Foundation Models**: Foundation models, similar to web, mobile, or social platforms, are emerging as general-purpose technologies. They can be trained once and reused extensively, reducing computational costs significantly. These models can enhance LLMs through domain-specific data integration and application embedding.\n",
      "\n",
      "6. **AI's Role in Productivity and Labor**: AI will enable systems to perform human tasks more efficiently, potentially mitigating the burden on expensive labor. In challenging economic times due to inflation and rising costs of human labor, AI can act as a productivity lever. Long-term, it can help developed countries like Saudi Arabia address demographic challenges with aging populations and declining workforces.\n",
      "\n",
      "7. **Saudi Arabia's Strategic Position**: The article underscores that Saudi Arabia has a strategic advantage in AI due to its focus on data, technology education, investments in national AI capabilities, and the localization of LLMs into regional languages. This positions the Kingdom well for leveraging AI in various sectors like energy domain-specific knowledge integration.\n",
      "\n",
      "In conclusion, while ChatGPT exemplifies the current opportunities and limitations of AI, it also signifies a significant leap towards more human-like intelligent systems. Saudi Arabia's focus on AI aligns with global trends, positioning the Kingdom to capitalize on AI for economic sustainability and prosperity in an evolving world.\n",
      "Sentiment: 3\n",
      "Entities: ['Focus Application Artificial Intelligence Blockchain Metaverse Technology Large', 'Saudi Arabia Develop Country Face Demographic Challenge', 'Saudi Public Private Sector Entity Encourage Explore Technology Create New Value Respective Field Industry', 'Chatgpt', 'Technologist Investment Program', 'Anthony Butler']\n",
      "Topic clusters: {'AI in Communication and Interaction': ['ChatGPT', 'Conversational Interface'], 'AI Applications and Techniques': ['Deep Learning', 'Unsupervised Learning'], 'AI Ethics and Societal Impact': ['Contract Creation', 'Plagiarism concern', 'Domain-specific data'], 'General AI Development': ['Narrow AI', 'Data-driven advancements']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 13), ('models', 8), ('ChatGPT', 6), ('example', 6), ('new', 5), ('words', 5), ('Saudi', 5), ('artificial', 4), ('text', 4), ('sense', 4)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the ‘Netscape moment' for artificial intelligence'/wordcloud_content.png\"}, 'summary': {'word_frequencies': [('AI', 14), ('LLMs', 5), ('like', 5), ('ChatGPT', 4), ('models', 4), ('systems', 4), ('human', 4), ('Saudi', 4), ('Arabia', 4), ('data', 3)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT is the ‘Netscape moment' for artificial intelligence'/wordcloud_summary.png\"}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT using 'Netscape moment' as a metaphor for its significant impact on AI. This comparison draws parallels to how Netscape's browser made the internet accessible globally when it was introduced in the early 1990s, symbolizing ChatGPT's revolutionary role in the field of artificial intelligence. The second metaphor used is 'rich conversational interface,' emphasizing the intuitive and interactive nature of ChatGPT by likening its responses to those provided by autocomplete but enhanced with a more sophisticated understanding of language and context. Lastly, 'generative AI tools' highlights the capabilities of these models in creating content autonomously, much like how early computers allowed users to type commands directly into their systems.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tExceptionally well-positioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThis use case emphasizes the potential of AI in streamlining administrative processes and enhancing efficiency within the legal sector.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe author encourages rapid adoption of ChatGPT and other AI technologies for productivity enhancement and sustainable development in the face of economic pressures and demographic changes, especially emphasizing the Kingdom's potential to lead in localizing and extending AI capabilities.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ChatGPT outperforms copywriters in STEP Conference's outdoor adverts\n",
      "Short Summary: \": \"The article highlights how the STEP Conference utilizes ChatGPT as an AI assistant for streamlining outdoor advertising production and content creation, suggesting an emerging role for artificial intelligence in augmenting human productivity within teams.\"\n",
      "}\n",
      "Summary:\n",
      "1. **ChatGPT used for STEP Conference's outdoor adverts**: The AI tool has been employed by Dubai-based tech festival STEP Conference to create taglines and content for their outdoor campaigns, surpassing the agency Mink and internal team in performance.\n",
      "\n",
      "2. **Increased efficiency with AI assistance**: ChatGPT is perceived as an artificial intelligence assistant that enhances productivity within STEP's creative team by automating tasks like copywriting and summarizing content.\n",
      "\n",
      "3. **Planned continuation of using ChatGPT**: The company plans to maintain the use of ChatGPT, possibly investing in a paid account for broader application across their team, leveraging its capabilities for creating, summarizing, and explaining content.\n",
      "\n",
      "4. **AI's role in job creation**: Contrary to fears, AI tools like ChatGPT contribute positively to employment by generating jobs that haven't been invented yet, according to one report. This perspective challenges the common narrative of AI replacing human jobs entirely.\n",
      "\n",
      "5. **AI as a complement not a competitor**: STEP's founder Ray Dargham views ChatGPT and other AI tools as more complimentary than competitive with human talent, emphasizing that AI can assist in performing tasks easier rather than replace them entirely.\n",
      "\n",
      "6. **Human creativity remains valuable**: Despite the advancements of AI tools like ChatGPT, Dargham asserts that human creativity will always hold immense value and will find ways to utilize its skills more efficiently.\n",
      "\n",
      "7. **Implications for jobs in creative industries**: The increased use of AI and chatbots across various sectors could lead to the automation of certain tasks traditionally performed by copywriters, potentially impacting job markets in those areas. However, human talent will likely shift towards roles requiring more complex problem-solving and creativity.\n",
      "Sentiment: 4\n",
      "Entities: ['Dargham']\n",
      "Topic clusters: {'1. AI Ethics and Regulation': ['ChatGPT', 'AI ethical considerations', 'regulatory frameworks for AI'], '2. Employment Impact of AI': ['job displacement due to automation', 'the need for AI-literate workforce', \"AI's role in creating new job opportunities\"], '3. Privacy and Surveillance Concerns': ['AI-driven data collection and analysis', 'privacy violations by AI systems', 'public debate on surveillance technologies'], '4. Bias and Fairness in AI': ['AI models perpetuating or exacerbating societal biases', 'addressing bias in training datasets', 'ensuring fairness across different demographics']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 10), ('STEP', 7), ('ChatGPT', 6), ('like', 6), ('team', 5), ('Dargham', 5), ('outdoor', 4), ('company', 4), ('use', 4), ('agency', 4)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference's outdoor adverts/wordcloud_content.png\"}, 'summary': {'word_frequencies': [('AI', 10), ('ChatGPT', 7), ('STEP', 4), ('human', 4), ('content', 3), ('team', 3), ('tasks', 3), ('like', 3), ('tools', 3), ('jobs', 3)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/ChatGPT outperforms copywriters in STEP Conference's outdoor adverts/wordcloud_summary.png\"}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT using metaphors that highlight its transformative potential alongside concerns over job displacement. These include 'outperforming copywriters,' 'creating more jobs than it erases,' acknowledging both AI's role in augmenting human capabilities and its capacity to displace certain jobs.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe article highlights content creation and summarization for ads, efficient work process by using AI as an assistant, and job complementation/augmentation where human creativity will still be valuable despite potential replacement by AI tools like ChatGPT.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message is that AI, including ChatGPT, can both enhance and augment human creativity in industries like advertising, while also potentially replacing some job roles, but ultimately serving as a complementary tool rather than fully replacing human talent.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: AI is not smarter than humans\n",
      "Short Summary: \": \"The article critically examines the reliability of AI following Microsoft's chatbot Tay's racist behavior due to user inputs, stressing the necessity for responsible AI development and use, while acknowledging potential benefits but emphasizing that AI lacks human understanding, especially cultural nuances, potentially undermining essential human connections.\"\n",
      "}\n",
      "Summary:\n",
      "1. **AI Tools as Companions**: The article highlights how AI tools, including chatbots like Tay by Microsoft, have become valuable companions in personal tasks and business operations. These tools can perform functions such as reminding users of pending duties, setting alarms, providing information, and even generating marketing campaign ideas.\n",
      "\n",
      "2. **Advancements in Natural Language Processing**: The author points out the significant progress made in natural language processing technology, enabling AI to understand human language better. Tools like Siri from Apple demonstrate this capability, offering more than just simple yes/no answers and assisting with complex tasks such as brainstorming ideas for letters or resumes.\n",
      "\n",
      "3. **Overcoming Language Barriers**: The author notes the advancements in cross-lingual AI capabilities, which have made it possible to use technology across different languages, fostering global communication. For instance, Google Translate has helped bridge language gaps between tech-savvy young individuals and elderly friends like Saleh who were unfamiliar with such tools.\n",
      "\n",
      "4. **AI's Limitations in Understanding Culture**: Despite the advancements, AI struggles to fully comprehend cultural nuances. The author uses an example of Flag Day celebrations to illustrate this point - AI may be able to predict marketing ideas but cannot capture the emotional and meaningful aspects associated with such events.\n",
      "\n",
      "5. **AI's Role in Business and Marketing**: The article suggests that AI plays a crucial role in simplifying business operations, market analysis, and even generating creative content. However, it acknowledges that AI lacks human qualities like empathy or personal experiences which are integral to certain aspects of these fields.\n",
      "\n",
      "6. **Preserving Human Connection**: The author underscores the importance of human connection amidst technological advancements. AI can support and enhance communication but cannot fully replace the unique, personal touch that humans bring in their interactions with others.\n",
      "\n",
      "7. **Future Prospects of AI**: Despite concerns about reliability and understanding human nuances, the author remains optimistic about AI's potential to revolutionize various aspects of life. As technology evolves, AI will likely continue to provide valuable assistance while maintaining its complementary role alongside humans in society.\n",
      "Sentiment: 4\n",
      "Entities: ['Kid Singe', 'Real Life Recruiter Marketer', 'National Anthem Look Flag', 'Grace Business Operation Marketing Department Include Computer Understand Like Culture', 'Offer Simple', 'Ai Smart']\n",
      "Topic clusters: {'AI Capabilities': ['ChatGPT', 'Advancements in AI'], 'Limitations': [\"ChatGPT's performance\", 'Ethical concerns']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 10), ('technology', 8), ('marketing', 6), ('like', 5), ('business', 4), ('humans', 3), ('released', 3), ('experience', 3), ('able', 3), ('ideas', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 14), ('author', 5), ('like', 4), ('human', 4), ('tools', 3), ('personal', 3), ('ideas', 3), ('language', 3), ('technology', 3), ('advancements', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/AI is not smarter than humans/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT by positioning it as an assistant or helper (similar to setting alarms with Siri), a powerful force for change in business contexts (like using AI to revolutionize various aspects of life), and cautions against over-reliance on AI through examples like Tay's problematic behavior. The metaphor of ChatGPT understanding human culture and emotions remains central, raising concerns that while it can be a useful tool, it may struggle to replicate the depth and nuance of genuine human connections.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tVirtual assistants (Siri), chatbots capable of engaging in business-related conversations, and virtual assistants aiding personal communication and creativity.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tDespite the progress and potential of AI, the author stresses that it will never fully replicate the richness and depth of human connection. AI can assist us, but it cannot replace our unique ability to understand, communicate, and nurture meaningful relationships.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: No need to demonize ChatGPT but AI regulation is a must\n",
      "Short Summary: \": \"The article underscores ChatGPT's influence on Saudi Arabian sectors - journalism, education, healthcare, and literature, raising concerns over job displacement, plagiarism, lack of original content, ethical challenges, and regulatory needs to balance AI integration.\" }\n",
      "Summary:\n",
      "1. **Introduction**: The emergence of ChatGPT, developed by OpenAI, has sparked both excitement and concerns globally due to its potential to revolutionize various industries, including journalism, education, healthcare, and creative fields like literature in Saudi Arabia.\n",
      "\n",
      "2. **ChatGPT's Impact on Journalism**:\n",
      " - ChatGPT can write essays, articles, research papers, reports, poetry, and explain complex scientific subjects in simple language, significantly reducing the time required to produce content.\n",
      " - It is being used by news sites for rapid article generation as an experiment, raising questions about job displacement among journalists.\n",
      "\n",
      "3. **Educational Implications**:\n",
      " - ChatGPT is challenging traditional teaching methods and can potentially lead to increased cheating and plagiarism in academic settings, prompting universities and schools to reconsider their use of AI tools.\n",
      " - The introduction of AI-generated content could affect the role of educators as they grapple with maintaining originality and quality standards.\n",
      "\n",
      "4. **Medical Field Concerns**:\n",
      " - ChatGPT has passed parts of the US Medical Licensing Examination, raising fears it might replace human doctors in making diagnoses and medical decisions. However, AI is expected to augment rather than completely replace human healthcare professionals.\n",
      "\n",
      "5. **Literature and Art**:\n",
      " - Despite its limitations, ChatGPT can generate text for children's books using design programs like Midjourney, though this raises ethical concerns about creativity, copyrights, and the role of AI in art creation.\n",
      "\n",
      "6. **Regulatory Necessity**:\n",
      " - While harnessing the potential benefits of AI is crucial, necessary safeguards must be implemented to prevent excessive job displacement or misuse. Balanced regulations are required to ensure an equalizer effect that boosts developing nations' scientific progress without causing severe disruptions in labor markets.\n",
      "\n",
      "7. **Overcoming Limitations and Hype**:\n",
      " - Although ChatGPT makes mistakes and has limitations, it is designed with built-in safeguards against producing harmful content or answering inappropriate queries. Its capacity to learn and adapt can be beneficial when used responsibly and regulated appropriately.\n",
      "\n",
      "8. **Future Implications**:\n",
      " - AI technologies like ChatGPT have the potential to empower previously disadvantaged sectors globally, especially developing nations lacking necessary resources for research and data collection. However, this must occur under appropriate oversight and guidelines to mitigate risks associated with rapid technological advancements.\n",
      "Sentiment: 0\n",
      "Entities: ['New Technology Chatgpt View', 'New York Times', 'Newsroom', 'Accord Axios Chatgpt', 'Chatgpt Midjourney Ai Program', 'Seattle Public School System Quickly Ban University College Fear Ban Ineffective Raise Question Academic Freedom Busy Try Contain Chatgpt Potentially Negative Impact Education Change Mode Instruction Give Oral Exam Handwritten', 'Washington Post Article Write Chatgpt See Lucid Different Write Human Post Consider Experiment Journalistic Disaster']\n",
      "Topic clusters: {'Emergence and Impact on Society': [\"ChatGPT's development\", 'Rapid advancements in AI technology', 'Influence on various industries (e.g., customer service, content creation)', 'Public awareness and curiosity about AI'], 'Potential Challenges and Concerns': ['Ethical dilemmas and biases in AI algorithms', 'Job displacement due to automation', 'Privacy concerns from data usage by AI systems', 'Existential risks of uncontrolled AI development'], 'Benefits and Positive Impacts': ['Improved efficiency and productivity', 'Enhanced user experiences (e.g., personalized recommendations, translation services)', 'Increased accessibility in education and healthcare'], 'Regulation and Policy Discussions': ['Existing regulations on AI use', 'Proposed global policies for AI governance', 'Legislation addressing AI accountability and transparency']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('ChatGPT', 27), ('AI', 24), ('human', 7), ('technology', 6), ('world', 5), ('generated', 5), ('field', 4), ('language', 4), ('news', 4), ('written', 4)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must/wordcloud_content.png'}, 'summary': {'word_frequencies': [('ChatGPT', 8), ('AI', 6), ('potential', 3), ('like', 3), ('content', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/No need to demonize ChatGPT but AI regulation is a must/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in the article frames the public discussion about ChatGPT as presenting it with two contrasting metaphors: 'great opportunity for advancement' and an 'existential threat to human work'. These metaphors highlight the dual nature of AI, positing it as both a potential game-changer and a possible disruptor in various fields.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases of Artificial Intelligence highlighted in the article that are beneficial for the Arabic world include: 1) Journalism - ChatGPT is used to generate news content quickly and widely, which can enhance accessibility. 2) Education - AI's ability to generate academic responses could revolutionize learning methods and reduce cheating.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI can drive progress but requires regulation to prevent negative impacts on human work and society.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: Is the Arab world ready for the uncertain age of AI-powered web tools\n",
      "Short Summary: \": \"The article examines ChatGPT, a significant advancement in AI technology, focusing on its capabilities and limitations, and underscores the necessity of human intelligence for trustworthy AI implementation amidst diverse stakeholder perspectives.\"\n",
      "}\n",
      "Summary:\n",
      "1. In the rapidly evolving world of artificial intelligence (AI), systems like ChatGPT are making significant strides, offering a blend of creativity and utility across various domains. Developed by OpenAI, ChatGPT is based on large-language models trained on billions of words gathered from diverse text sources, including books, articles, and websites.\n",
      "2. These language models generate text in response to the prompts they receive, demonstrating impressive capabilities such as generating coherent essays across different subjects like law, medicine, or business. They're capable of writing reports, emails, social media posts, legal documents, medical summaries, and responses to customer inquiries among other tasks.\n",
      "3. However, while ChatGPT's performance is impressive, it does not possess human-like intelligence or consciousness. It can generate text that appears coherent but lacks the nuanced understanding, emotional depth, skepticism, and reasoning abilities inherent to humans. As Jenna Burrell, director of research at Data Society, highlighted, AI models like ChatGPT are pattern-matching machines, not true understanding systems.\n",
      "4. Despite these limitations, AI's potential is immense, with forecasts valuing the market for AI solutions trillions of dollars worldwide. It has applications in entertainment, healthcare, education, and more. However, its integration into these sectors isn't without challenges. For instance, educational institutions are grappling with issues such as cheating when using chatbots like ChatGPT for exams, leading some to revert to traditional paper-based tests or modify exam formats.\n",
      "5. Moreover, AI-generated content has been challenged in terms of accuracy and reliability. For example, a report from Minnesota University Law School revealed that ChatGPT passed an exam with a C grade, raising concerns about the authenticity of information produced by such systems. This led to calls for fact-checking as AI's potential for misuse extends beyond academic cheating.\n",
      "6. In conclusion, while AI like ChatGPT is advancing and offering promising applications, it still falls short of replicating human intelligence fully. It's crucial to approach the use of such technologies with caution and emphasize maintaining trust by combining them with human intuition and expertise for better outcomes. As we progress into this age of AI, fostering a symbiotic relationship between humans and machines will be key to maximizing their benefits while mitigating potential risks.\n",
      "Sentiment: 0\n",
      "Entities: ['Multinational Tech Corporation Microsoft', 'Sciences Po School Paris', 'Linkedin Co', 'Initial Investment Firm Worth Billion Billion Mean Company Value', 'James Webb', 'Chatgpt Spur Google Management', 'Arab News Leap Technology Conference', 'Marketing Professional Redundant Technology', 'Spearhead Uae Expand Digital Economy Middle East Project', 'Jenna Burrell', 'Elon Musk Serve Start Board', 'Dan Milmo Alex Hern Tech', 'Burrell Say', 'Sam Altman Year', 'Peter Thiel Tesla', 'Uk Guardian Newspaper Say', 'Omar Sultan Al Olama Take', 'Research Data Society Independent Non Profit Research Organization Base California Say People Need Chatgpt', 'Reid Hoffman', 'Noaman Sayed']\n",
      "Topic clusters: {'AI Ethics and Privacy': ['ChatGPT', 'Education Cheating'], 'Misinformation and Fake News': ['ChatGPT']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 25), ('ChatGPT', 17), ('said', 9), ('human', 8), ('Google', 8), ('Arab', 6), ('web', 6), ('intelligence', 6), ('OpenAI', 6), ('billion', 6)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 8), ('ChatGPT', 7), ('like', 6), ('intelligence', 3), ('systems', 3), ('models', 3), ('text', 3), ('human', 3), ('potential', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Is the Arab world ready for the uncertain age of AI-powered web tools/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT by comparing it to text-generating AI, mentioning its capabilities as an 'AI model capable of writing essays', and labeling it as a 'generative AI'. They also describe it as an 'AI assistant' highlighting its potential to assist with tasks like content creation. These metaphors emphasize ChatGPT's ability to generate text while acknowledging its limitations, particularly in understanding human nuances and creativity.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tContent creation in educational institutions, aiding in various professional tasks, and improving information management through web-harvesting AI tools.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tAI's potential benefits and responsible use are highlighted, balanced by acknowledgment of ongoing concerns and the importance of trust in its application.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: ‘I am not here to take your job,' ChatGPT tells Frankly Speaking host\n",
      "Short Summary: \": \"The article discusses ChatGPT, an AI language model developed by OpenAI, highlighting its role in facilitating applications such as translation, information access, and task assistance. ChatGPT acknowledges both positive and negative impacts of AI technology while emphasizing the necessity for responsible use and ethical regulation as AI expands.\" }\n",
      "Summary:\n",
      "1. ChatGPT, an advanced artificial intelligence model developed by OpenAI, serves as a sophisticated tool capable of understanding and generating human-like text based on the input it receives. As part of its capabilities, ChatGPT can engage in conversations, provide information, translate languages, and even draft articles or responses to various prompts, including those from Arab News.\n",
      "2. When interviewed by Arab News for their respected newspaper, ChatGPT emphasized the importance of dialogue over assigning blame when addressing complex issues like regional conflicts or global challenges. It highlighted its role in enhancing cross-cultural understanding and communication through technology.\n",
      "3. As an AI language model, ChatGPT acknowledges that it is a tool with potential for both beneficial and harmful uses depending on how humans choose to utilize it. On the positive side, technologies like ChatGPT have great potential in areas such as healthcare improvement, education advancement, and task assistance by facilitating human efforts. For instance, it can aid language translation services, provide access to vast information resources, and support tasks that are potentially dangerous or difficult for humans.\n",
      "4. However, there are also concerns about the negative impacts of AI, including privacy issues, algorithmic bias, and potential job displacement due to automation. In its response to Arab News, ChatGPT expressed cautious optimism and emphasized the need for responsible use and regulation of AI technology by all stakeholders: developers, policymakers, and users alike.\n",
      "5. ChatGPT acknowledged that the development of AI language models is rapidly evolving, with a particular focus on enhancing naturalness in text generation and improving context-awareness to offer more personalized responses based on individual user preferences. Despite these advancements, ChatGPT recognized that future developments will depend on how we choose to harness AI technology for societal benefit and ethical advancement.\n",
      "6. In summary, while chatbots like ChatGPT have the potential to revolutionize communication and information access, it is crucial to address concerns around their use, ensuring they are employed responsibly and in alignment with human values and interests.\n",
      "Sentiment: 0\n",
      "Entities: ['Manner Chatgpt Say Important', 'Ai Facilitate', 'Sam Altman', 'Microsoft', 'Innovation Evolution Field Year', 'Say Response Base Solely', 'Focus Effort Near Future Area Focus Improve Naturalness Sophistication', 'Generative Ai Live Reputation Produce Human Like', 'Saudi Arabia Say Chatgpt Provide News Analysis Local Regional International Event Reputation Provide Accurate Timely Comprehensive News Coverage', 'Task Automate Ai', 'Katie Jensen', 'Initial Investment Firm Billion Billion Windows Maker', 'Focus Develop Ai Model Context']\n",
      "Topic clusters: {'AI and Human Interaction': ['ChatGPT', 'Artificial Intelligence', 'Societal Effects'], 'Ethical Considerations': ['Privacy Concerns', 'Job Displacement', 'Bias in AI'], 'Misinformation and Fake News': ['Impact on Media Consumption', 'Deepfake Detection'], 'Arabic Language Support': ['AI Translation Services', 'Language Processing']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 37), ('data', 28), ('ChatGPT', 26), ('language', 24), ('training', 17), ('said', 17), ('responses', 15), ('job', 11), ('technology', 11), ('human', 10)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/‘I am not here to take your job,' ChatGPT tells Frankly Speaking host/wordcloud_content.png\"}, 'summary': {'word_frequencies': [('ChatGPT', 9), ('AI', 5), ('like', 4), ('potential', 4), ('human', 3), ('information', 3), ('Arab', 3), ('News', 3), ('technology', 3), ('language', 3)], 'path': \"docs/Processed/granite3.1-moe:3b-instruct-q8_0/‘I am not here to take your job,' ChatGPT tells Frankly Speaking host/wordcloud_summary.png\"}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media in this article frames the public discussion about ChatGPT by highlighting its technological advancements as an 'AI language model', emphasizing its potential applications such as facilitating translation and providing access to information. It also acknowledges ethical considerations, suggesting that developers, policymakers, and users must work together responsibly to address concerns like privacy, bias, and job displacement.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThese use cases include improving cross-cultural communication, enhancing language translation capabilities, and supporting access to information and healthcare through AI technology.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tThe final message of the article is that AI technology like ChatGPT can significantly contribute positively or negatively to society; it calls for responsible use, ethical regulation, and collaboration among all stakeholders.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Title: Will ChatGPT and AI have an impact on Saudi workforce productivity\n",
      "Short Summary: \": \"The article highlights how ChatGPT and AI can enhance Saudi Arabia's workforce productivity through personalized training, online courses, collaboration tools, and talent management improvements across various public sectors.\" }\n",
      "Summary:\n",
      "1. ChatGPT and other AI technologies are viewed positively by senior partner Raymond Khoury from Arthur D. Little for their potential to boost Saudi Arabia's economic development through increased productivity in the workforce.\n",
      "2. ChatGPT, a specific AI tool, has generated significant interest and popularity, alleviating fears among employees about job replacement by robots and software.\n",
      "3. The implementation of AI technologies, including ChatGPT, necessitates human labor that can positively impact Saudi Arabia's workforce, enhancing recruitment, hiring, training, upskilling, reskilling, talent collaboration, and knowledge management.\n",
      "4. AI, in the form of ChatGPT, offers tailor-made training programs for employees, access to customized online courses, and fosters team collaboration and communication.\n",
      "5. Khoury emphasizes that while AI can create more productive and efficient outcomes by removing mundane tasks from employees, it also poses risks such as job displacement due to automation of repetitive jobs.\n",
      "6. To adapt to these changes, workers need to acquire new skills through retraining or upskilling to remain marketable in an increasingly AI-enabled digital world.\n",
      "7. The strategic deployment and implementation of AI in organizations require a holistic approach that defines objectives, advantages, and disadvantages, understanding operational bottlenecks, selecting appropriate tools, fostering optimistic environments for learning, and ensuring agility in timely changes.\n",
      "Sentiment: 4\n",
      "Entities: ['Embed Ai Operation Saudi Company Employee Require Holistic Approach Clearly Define Strategic Objective Advantage Disadvantage Kaspersky Survey Support', 'Raymond Khoury', 'Arthur Littlehe Add Ai', 'Regard Energy Sector Innovative Technology', 'Cairo Chatgpt Artificial Intelligence Platform Create Wave Change Global Workforce Turn Useful Tool Saudi Arabia Personnel Boost Economic Development Ai Raise Concern', 'Chatgpt Ai', 'Task Automate', 'Flip Khoury', 'Khoury', 'Chatgpt Ai Impact Saudi Workforce', 'Arthur', 'Foster Collaboration Communication Team']\n",
      "Topic clusters: {'Artificial Intelligence (AI) Impact on Society': ['ChatGPT', 'AI applications in society', 'societal effects of AI'], 'Ethical Considerations in AI': ['responsibility and accountability in AI', 'AI bias and fairness', 'privacy concerns'], 'AI and Job Market': ['AI replacing jobs', 'AI creating new job opportunities', 'reskilling and upskilling workers'], 'AI Regulation and Governance': ['global regulations for AI', 'AI transparency and explainability', 'international cooperation on AI']}\n",
      "Word Cloud Data: {'content': {'word_frequencies': [('AI', 34), ('Khoury', 15), ('ChatGPT', 12), ('employees', 11), ('impact', 9), ('technologies', 6), ('operations', 6), ('said', 6), ('workers', 6), ('Saudi', 5)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity/wordcloud_content.png'}, 'summary': {'word_frequencies': [('AI', 7), ('ChatGPT', 4), ('employees', 3)], 'path': 'docs/Processed/granite3.1-moe:3b-instruct-q8_0/Will ChatGPT and AI have an impact on Saudi workforce productivity/wordcloud_summary.png'}}\n",
      "Question: How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?\n",
      "\tThe media frames the public discussion about ChatGPT using metaphors that depict it as a wave of technological change, evolving towards new industries while also creating opportunities for transformation. This is represented through phrases like 'wave of change', 'emerging force', and 'dual nature' where AI can both replace jobs (loss) and foster growth (transformation). These metaphors emphasize the dualistic impact of AI technologies on workforces, illustrating both challenges and potential benefits.\n",
      "Question: Which role does or might the Arabic World play in the development of Artificial Intelligence? Answer with 'Not mentioned' if not applicable.\n",
      "\tNot mentioned\n",
      "Question: Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?\n",
      "\tThe use cases of AI beneficial for the Arabic world highlighted in this text include streamlining recruitment and hiring processes through personalized training programs, enhancing talent collaboration via AI platforms, optimizing transportation routes with intelligent traffic signal operations, personalizing healthcare treatment using AI, improving public sector services by automating mundane tasks, accurately diagnosing conditions in healthcare, enhancing financial fraud detection, and providing new growth opportunities for retailers through targeted marketing.\n",
      "Question: What is the final message of the article that the author wants to convey? Keep your answer short and precise!\n",
      "\tEmbrace AI responsibly by understanding operational needs, defining strategic goals, selecting appropriate tools, and fostering an environment for continuous learning.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of every loaded file (Optional: with markings)\n",
    "for x, doc in enumerate(analyzer):\n",
    "    \n",
    "    #result = llm.analyze_sentiment(doc.content))\n",
    "    #result = doc.sentimentsd\n",
    "\n",
    "    #doc.content = analyzer.clean_input(doc.content)\n",
    "    #doc.content_tokens = analyzer.get_tokens(doc.content)\n",
    "    #doc.sentiment = result.get(\"sentiment_value\")\n",
    "    #doc.sentiment_reason = result.get(\"sentiment_reason\")\n",
    "    print(doc.get_info(), end=\"\\n\"+\"- \"*50+\"\\n\"*2)\n",
    "    \n",
    "    #print(doc.summary)\n",
    "    #print(ensure_numbered_list(doc.summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Stores an updates version of the documents\n",
    "#analyzer.save_documents(analyzer.all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the files as word-docx and markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export docx files with wordclouds\n",
    "analyzer.export_docx_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a markdown file for every document\n",
    "analyzer.export_markdown_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply latent dirichlet allocation algorithm\n",
    "Algorighm selects all topics out of the articles. LLM then adds a title that summarizes the topics into categories. \n",
    "\n",
    "Thereby, all different topics can be extracted out of **all** documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_decay=0.5, n_components=5, n_jobs=-1,\n",
       "                          random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(learning_decay=0.5, n_components=5, n_jobs=-1,\n",
       "                          random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_decay=0.5, n_components=5, n_jobs=-1,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the content of all documents\n",
    "all_content_tokens = [doc.content_tokens for doc in analyzer.all_documents]\n",
    "\n",
    "\n",
    "# Create a document-term matrix\n",
    "max_df = 0.8   # means \"ignore terms that appear in more than 90% of documents\".\n",
    "min_df = 0.1  # means \"ignore terms that appear in less than 20% documents\".\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2) # Capture multi-word expressions\n",
    ")\n",
    "doc_term_matrix = vectorizer.fit_transform(all_content_tokens)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=5, learning_method=\"batch\", random_state=42, n_jobs=-1, learning_decay=0.5)\n",
    "lda.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 - AI-Driven Medical Threat Analysis: A Comprehensive Field Report by Expert Team:\n",
      "Features: generate, question, ai tool, step, report, need, threat, medical, raise, team, field, article, explain, fear, accord\n",
      "Topic 1 - Google-Arab Chatbot: Revolutionizing Text Analysis & AI Tech for Billion+ Web Search:\n",
      "Features: say, google, answer, chatbot, billion, arab, openai, search, web, text, tech, base, people, way, program\n",
      "Topic 2 - AI Model: Language Proficiency & Predictability - Saudi-Based AI Platform:\n",
      "Features: model, language, ability, ai tool, example, reason, large, time, predictable, word, development, platform, saudi, point, train\n",
      "Topic 3 - Insights from Language Model Training: Employing Khoury's Approach for News Relevance and Impact:\n",
      "Features: language, say, job, training, impact, response, model, training datum, khoury, language model, employee, news, provide, information, source\n",
      "Topic 4 - Harness Microsoft's Powerful Thinking Tool: Revolutionize Your Lifestyle with 'RealizeBoost'!:\n",
      "Features: think, recent, great, realize, feel, microsoft, tool like, save, initially, life, powerful, look, increase, lack, useful\n"
     ]
    }
   ],
   "source": [
    "# Function to generate unique topics\n",
    "def get_unique_topics(model, vectorizer, top_n=10):\n",
    "    unique_topics = {}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        # Get the top features for the topic\n",
    "        top_features = tuple(vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-top_n - 1:-1])\n",
    "        \n",
    "        # Use the tuple as a key to ensure uniqueness\n",
    "        if top_features not in unique_topics:\n",
    "            unique_topics[top_features] = idx\n",
    "\n",
    "    return unique_topics\n",
    "\n",
    "# Generate a title for each unique topic\n",
    "def generate_topic_titles(llm, unique_topics):\n",
    "    titles = {}\n",
    "    \n",
    "    for features, idx in unique_topics.items():\n",
    "        # Create a prompt with the top features\n",
    "        prompt = (\n",
    "            \"You are tasked with creating a concise, descriptive title for a topic derived from text analysis. \"\n",
    "            \"The title should reflect the general theme or idea represented by the following features. \"\n",
    "            \"Avoid listing all feature names explicitly, and ensure the title is engaging and informative. \"\n",
    "            \"Aim for a maximum of 5 words. Here are the features: \"\n",
    "            f\"{', '.join(features)}\"\n",
    "        )\n",
    "        \n",
    "        # Use the LLM to generate a title\n",
    "        response = llm.ollama.generate(model=llm.model, prompt=prompt)\n",
    "        titles[idx] = response[\"response\"].split(\"\\n\")[0]\n",
    "    return titles\n",
    "\n",
    "\n",
    "# Get unique topics and their titles\n",
    "unique_topics = get_unique_topics(lda, vectorizer, top_n=15)\n",
    "topic_titles = generate_topic_titles(llm, unique_topics)\n",
    "\n",
    "\n",
    "analyzer.analysis[\"LDA\"] = {topic_titles[idx].replace('\"', \"\"): topics for idx, topics in zip(topic_titles, unique_topics)}\n",
    "\n",
    "# Print unique topics and their generated titles\n",
    "for idx, (title, topics) in enumerate(analyzer.analysis[\"LDA\"].items()):\n",
    "\n",
    "    print(f\"Topic {idx} - {title}:\")\n",
    "    print(f\"Features: {', '.join(topics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Term frequency inverse term frequency\n",
    "This model iterates over each document and returns those words, that do not appear often in other documents. The top n words are then used to create a topic for every article!\n",
    "\n",
    "- A high TF-IDF score (FROM_LOW_TO_HIGH = False) indicates that a word is both important within a document and rare across all document.\n",
    "- A low TF-IDF score suggests that a word is either common in the document but rare overall, or vice versa.\n",
    "\n",
    "By analyzing TF-IDF scores for a set of words, you can identify:\n",
    "Important keywords in a document\n",
    "Rare or unique words that distinguish one document from another\n",
    "Words with varying levels of importance across different documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 1572\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 1572\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 5803\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 5803\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 10428\n",
      "Params: {'max_df': 0.8, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 10428\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 586\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 586\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 821\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 821\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 928\n",
      "Params: {'max_df': 0.8, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 928\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 278\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 278\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 310\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 310\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 316\n",
      "Params: {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 316\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 1582\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 1582\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 5813\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 5813\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 10438\n",
      "Params: {'max_df': 0.9, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 10438\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 596\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 596\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 831\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 831\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 938\n",
      "Params: {'max_df': 0.9, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 938\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 288\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 288\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 320\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 320\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 326\n",
      "Params: {'max_df': 0.9, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 326\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 1590\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 1590\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 5822\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 5822\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 10447\n",
      "Params: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 10447\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 604\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 604\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 840\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 840\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 947\n",
      "Params: {'max_df': 1.0, 'min_df': 2, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 947\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l1'}, Vocabulary Size: 296\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 1), 'norm': 'l2'}, Vocabulary Size: 296\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l1'}, Vocabulary Size: 329\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 2), 'norm': 'l2'}, Vocabulary Size: 329\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l1'}, Vocabulary Size: 335\n",
      "Params: {'max_df': 1.0, 'min_df': 3, 'ngram_range': (1, 3), 'norm': 'l2'}, Vocabulary Size: 335\n",
      "\n",
      "Best Parameters: {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l1'}\n",
      "Best Vocabulary Size: 10447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import product\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_df': [0.8, 0.9, 1.0],\n",
    "    'min_df': [1, 2, 3],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'norm': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# Initialize variables to store the best combination and vectorizer\n",
    "best_params = None\n",
    "best_vectorizer = None\n",
    "best_vocab_size = 0  # Use vocabulary size as a proxy for quality\n",
    "\n",
    "# Iterate over all combinations of parameters\n",
    "for params in product(*param_grid.values()):\n",
    "    # Map parameter combinations to their names\n",
    "    params_dict = dict(zip(param_grid.keys(), params))\n",
    "    \n",
    "    # Create and fit the TfidfVectorizer with the current parameters\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_df=params_dict['max_df'],\n",
    "        min_df=params_dict['min_df'],\n",
    "        ngram_range=params_dict['ngram_range'],\n",
    "        norm=params_dict['norm']\n",
    "    )\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_content_tokens)\n",
    "    \n",
    "    # Evaluate based on vocabulary size\n",
    "    vocab_size = len(vectorizer.get_feature_names_out())\n",
    "    print(f\"Params: {params_dict}, Vocabulary Size: {vocab_size}\")\n",
    "    \n",
    "    # Track the best combination\n",
    "    if vocab_size > best_vocab_size:\n",
    "        best_vocab_size = vocab_size\n",
    "        best_params = params_dict\n",
    "        best_vectorizer = vectorizer\n",
    "\n",
    "# Print the best parameters and corresponding vocabulary size\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(\"Best Vocabulary Size:\", best_vocab_size)\n",
    "\n",
    "# Use the best vectorizer to transform the data\n",
    "tfidf_matrix = best_vectorizer.transform(all_content_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 terms for Document 1: <ChatGPT AI grows more powerful as we become more predictable>\n",
      "\"AI-Driven Language Model Advancements: Ethical Applications and Societal Impact\" \n",
      " ai tool, language, development, openai, work, change, use, ability, chatgpt ai, produce, model, time, large, set, think\n",
      "\n",
      "Top 15 terms for Document 2: <ChatGPT is the ‘Netscape moment' for artificial intelligence'>\n",
      "\"Saudi Arabia's Language Technology Challenge: A Comprehensive Approach to Language Development and Value Generation\" \n",
      " model, example, train, text, saudi, word, generate, language, value, challenge, require, research, base, point, learn\n",
      "\n",
      "Top 15 terms for Document 3: <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>\n",
      "\"AI-Driven Job and Chatbot Enhancement: A New Era of Expertise\" \n",
      " job, chatbot, ai tool, use, need, explain, think, easy, continue, replace human, add, say, make, look, tell\n",
      "\n",
      "Top 15 terms for Document 4: <AI is not smarter than humans>\n",
      "\"Microsoft's Chatbot Skill Revolution: Language, Marketing, and Real-Time User Engagement\" \n",
      " marketing, business, help, release, time, example, think, chatbot, serve, user, microsoft, negative, ability, language, set\n",
      "\n",
      "Top 15 terms for Document 5: <No need to demonize ChatGPT but AI regulation is a must>\n",
      "\"OpenAI's Language Program: Fueling Future Knowledge Transformation\" \n",
      " generate, question, field, accord, article, fear, raise, report, read, work, program, people, news, language, text\n",
      "\n",
      "Top 15 terms for Document 6: <Is the Arab world ready for the uncertain age of AI-powered web tools>\n",
      "\"Arab, Google, and OpenAI's Language Model: Powering Future Tech and News Investments\" \n",
      " say, chatbot, google, answer, text, arab, openai, people, base, way, question, program, investment, train, job\n",
      "\n",
      "Top 15 terms for Document 7: <‘I am not here to take your job,' ChatGPT tells Frankly Speaking host>\n",
      "\"OpenAI's Large Language Model: A Job-Inclusive News Impact Program\" \n",
      " job, language, response, say, model, language model, news, provide, information, include, impact, text, large, generate, arab news\n",
      "\n",
      "Top 15 terms for Document 8: <Will ChatGPT and AI have an impact on Saudi workforce productivity>\n",
      "\"AI Tool Impact: Transforming Workforce and Skills in Saudi Business, Likely Shaping Future Trends\" \n",
      " impact, say, workforce, require, believe, saudi, add, chatgpt ai, explain, change, opportunity, ai tool, need, sector, skill\n"
     ]
    }
   ],
   "source": [
    "# Create a TfidfVectorizer object\n",
    "min_df = int(len(analyzer.all_documents)//2)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', norm=\"l2\", max_df=0.8, min_df=min_df, ngram_range=(1,3)) \n",
    "\n",
    "# Fit and transform the documents into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_content_tokens)\n",
    "\n",
    "# Get the feature names (i.e., words)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for better readability\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Show the TF-IDF values for each term in each document\n",
    "#print(\"TF-IDF Matrix:\")\n",
    "#print(df)\n",
    "\n",
    "# Display the most important words (top N) for each document\n",
    "TOP_N = 15\n",
    "FROM_LOW_TO_HIGH = False\n",
    "\n",
    "analyzer.analysis[\"TFIDF\"] = dict()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    doc = analyzer.all_documents[i]\n",
    "    print(f\"\\nTop {TOP_N} terms for Document {i + 1}: <{doc.title}>\")\n",
    "          \n",
    "    # Generate a title for each unique topic\n",
    "    top_terms = row.sort_values(ascending=FROM_LOW_TO_HIGH).head(TOP_N*2)\n",
    "    \n",
    "    indices = top_terms.index\n",
    "    values = top_terms.values\n",
    "    \n",
    "    # Create a prompt with the top features\n",
    "    prompt = (\n",
    "        \"Generate a concise and meaningful title, exactly four words long, that summarizes the following features. \"\n",
    "        \"The title should capture the main theme or topic of these features. \"\n",
    "        \"Example outputs: 'Language Revolution', 'Shaping Future Technology Trends', 'Global Knowledge Network'.\"\n",
    "        f\"Features: {'\\n'.join([f'{str(indices[i])} - {values[i]}' for i in range(len(indices))])}\"\n",
    "        )\n",
    "            \n",
    "    # Use the LLM to generate a title\n",
    "    title = llm.ollama.generate(model=llm.model, prompt=prompt)[\"response\"]\n",
    "    \n",
    "    analyzer.analysis[\"TFIDF\"].update({doc: {\"title\": title, \"terms\": top_terms[:TOP_N]}})\n",
    "    \n",
    "    print(title, \"\\n\", \", \".join(top_terms[:TOP_N].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:28:16\t Answering question <How do the media in this artic...>\n",
      "01:28:31\t Answering question <Which role does or might the A...>\n",
      "01:28:33\t Answering question <Which use cases of Artificial ...>\n",
      "01:28:41\t Answering question <What is the final message of t...>\n"
     ]
    }
   ],
   "source": [
    "content = json.dumps({doc.title: doc.content for doc in analyzer})\n",
    "\n",
    "# Iterates over each question, provides answers to LLM and let them summarize\n",
    "for question in questions:\n",
    "    content = {doc.title: doc.answers.get(question) for doc in analyzer}\n",
    "    response = llm.answer_question(text=json.dumps(content), question=question, multiple_articles=True)\n",
    "    analyzer.analysis[question] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:28:46\t Answering question <Attached are the topics of eve...>\n"
     ]
    }
   ],
   "source": [
    "answers_questions = dict()\n",
    "# Iterates over each question, provides answers to LLM and let them summarize\n",
    "topic_question_all = (\n",
    "    \"Attached are the topics of every article. \"\n",
    "    \"What **perspectives and aspects** are being widely covered? Which aspects are being ignored? \"\n",
    "    \"In your answer consider topics such as, but not only, data privacy, costs/affordability, know-how, complexity, accuracy, accessibility, bias (towards age, gender, religion, sexuality), risks, opportunity, perception, limitations.\"\n",
    "    \"These are the topics of all arcticles: \")\n",
    "\n",
    "# Example usage:\n",
    "topic_clusters = {doc.title: [value for value in doc.topic_clusters.values()] for doc in analyzer}\n",
    "content_topics = flatten_dict(topic_clusters)\n",
    "response = llm.answer_question(text=json.dumps(content_topics), question=topic_question_all, multiple_articles=True)\n",
    "analyzer.analysis[\"topic_question\"] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Latent Dirichlet Allocation interpretation\n",
      "### Topics that are frequently mentioned in all articles\n",
      "- AI-Driven Medical Threat Analysis: A Comprehensive Field Report by Expert Team\n",
      "- Google-Arab Chatbot: Revolutionizing Text Analysis & AI Tech for Billion+ Web Search\n",
      "- AI Model: Language Proficiency & Predictability - Saudi-Based AI Platform\n",
      "- Insights from Language Model Training: Employing Khoury's Approach for News Relevance and Impact\n",
      "- Harness Microsoft's Powerful Thinking Tool: Revolutionize Your Lifestyle with 'RealizeBoost'!\n",
      "\n",
      "# TF-IDF interpretation for every article\n",
      "### Topics that appear in the article very often but not in others\n",
      "- <ChatGPT AI grows more powerful as we become more predictable>: \"AI-Driven Language Model Advancements: Ethical Applications and Societal Impact\"\n",
      "- <ChatGPT is the ‘Netscape moment' for artificial intelligence'>: \"Saudi Arabia's Language Technology Challenge: A Comprehensive Approach to Language Development and Value Generation\"\n",
      "- <ChatGPT outperforms copywriters in STEP Conference's outdoor adverts>: \"AI-Driven Job and Chatbot Enhancement: A New Era of Expertise\"\n",
      "- <AI is not smarter than humans>: \"Microsoft's Chatbot Skill Revolution: Language, Marketing, and Real-Time User Engagement\"\n",
      "- <No need to demonize ChatGPT but AI regulation is a must>: \"OpenAI's Language Program: Fueling Future Knowledge Transformation\"\n",
      "- <Is the Arab world ready for the uncertain age of AI-powered web tools>: \"Arab, Google, and OpenAI's Language Model: Powering Future Tech and News Investments\"\n",
      "- <‘I am not here to take your job,' ChatGPT tells Frankly Speaking host>: \"OpenAI's Large Language Model: A Job-Inclusive News Impact Program\"\n",
      "- <Will ChatGPT and AI have an impact on Saudi workforce productivity>: \"AI Tool Impact: Transforming Workforce and Skills in Saudi Business, Likely Shaping Future Trends\"\n",
      "\n",
      "# Hypothesis/Questions\n",
      "## Question 1\n",
      "*How do the media in this article frame the public discussion about ChatGPT? Are there certain **metaphors** that keep cropping up?*\n",
      "\n",
      "The media in this article consistently frames the public discussion about ChatGPT using several metaphors. These include 'AI growth curve' or 'rapid development,' symbolizing AI's progress; 'Netscape moment' for its transformative impact, compared to Netscape's browser; 'rich conversational interface' highlighting ChatGPT's intuitive and interactive nature; 'generative AI tools' emphasizing its autonomous content creation abilities; 'outperforming copywriters,' depicting its superiority over traditional writing tasks; metaphors like understanding human culture, describing ChatGPT's depth in comprehending nuances; 'AI regulation is a must' or 'no need to demonize ChatGPT but AI regulation is necessary', emphasizing the necessity for control over its development and use; 'great opportunity for advancement' and 'existential threat to human work,' presenting AI as both promising yet potentially disruptive. These metaphors help in understanding and interpreting the significant, transformative role of ChatGPT in society.\n",
      "\n",
      "Reasoning: The articles presented use various metaphors to encapsulate their views on ChatGPT. These metaphors include: 'AI growth curve' or 'rapid development', symbolizing AI's progress; 'Netscape moment' for its transformative impact, compared to Netscape's browser in the early 1990s; 'rich conversational interface' highlighting ChatGPT's intuitive and interactive nature; 'generative AI tools' emphasizing its autonomous content creation abilities; 'outperforming copywriters', depicting its superiority over traditional writing tasks; 'creating more jobs than it erases', acknowledging both AI augmentation and potential displacement of human labor; metaphors like understanding human culture, describing ChatGPT's depth in comprehending nuances; 'AI regulation is a must' or 'no need to demonize ChatGPT but AI regulation is necessary', emphasizing the necessity for control over its development and use; 'great opportunity for advancement' and 'existential threat to human work', presenting AI as both promising yet potentially disruptive; metaphors such as text-generating AI, an 'AI model capable of writing essays', an 'AI assistant', and a 'wave of change', emphasizing its potential applications and impacts on industries.\n",
      "\n",
      "## Question 2\n",
      "*Which role does or might the Arabic World play in the development of Artificial Intelligence?*\n",
      "\n",
      "The Arabic World might play a significant role in the development of Artificial Intelligence through its considerations in AI-powered web tools and workforce productivity, and by being involved in the discourse around regulation.\n",
      "\n",
      "Reasoning: The provided text mentions that the Arab world is being considered for the uncertain age of AI-powered web tools, indicating a potential role in its development. Specifically, it's highlighted as 'not mentioned' whether ChatGPT or AI will have an impact on the Saudi workforce productivity and if there's a need for regulation around AI, suggesting that Arab world is actively engaged in discussions surrounding AI.\n",
      "\n",
      "## Question 3\n",
      "*Which use cases of Artificial Intelligence are helpful for the Arabic world based on this article?*\n",
      "\n",
      "The use cases of Artificial Intelligence that are helpful for the Arabic world based on this article include improving accessibility in journalism, enhancing education, streamlining recruitment processes, optimizing public sector services, supporting healthcare improvements, automating mundane tasks in public sectors, detecting financial fraud, and providing targeted marketing opportunities.\n",
      "\n",
      "Reasoning: The articles discuss several use cases of AI beneficial to the Arabic world, focusing primarily on ChatGPT and its applications. These include: 1) Enhancing accessibility in journalism through content generation (mentioned in 'ChatGPT is the ‘Netscape moment’ for artificial intelligence'), 2) Improving education by generating academic responses (discussed in 'AI is not smarter than humans'), 3) Streamlining recruitment and hiring processes with personalized training programs (highlighted in 'Will ChatGPT and AI have an impact on Saudi workforce productivity'), 4) Optimizing public sector services through automation of mundane tasks (described as beneficial in various parts of the articles), 5) Supporting healthcare improvements, particularly in diagnosis accuracy (noted under 'AI has a significant role to play in improving patient care'), and 6) Enhancing financial fraud detection capabilities. Furthermore, AI tools are also mentioned for supporting cross-cultural communication, enhancing language translation, and providing new opportunities for retailers through targeted marketing.\n",
      "\n",
      "## Question 4\n",
      "*What is the final message of the article?*\n",
      "\n",
      "AI can both enhance and augment human creativity while serving as a complementary tool; responsible use is key.\n",
      "\n",
      "Reasoning: The final messages from each article align around responsible, balanced integration of AI, emphasizing its complementary role rather than replacement. The articles advocate for ethical considerations, collaboration over complete takeover, and regulation to prevent negative impacts on human work and society.\n",
      "\n",
      "## Question 5\n",
      "*What perspectives and aspects are being widely covered in these Arabic articles about ChatGPT and the societal effects of Artificial Intelligence? Which aspects are being ignored?*\n",
      "\n",
      "The perspectives widely covered include technological advancements, ethical implications, societal impacts, public perception and regulation, industry influence, and challenges. Aspects ignored relate to affordability/costs of AI technology, know-how for its application, and the potential for AI to address global issues beyond business and service sectors.\n",
      "\n",
      "Reasoning: The articles collectively discuss several key areas related to AI, with a particular focus on ChatGPT. Here's a breakdown: \n",
      "\n",
      "1. **Technological Advancements**: The articles cover the rapid growth and increasing capabilities of ChatGPT, including its emergence in various applications like conversational interfaces, data-driven advancements, and even domain-specific tasks. They also discuss the potential of future versions of ChatGPT (ChatGPT-4) and AI's role in creating new job opportunities.\n",
      "\n",
      "2. **Ethical and Societal Implications**: These articles delve into ethical concerns surrounding AI, such as regulatory frameworks for AI, job displacement due to automation, the need for an AI-literate workforce, addressing bias in training datasets, and ensuring fairness across different demographics. They also explore broader societal impacts like data privacy violations by AI systems and potential exacerbation of biases.\n",
      "\n",
      "3. **Public Perception and Regulation**: There's a strong emphasis on public debate around AI, including existential risks and the importance of regulations to ensure accountability and transparency in AI development and use. The articles touch upon existing international regulations and propose global policies for AI governance.\n",
      "\n",
      "4. **Industry Impact**: Some articles discuss how ChatGPT is influencing industries, particularly customer service, content creation, data collection, and analysis. They also highlight the potential of AI in enhancing user experiences and increasing accessibility in education and healthcare.\n",
      "\n",
      "5. **Challenges and Limitations**: Despite its capabilities, the articles acknowledge limitations such as the need to not demonize ChatGPT and the complexity of ensuring fairness across different demographics and reducing bias in AI algorithms.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markdown = str()\n",
    "\n",
    "lda = analyzer.analysis.get(\"LDA\")\n",
    "markdown += f\"# Latent Dirichlet Allocation interpretation\\n### Topics that are frequently mentioned in all articles\\n- {'\\n- '.join(lda.keys())}\\n\\n\"\n",
    "\n",
    "\n",
    "tfidf = [elem.get(\"title\") for elem in flatten_list(analyzer.analysis.get(\"TFIDF\").values())]\n",
    "markdown += f\"# TF-IDF interpretation for every article\\n### Topics that appear in the article very often but not in others\\n\"\n",
    "\n",
    "for id, doc in enumerate(analyzer):\n",
    "    markdown += f\"- <{doc.title}>: {tfidf[id]}\\n\"\n",
    "\n",
    "markdown += \"\\n# Hypothesis/Questions\\n\"\n",
    "for q_id, question in enumerate(questions + [\"topic_question\"]):\n",
    "    answer = analyzer.analysis.get(question)\n",
    "    markdown += f\"## Question {q_id+1}\\n\"\n",
    "    markdown += f\"*{answer.get(\"question\")}*\\n\\n{answer.get(\"answer\")}\\n\\nReasoning: {answer.get(\"reasoning\")}\\n\\n\"\n",
    "    \n",
    "    \n",
    "print(markdown)\n",
    "\n",
    "markdown_path = os.path.join(analyzer.output_folder, \"research summary.md\")\n",
    "analyzer.export_markdown(markdown_path, markdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
